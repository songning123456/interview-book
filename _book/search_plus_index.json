{"./":{"url":"./","title":"interview of sonin","keywords":"","body":"面试大全 本系列知识由sonin总结发布,内容涵盖前端以及后端等 其他参考 中华石杉 https://blog.csdn.net/qq_42046105 advanced-java https://github.com/doocs/advanced-java 潜林 https://www.cnblogs.com/fyql/default.html?page=1 霖呆呆 https://juejin.im/post/5eb55ceb6fb9a0436748297d 欢迎star https://github.com/songning123456/interview-book "},"pages/Java/":{"url":"pages/Java/","title":"Java","keywords":"","body":"Java Please Go Forward "},"pages/Java/base/":{"url":"pages/Java/base/","title":"基础","keywords":"","body":"Java基础 Please Go Forward "},"pages/Java/base/1266003510067986476.html":{"url":"pages/Java/base/1266003510067986476.html","title":"为什么在Java面试中一定会深入考察HashMap?","keywords":"","body":"原因 HashMap作为一个键值对(key-value)的常见集合，在整个java的使用过程中都起着举足轻重的作用。比如从DB中取值、数据的加工、数据回传给前端、数据转换为json等都可能使用到HashMap；且HashMap作为一个可以允许空键值对的集合，也能实现自动的扩容，扩容的参数值为0.75，达到后自动扩容一倍，这样给一些处理未知数据量大小的数据来说，是很方便的。虽然HashMap是线程不安全的，主要体现在1.7和1.8上。1.7的hashMap在扩容的时候回形成循环链，导致死循环而报错，或者数据的丢失情况，在1.8上，虽然对这方面做了改进，但是仍然是线程不安全的，主要是体现在，若多线程操作数据，如线程A B同时进行数据的put操作，在put操作前，会进行key的hash碰撞，但是线程A B有可能同时碰撞且碰撞的值相同，那么就会发生线程A先插入到了碰撞的地方值，然后B也随后插入到同样的地方，导致线程B会覆盖线程A所插入的值，导致数据丢失。所以，在面试的时候，都很喜欢问HashMap。 "},"pages/Java/base/1266003510239952957.html":{"url":"pages/Java/base/1266003510239952957.html","title":"你知道HashMap底层的数据结构是什么吗?","keywords":"","body":"基本结构 数组 + 链表 + 红黑树 HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫Entry，这些个键值对（Entry）分散存储在一个数组之中，这个数组就是HashMap的主干，HashMap数组每一个元素的初始值都是null。 "},"pages/Java/base/1266003510374170667.html":{"url":"pages/Java/base/1266003510374170667.html","title":"JDK1.8中对hash算法和寻址算法是如何优化的?","keywords":"","body":"源码解析 // JDK1.8以后的HashMap里面的一段源码 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); } 运算 高低16位参与运算: 比如有一个key的hash值: 原值: 1111 1111 1111 1111 1111 1010 0111 1100 右移16位: 0000 0000 0000 0000 1111 1111 1111 1111 异或运算: 1111 1111 1111 1111 0000 0101 1000 0011 -> 转换成int值表示hash值 寻址算法优化: (n - 1) & hash -> 算出数组里的一个位置下标 取模运算性能差一些，为了优化数组寻址过程，数组长度2的n次方，hash & (n – 1)效果跟hash对n取模效果一样，与运算性能更高。核心在于低16的与运算。 hash算法的优化 对每个hash值，在他的低16位中，让高低16位进行了异或，让他的低16位同时保持了高低16位的特征，尽量避免一些hash值后续出现冲突，大家可能会进入数组的同一个位置。 "},"pages/Java/base/1266003510550331466.html":{"url":"pages/Java/base/1266003510550331466.html","title":"你知道HashMap是如何解决hash碰撞问题的吗?","keywords":"","body":"基本结构 链表+红黑树: O(n)和O(logn) 解决方案 利用“拉链法”处理HashCode的碰撞问题；当我们将键值对传递给put方法时，他调用键对象的hashCode()方法来计算hashCode，然后找到bucket（哈希桶）位置来存储对象；当用get方法获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当碰撞发生了，对象将会存储在链表的下一个节点中。hashMap在每个链表节点存储键值对对象。当两个不同的键却有相同的hashCode时，他们会存储在同一个bucket位置的链表中。键对象的equals()来找到键值对。 "},"pages/Java/base/1266003510697132063.html":{"url":"pages/Java/base/1266003510697132063.html","title":"说说HashMap是如何进行扩容的可以吗?","keywords":"","body":"扩容值 2的N次方扩容: 16,32,64... 方案 rehash:如果数组的长度扩容之后 = 32，重新对每个hash值进行寻址，也就是用每个hash值跟新数组的length - 1进行与操作。 n-1 0000 0000 0000 0000 0000 0000 0001 1111 hash1 1111 1111 1111 1111 0000 1111 0000 0101 &结果 0000 0000 0000 0000 0000 0000 0000 0101 = 5(index = 5的位置) n-1 0000 0000 0000 0000 0000 0000 0001 1111 hash2 1111 1111 1111 1111 0000 1111 0001 0101 &结果 0000 0000 0000 0000 0000 0000 0001 0101 = 21(index = 21的位置) 判断二进制结果中是否多出一个bit的1，如果没多，那么就是原来的index，如果多了出来，那么就是index + oldCap，通过这个方式，就避免了rehash的时候，用每个hash对新数组.length取模，取模性能不高，位运算的性能比较高。 "},"pages/Java/base/1266003510818766945.html":{"url":"pages/Java/base/1266003510818766945.html","title":"HashMap默认的初始长度是多少?为什么这么规定?","keywords":"","body":"初始值 HaspMap的默认初始长度是16 原因 每次扩展长度或者手动初始化时，长度必须是2的次幂。之所以是16，是为了服务于从Key值映射到index的hash算法。前面说到了，从Key值映射到数组中所对应的位置需要用到一个hash函数：index = hash(\"Java\");那么为了实现一个尽量分布均匀的hash函数，利用的是Key值的HashCode来做某种运算。因此问题来了，如何进行计算，才能让这个hash函数尽量分布均匀呢？一种简单的方法是将Key值的HashCode值与HashMap的长度进行取模运算，即 index = HashCode(Key)% hashMap.length，但是，但是！这种取模方式运算固然简单，然而它的效率是很低的， 而且，如果使用了取模%， 那么HashMap在容量变为2倍时， 需要再次rehash确定每个链表元素的位置，浪费了性能。因此为了实现高效的hash函数算法，HashMap的发明者采用了位运算的方式。那么如何进行位运算呢？可以按照下面的公式：index = HashCode(Key) & (hashMap.length - 1); "},"pages/Java/base/1266003510948790365.html":{"url":"pages/Java/base/1266003510948790365.html","title":"高并发情况下,HashMap会出现死锁吗?","keywords":"","body":"答案 会 原因 由于HashMap的容量是有限的，如果HashMap中的数组的容量很小，假如只有2个，那么如果要放进10个keys的话，碰撞就会非常频繁，此时一个O(1)的查找算法，就变成了链表遍历，性能变成了O(n)，这是Hash表的缺陷。为了解决这个问题,HashMap设计了一个阈值，其值为容量的0.75，当HashMap所用容量超过了阈值后，就会自动扩充其容量。在多线程的情况下，当重新调整HashMap大小的时候，就会存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历。如果条件竞争发生了，那么就会产生死循环了。 "},"pages/Java/base/1266003511787651113.html":{"url":"pages/Java/base/1266003511787651113.html","title":"ConcurrentHashMap实现线程安全的底层原理到底是什么?","keywords":"","body":"过去 在ConcurrentHashMap没有出现以前，jdk使用hashtable来实现线程安全，但是hashtable是将整个hash表锁住，所以效率很低下。ConcurrentHashMap将数据分别放到多个Segment中，默认16个，每一个Segment中又包含了多个HashEntry列表数组，对于一个key，需要经过三次hash操作，才能最终定位这个元素的位置，这三次hash分别为: * 对于一个key，先进行一次hash操作，得到hash值h1，也即h1 = hash1(key)； * 将得到的h1的高几位进行第二次hash，得到hash值h2，也即h2 = hash2(h1高几位)，通过h2能够确定该元素的放在哪个Segment； * 将得到的h1进行第三次hash，得到hash值h3，也即h3 = hash3(h1)，通过h3能够确定该元素放置在哪个HashEntry。 每一个Segment都拥有一个锁，当进行写操作时，只需要锁定一个Segment，而其它Segment中的数据是可以访问的。 现在 JDK1.8之前，多个数组，分段加锁，一个数组一个锁。JDK1.8之后，优化细粒度，一个数组，每个元素进行CAS，如果失败，则有线程已经用synchronized对元素加锁。链表+红黑树处理，对数组每个元素加锁。多个线程要访问同一个数据，synchronized加锁，CAS去进行安全的累加，去实现多线程场景下的安全的更新一个数据的效果。JDK1.8 [一个大的数组]，数组里每个元素进行put操作，都是有一个不同的锁，刚开始进行put的时候，如果两个线程都是在数组[5]这个位置进行put，这个时候，对数组[5]这个位置进行put的时候，采取的是CAS的策略，同一个时间，只有一个线程能成功执行这个CAS，就是说他刚开始先获取一下数组[5]这个位置的值，是null，然后执行CAS，线程1，比较一下，put进去我的这条数据，同时间，其他的线程执行CAS，都会失败。通过对数组每个元素执行CAS的策略，如果是很多线程对数组里不同的元素执行put，大家是没有关系的，可以并行。如果其他线程失败了，其他线程此时会发现数组[5]这位置，已经给刚才有线程放进去值了，就需要在这个位置基于链表+红黑树来进行处理，synchronized(数组[5])，加锁，基于链表或者是红黑树在这个位置插进去自己的数据，如果你是对数组里同一个位置的元素进行操作，才会加锁串行化处理；如果是对数组不同位置的元素操作，此时大家可以并发执行的。 "},"pages/Java/advance/":{"url":"pages/Java/advance/","title":"进阶","keywords":"","body":"Java进阶 Please Go Forward "},"pages/Java/advance/1266003511150116913.html":{"url":"pages/Java/advance/1266003511150116913.html","title":"说说synchronized的关键字的底层原理是什么?","keywords":"","body":"实现代码 synchronized(myObject) { // code... synchronized(myObject) { // code... } } 作用 monitorenter(加锁) monitorexit(解锁)用于线程同步，加锁。可用于类，对象，块。一般是对一个对象进行加锁。synchronize底层原理与JVM指令和monitor有关系。深入涉及CPU硬件原理，原则性、可见性、有序性、指令重排、偏向锁、JDK的对其进行的优化。synchronized关键字，底层编译后的JVM指令中，使用monitorenter和monitorexit指令。如果一个线程第一次synchronized那里，获取到了myObject对象的monitor的锁，计数器加1，然后第二次synchronized那里，会再次获取myObject对象的monitor的锁，这个就是重入加锁了，然后计数器会再次加1，变成2。这个时候，其他的线程在第一次synchronized那里，会发现说myObject对象的monitor锁的计数器是大于0的，意味着被别人加锁了，然后此时线程就会进入block阻塞状态，什么都干不了，就是等着获取锁。接着如果出了synchronized修饰的代码片段的范围，就会有一个monitorexit的指令，在底层。此时获取锁的线程就会对那个对象的monitor的计数器减1，如果有多次重入加锁就会对应多次减1，直到最后，计数器是0。 "},"pages/Java/advance/1266003511292723238.html":{"url":"pages/Java/advance/1266003511292723238.html","title":"能聊聊你对CAS的理解以及其底层原理可以吗?","keywords":"","body":"图解 定义 CAS会操作3个数字，当前内存中的值，旧的预期值，新的修改值，只有当旧的预期值跟内存中的值一样的时候，才会将内存中的值修改为新的修改值。举个例子吧，比如int a = 3，这是内存中的当前值，然后你CAS（3, 5），第一个是旧的预期值，如果3和a是一样的，那么就将a修改为5。其实吧，这里比较关键的一点就是cpu的compareAndSwap操作的原理是啥，以CPU（Intel X86）来举个例子。这块底层指令，会根据当前处理器类型，来决定要不要对一个cmpxchg指令加lock前缀，如果是单处理器，就不要加，因为自动保证顺序；但是如果是多处理器，就加个lock。intel对lock的定义，就是说加了lock之后，就会自动锁掉一块内存区域，然后同一时间只有一个处理器可以读写这块内存区域，其他处理器就不行了。 CAS缺点 ABA问题如果某个值一开始是A，后来变成了B，然后又变成了A，你本来期望的是值如果是第一个A才会设置新值，结果第二个A一比较也ok，也设置了新值，跟期望是不符合的。所以atomic包里有AtomicStampedReference类，就是会比较两个值的引用是否一致，如果一致，才会设置新值假设一开始变量i = 1，你先获取这个i的值是1，然后累加了1，变成了2。但是在此期间，别的线程将i -> 1 -> 2 -> 3 -> 1这个期间，这个值是被人改过的，只不过最后将这个值改成了跟你最早看到的值一样的值。结果你后来去compareAndSet的时候，会发现这个i还是1，就将它设置成了2，就设置成功了。说实话，用AtomicInteger，常见的是计数，所以说一般是不断累加的，所以ABA问题比较少见。 无限循环问题大家看源码就知道Atomic类设置值的时候会进入一个无限循环，只要不成功，就不停循环再次尝试，这个在高并发修改一个值的时候其实挺常见的，比如你用AtomicInteger在内存里搞一个原子变量，然后高并发下，多线程频繁修改，其实可能会导致这个compareAndSet()里要循环N次才设置成功，所以还是要考虑到的。 多变量原子问题一般的AtomicInteger，只能保证一个变量的原子性，但是如果多个变量呢？你可以用AtomicReference，这个是封装自定义对象的，多个变量可以放一个自定义对象里，然后他会检查这个对象的引用是不是一个。 "},"pages/Java/advance/1266003511913480288.html":{"url":"pages/Java/advance/1266003511913480288.html","title":"你对JDK中的AQS理解吗?AQS的实现原理是什么?","keywords":"","body":"理解 AQS=Abstract Queue Synchronizer 抽象队列同步器 实现原理 ReentrantLock state变量 -> CAS -> 失败后进入队列等待 -> 释放锁之后唤醒 非公平锁 公平锁 "},"pages/Java/advance/1266003512047697966.html":{"url":"pages/Java/advance/1266003512047697966.html","title":"说说线程池的底层工作原理可以吗?","keywords":"","body":"代码 ExecutorService threadPool = Executors.newFixedThreadPool(3); threadPool.submit(new Callable() { public void run() {} }); 执行流程 在创建了线程池后，等待提交过来的任务请求。 在调用execute()方法添加一个请求任务时，线程池会做如下判断: 如果正在运行的线程数量小于corePoolSize=3，那么马上创建线程运行这个任务； 如果正在运行的线程数量大于或等于corePoolSize=3，那么将这个任务放入队列； 如果这时候队列满了且正在运行的线程数量还小于maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务; 如果队列满了且正在运行的线程数量大于或等于maximumPoolSize,那么线程池会启动饱和拒绝策略来执行。 当一个线程完成任务时，它会从队列中去下一个任务来执行。 当一个线程无事可做超过一定的时间（keepAliveTime）时，线程池会判断：如果当前运行的线程数大于corePoolSize=3，那么这个线程就被停掉。所以线程池的所有任务完成后它最终会收缩到corePoolSize=3的大小。 "},"pages/Java/advance/1266003512169332821.html":{"url":"pages/Java/advance/1266003512169332821.html","title":"那你再说说线程池的核心配置参数都是干什么的?平时我们应该怎么用?","keywords":"","body":"背景 我们创建线程的常见方式一般有继承Thread类以及实现Runnable接口，其实Thread类也是实现了Runnable接口。通过这两种方式创建的线程，在执行完毕之后都会被销毁，这样频繁的创建和销毁线程是一件很浪费资源到的事情。那么，有没有什么办法解决这个问题呢?通过创建线程池就可以解决这个问题。通过线程池创建的线程执行完毕之后并不会销毁，而是会回到线程池继续重复利用，执行其他任务。 核心参数 corePoolSize(核心线程数) 核心线程会一直存在，即使没有任务执行； 当线程数小于核心线程数的时候，即使有空闲线程，也会一直创建线程直到达到核心线程数； 设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭。 queueCapacity(任务队列容量)也叫阻塞队列，当核心线程都在运行，此时再有任务进来，会进入任务队列，排队等待线程执行。 maxPoolSize(最大线程数) 线程池里允许存在的最大线程数量； 当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务； 线程池里允许存在的最大线程数量。当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务。 keepAliveTime(线程空闲时间) 当线程空闲时间达到keepAliveTime时，线程会退出（关闭），直到线程数等于核心线程数； 如果设置了allowCoreThreadTimeout=true，则线程会退出直到线程数等于零。 allowCoreThreadTimeout(允许核心线程超时) rejectedExecutionHandler(任务拒绝处理器) 当线程数量达到最大线程数，且任务队列已满时，会拒绝任务； 调用线程池shutdown()方法后，会等待执行完线程池的任务之后，再shutdown()。如果在调用了shutdown()方法和线程池真正shutdown()之间提交任务，会拒绝新任务。 线程池参数默认值 corePoolSize = 1 queueCapacity = Integer.MAX_VALUE maxPoolSize = Integer.MAX_VALUE keepAliveTime = 60秒 allowCoreThreadTimeout = false rejectedExecutionHandler = AbortPolicy() ThreadPoolExecutor(线程池)执行顺序 当线程数小于核心线程数时，会一直创建线程直到线程数等于核心线程数； 当线程数等于核心线程数时，新加入的任务会被放到任务队列等待执行； 当任务队列已满，又有新的任务时，会创建线程直到线程数量等于最大线程数； 当线程数等于最大线程数，且任务队列已满时，新加入任务会被拒绝。 ThreadPoolExecutor已经实现4个拒绝策略 AbortPolicy直接抛异常 DiscardPolicy当前任务会强制调用run先执行，任务将由调用者线程(可能是主线程)去执行。缺点可能会阻塞主线程。 DiscardOldestPolicy抛弃任务队列中最旧任务 CallerRunsPolicy抛弃当前将要加入队列的任务 自定义如果后续慢慢的队列里没任务了，线程空闲了，超过corePoolSize的线程会自动释放掉，在keepAliveTime之后就会释放。 "},"pages/Java/advance/1266003512362270766.html":{"url":"pages/Java/advance/1266003512362270766.html","title":"如果在线程中使用无界阻塞队列会发生什么问题?","keywords":"","body":"问题 因为调用异常，会调用超时，线程处理任务时间是超时时间，线程池等待队列，会变得越来越大，此时会导致内存飙升起来，而且还可能导致OOM，内存溢出或者频繁的GC。 "},"pages/Java/advance/1266003512504877152.html":{"url":"pages/Java/advance/1266003512504877152.html","title":"你知道如果线程池的队列满了之后,会发生什么事情吗?","keywords":"","body":"使用线程池的好处 降低资源消耗可以重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。 线程池的工作原理 线程池判断核心线程池里的线程是否都在执行任务?如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则执行第二步。 线程池判断工作队列是否已经满?如果工作队列没有满，则将新提交的任务存储在这个工作队列里进行等待。如果工作队列满了，则执行第三步。 线程池判断线程池的线程是否都处于工作状态?如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。 线程池饱和策略 AbortPolicy为Java线程池默认的阻塞策略，不执行此任务，而且直接抛出一个运行时异常，切记ThreadPoolExecutor.execute需要try catch，否则程序会直接退出。 DiscardPolicy直接抛弃，任务不执行，空方法。 DiscardOldestPolicy从队列里面抛弃head的一个任务，并再次execute 此task。 CallerRunsPolicy在调用execute的线程里面执行此command，会阻塞入口。 用户自定义拒绝策略（最常用）实现RejectedExecutionHandler，并自己定义策略模式。 Tips 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。 如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。 如果无法将任务加入BlockingQueue（队列已满），则在非corePool中创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。 如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。 ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，尽可能地避免获取全局锁（那将会是一个严重的可伸缩瓶颈）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。 "},"pages/Java/advance/1266003512655872046.html":{"url":"pages/Java/advance/1266003512655872046.html","title":"如果线上机器突然宕机,线程池的阻塞队列中的请求怎么办?","keywords":"","body":"问题 机器宕机，必然会导致线程池里的积压的任务丢失。 如何解决? 在提交一个任务到线程池里去，提交之前，将这个任务信息持久化到数据库里，此时的状态为未提交，提交成功之后，更新任务信息的状态为提交成功，当任务完成的时候，更新任务信息的状态为 已完成当宕机的机器重启的时候，可以开启一个后台线程，扫描数据库里未提交和已提交的任务，可以把任务读取出来，重新提交到线程池中，继续进行执行，被调用的方法一定做好幂等操作，防止请求重复执行。 "},"pages/Java/advance/1266003512857198645.html":{"url":"pages/Java/advance/1266003512857198645.html","title":"谈谈你对Java内存模型的理解可以吗?","keywords":"","body":"基本指令 lock、unlock、read、load、use、assign、store、write两个线程同时执行data++。 "},"pages/Java/advance/1266003512966250566.html":{"url":"pages/Java/advance/1266003512966250566.html","title":"你知道Java内存模型中的原子性,有序性,可见性是什么?","keywords":"","body":"可见性 定义是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的，也就是一个线程修改的结果。另一个线程马上就能看到。线程1操作i++后，强制线程2操作i时，必须从主内存中刷新更新后的i的值。 作用用volatile修饰的变量，就会具有可见性。volatile修饰的变量不允许线程内部缓存和重排序，即直接修改内存。所以对其他线程是可见的volatile只能让被他修饰内容具有可见性，但不能保证它具有原子性。在Java中volatile、synchronized和final实现可见性。 原子性 定义原子是世界上的最小单位，具有不可分割性。 作用在Java中synchronized和在lock、unlock中操作保证原子性。线程1对i++时，线程2不能对i++同时进行。同时刻只有一个线程对一个值进行操作。i++必须独立执行，但默认时线程不安全的。 有序性 定义Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性。 作用volatile是因为其本身包含“禁止指令重排序”的语义，synchronized是由“一个变量在同一个时刻只允许一条线程对其进行 lock操作”这条规则获得的，此规则决定了持有同一个对象锁的两个同步块只能串行执行。对于代码，还有一个问题时指令重排序，编译器和指令器，有时候为了提高代码执行效率，会将指令重排序。具备有序性，不会发生指令重排导致代码异常；不具有有序性，会发生指令重排，导致代码可能会出现一些问题。 volatile关键字用法 public class Counter { public volatile static int count = 0; public static void inc() { //这里延迟1毫秒，使得结果明显 try { Thread.sleep(1); } catch (InterruptedException e) { } count++; } public static void main(String[] args) { //同时启动1000个线程，去进行i++计算，看看实际结果 for (int i = 0; i 由于volatile具有可见性，在不并发的情况下是1000，实际输出只有994，由于并发原因。 "},"pages/Java/advance/1266003513092079621.html":{"url":"pages/Java/advance/1266003513092079621.html","title":"能能从Java底层角度聊聊volatile关键字的原理吗?","keywords":"","body":"原理 volatile用来解决可见性和有序性，在有些罕见条件下，可以有限保证原则性，但主要不是保证原则性的。讲volatile要从内存模型开始讲起，还有原子性，可见性，有序性。使其他工作线程内存中的值缓存失效，强制从主内存中读取新值，即可见性。在很多开源中间件系统源码里都有多线程并发，大量使用volatile关键字。 "},"pages/Java/advance/1266003513297600516.html":{"url":"pages/Java/advance/1266003513297600516.html","title":"你知道指令重排以及happens-before原则是什么吗?","keywords":"","body":"指令重排 定义Java语言规范规定了JVM线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致。这个过程通过叫做指令的重排序。指令重排序存在的意义在于：JVM能够根据处理器的特性（CPU的多级缓存系统、多核处理器等）适当的重新排序机器指令，使机器指令更符合CPU的执行特点，最大限度的发挥机器的性能。 背景我们知道现代CPU的主频越来越高，与cache的交互次数也越来越多。当CPU的计算速度远远超过访问cache时，会产生cache wait，过多的cache wait就会造成性能瓶颈。针对这种情况，多数架构（包括X86）采用了一种将cache分片的解决方案，即将一块cache划分成互不关联地多个 slots (逻辑存储单元，又名 Memory Bank 或 Cache Bank)，CPU可以自行选择在多个 idle bank 中进行存取。这种 SMP 的设计，显著提高了CPU的并行处理能力，也回避了cache访问瓶颈。 一般Memory bank是按cache address来划分的。比如偶数adress0×12345000分到bank 0, 奇数address 0×12345100分到bank1。 种类 编译期重排编译源代码时，编译器依据对上下文的分析，对指令进行重排序，以之更适合于CPU的并行执行。 运行期重排CPU在执行过程中，动态分析依赖部件的效能，对指令做重排序优化。 happens-before原则 定义Java存储模型有一个happens-before原则，就是如果动作B要看到动作A的执行结果（无论A/B是否在同一个线程里面执行），那么A/B就需要满足happens-before关系。 要求 同一个线程中的每个Action都happens-before于出现在其后的任何一个Action。 对一个监视器的解锁happens-before于每一个后续对同一个监视器的加锁。 对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。 Thread.start()的调用会happens-before于启动线程里面的动作。 Thread中的所有动作都happens-before于其他线程检查到此线程结束或者Thread.join()中返回或者Thread.isAlive()==false。 一个线程A调用另一个另一个线程B的interrupt()都happens-before于线程A发现B被A中断（B抛出异常或者A检测到B的isInterrupted()或者interrupted()）。 一个对象构造函数的结束happens-before与该对象的finalizer的开始。 如果A动作happens-before于B动作，而B动作happens-before与C动作，那么A动作happens-before于C动作。 理解happens-before规则是用来判断一个动作对另一个动作是否可见的法则，它只是用来判断可见性的，而不是决定执行顺序的，就是说动作A和动作B 的执行顺序是可以通过指令重排发生变化的，而如果你要保证A和B的可见性关系，就必须采用其他控制手段（比如volatile修饰属性）来保证AB的执行顺序不被打乱，这样就能用happens-before规则来判断AB两个动作的可见性。 "},"pages/Java/senior/":{"url":"pages/Java/senior/","title":"高级","keywords":"","body":"Java高级 Please Go Forward "},"pages/Java/senior/1266003515533164602.html":{"url":"pages/Java/senior/1266003515533164602.html","title":"JVM中有哪几块内存区域?Java8之后对内存做了什么改进?","keywords":"","body":"图解 区域 物理内存Metaspace(除jvm占用的内存，剩余的内存空间都可以被Metaspace占用) 方法区(常量，即时编译后的代码) 年轻代(eden space, from survivor, to survivor) 老年代 程序计数器PC 虚拟机栈(局部变量表, 操作数栈, 方法返回地址, 动态链接, 额外附加信息) 本地方法栈   Java 8以后的内存分代的改进，永久代里放了一些常量池+类信息，常量池 -> 堆里面，类信息 -> metaspace（元区域）。 "},"pages/Java/senior/1266003515960983567.html":{"url":"pages/Java/senior/1266003515960983567.html","title":"你知道JVM是如何运行起来的吗?我们的对象是如何分配的?","keywords":"","body":"图解 原理   有一个类里面包含了一个main方法，你去执行这个main方法，此时会启动一个jvm进程，他会默认就会有一个main线程，这个main线程就负责执行这个main方法的代码，进而创建各种对象。一般tomcat，类都会加载到jvm里去，spring容器而言都会对我们的类进行实例化成bean，有工作线程会来执行我们的bean实例对象里的方法和代码，进而也会创建其他的各种对象，实现业务逻辑。 "},"pages/Java/senior/1266003516292333626.html":{"url":"pages/Java/senior/1266003516292333626.html","title":"说说JVM在哪些情况下会触发垃圾回收可以吗?","keywords":"","body":"图解 条件 对象没有引用 作用域发生未捕获异常 程序在作用域正常执行完毕 程序执行了System.exit() 程序发生意外终止(被杀进程等) Tips   JVM的内存其实是有限制的，不可能是无限的，昂贵的资源，2核4G的机器，堆内存也就2GB左右，4核8G的机器，堆内存可能也就4G左右，栈内存也需要空间，metaspace区域放类信息也需要空间。在jvm里必然是有一个内存分代模型，年轻代和老年代。给年轻代一共是2GB内存，给老年代是2GB内存，默认情况下eden和2个s的比例：8:1:1，eden是1.6GB，S是0.2GB。如果说eden区域满了，此时必然触发垃圾回收，young gc(ygc)，没有人引用的对象就是垃圾对象。 "},"pages/Java/senior/1266003516485271593.html":{"url":"pages/Java/senior/1266003516485271593.html","title":"说说JVM的年轻代垃圾回收算法?对象什么时候转移到老年代?","keywords":"","body":"图解 解析   年轻代，大部分情况下，对象生存周期是很短的，可能在0.01ms之内，线程执行了3个方法，创建了几个对象，0.01ms之后就方法都执行结束了，此时那几个对象就会在0.01ms之内变成垃圾，可以回收的100个对象，可能90个对象都是垃圾对象，10个对象是存活的对象，5个复制算法，一次young gc，年轻代的垃圾回收。有的对象在年轻代里熬过了很多次垃圾回收，15次垃圾回收，此时会认为这个对象是要长期存活的对象，移到老年代。 "},"pages/Java/senior/1266003516749512749.html":{"url":"pages/Java/senior/1266003516749512749.html","title":"说说老年代的垃圾回收算法?常用的垃圾回收器都有什么?","keywords":"","body":" 对老年代而言，他里面垃圾对象可能是没有那么多的。 标记-清理   找出来那些垃圾对象，然后直接把垃圾对象在老年代里清理掉。 标记-整理   把老年代里的存活对象标记出来，移动到一起，存活对象压缩到一片内存空间里去。剩余的空间都是垃圾对象整个给清理掉，剩余的都是连续的可用的内存空间，解决了内存碎片的一个问题。 parnew+cms的组合   g1直接分代回收，新版本，慢慢的就是主推g1垃圾回收器了，以后会淘汰掉parnew+cms的组合，jdk 8~jdk 9比较居多一些，parnew+cms的组合比较多一些。 CMS   分成好几个阶段，刚开始用标记-清理，标记出垃圾对象，并发清理一些垃圾对象，整理，把存活的对象压缩到一起，避免内存碎片的产生。执行一个比较慢的垃圾回收，会stop the world，需要100mb，此时会导致系统停顿100ms，不能处理任何请求，应该尽可能垃圾回收和工作线程的运行，并发执行。 "},"pages/Java/senior/1266003516866953280.html":{"url":"pages/Java/senior/1266003516866953280.html","title":"你们生产环境中的Tomcat是如何设置JVM参数的?如何检查JVM运行情况?","keywords":"","body":"你们线上系统jvm参数是怎么配置的,为什么要这样配置,在这个配置参数之下,线上系统jvm运行情况如何?   一般web系统部署到tomcat，系统仅仅在tomcat的jvm进程来执行。tomcat有一个配置脚本，catalina对应有启动的一些jvm参数设置。主要是内存区域大小的分配，每个线程的栈大小，metaspace的大小，堆内存大小，年轻代和老年代分别大小，eden和survivor区域的大小分别是多少，如果没有设置，会有一个默认值。垃圾回收器，年轻代，老年代分别使用哪种垃圾回收器，每种垃圾回收器是否有对应的一些特殊参数设置，这些设置都是用来干什么的。 为什么要这样设置?jvm表现如何?   在一定业务背景下，进行系统运行时的对象数量的预估，对内存压力进行预估，对整个jvm运行状况进行预估，预估完毕之后，根据预估情况，可以去设置一些jvm参数，然后进行压测，压测时候，需要观察jvm运行情况，jstat工具去分析jvm运行情况，年轻代的eden区域的对象增长情况，ygc的频率，每次ygc过后多少对象存活，survivor区能否放的下，老年代对象增加速率，老年代多久会触发一次fgc。可以根据压测的情况进行一定的jvm参数的调优。压测主要两点：一个系统QPS，一个是系统的接口性能。压测到一定程度时，了解机器的cpu, 内存，io, 磁盘的负载情况，jvm的表现等，由此需要对一些代码进行优化，比如优化性能，或减轻cpu, io磁盘负担等，如果发现jvm的gc过于频繁，内存泄漏，需要对jvm各内存区域的大小以及一些参数进行调优。在线上生产环境时，也需要基于一些监控工具，或者jstat，观察系统的QPS和性能，接口可用性，调用成功率，机器负载，jvm表现，gc频率，耗时，内存消耗等等。 "},"pages/Java/senior/1266003516984393818.html":{"url":"pages/Java/senior/1266003516984393818.html","title":"你在实际项目中是否做过JVM GC优化,怎么做的?","keywords":"","body":"背景   如果jvm出频繁full gc，有没有尝试过生产环境的系统去进行gc优化，对于这个问题，需要结合具体业务来分析。如何一步一步去分析系统的jvm的性能问题，如何去进行jvm gc调优? 分不同情况 自己做过jvm gc的生产调优，恭喜你了，直接实话实说，你当时怎么调优，你们的问题如何暴露出来的，你如何一步一步定位问题的，如何进行调优，最后的结果是什么? 你看了jvm专栏，在过程中，或者看完以后，在自己生产环境中根据专栏学习到的知识，去调优过jvm，这个时候，你可以专栏里学习到的知识，去讲。最好对自己系统的生产环境的jvm，进行一个分析，gc频繁的问题，尽可能的去调优一下参数。 发现分析了一下生产环境的jvm的运行情况，非常好，并发量很低，几十分钟才一次young gc，存活的对象特别少，几乎都在s区域，老年代几乎没什么对象，几天或者几周才发生一次full gc，在自己本地单机部署，测试环境里，去压测，每秒单机有500并发请求，去观察jvm的运行情况，这个时候他会不会存在频繁gc的问题，你就去调优一下，你就可以基于这个压测的例子去讲解。 "},"pages/Java/senior/1266003517114417182.html":{"url":"pages/Java/senior/1266003517114417182.html","title":"你知道发生OOM之后,应该如何排查和处理线上系统的OOM?","keywords":"","body":"年老代堆空间被占满 异常java.lang.OutOfMemoryError: java heap space 说明这是最典型的内存泄漏方式，简单说就是所有堆空间都被无法回收的垃圾对象占满，虚拟机再也无法分配新空间 解决这种方式解决起来比较简单，一般就是根据垃圾回收前后的情况对比，同时根据对象引用情况（常见的集合对象引用）分析，基本都可以找到泄漏点。 持久代被占满 异常java.lang.OutOfMemoryError：PermGen space 说明Perm空间被占满，无法为新的class分配存储空间而引发的异常。这个异常以前是没有的，但是在java大量使用反射的今天这个异常就比较常见了。 主要原因大量动态反射生成的类不断被加载，最终导致Perm区被占满。更可怕的是，不同的ClassLoader即便使用相同的类，但是都会对其进行加载，相当于同一个东西，如果有N个ClassLoader那么它将会被加载N次。因此，在某些情况下，这个问题基本视为无解，当然，存在大量ClassLoader和大量反射类的情况并不多。 解决增加持久代内存 ，例如：-XX：MaxPermSize=16M 思考OOM可能发生在哪几个区域? 解决思路，在jvm里设置几个参数，一旦发生OOM之后，就会导出一份内存快照，就会有当时线上内存里对象的一个情况，可以用MAT（eclipse的一个插件(MAT也可以单独使用)）这样的工具进行分析。无非就是找出来当时占用内存最大的对象，找出来这些对象在代码中哪些地方创建出来的，一般来说就是可能会对内存做一个调优。从业务背景出发，一步一步的说明，在什么样的业务背景下，为什么会产生OOM的问题？当某个系统崩溃时，找到自动导出的内存快照，分析XX对象，直接定位代码，修改代码。你一定要把案例的业务、背景和思想给吸收了，就得融入到自己的业务里去，我负责的业务系统，在什么样的情况下，可能说会出现一大批的对象卡在内存里，无法回收，导致我系统没法放更多的对象了。OOM不是你自己的代码，可能是你依赖的第三方的组件，结合自己的项目去一步一步的分析，OOM问题的产生，和解决的过程。 "},"pages/Java/senior/1266003522684452895.html":{"url":"pages/Java/senior/1266003522684452895.html","title":"计算机的通信方式","keywords":"","body":"并行通信 Parallel communication(并行是指多比特数据同时通过并行线进行传送，这样数据传送速度大大提高，但并行传送的线路长度受到限制，因为长度增加，干扰就会增加，数据也就容易出错。)，只适用于近距离。 串行通信 一组信息的各位数据被逐位顺序传送的通信方式称为串行通信。串行通信可以通过串行接口来实现，串行通信传输速度慢，但是传输线少，适宜长距离通信。 传送方向 单工 - 只能一个方向传输数据 半双工 - 信息能双向传输，但不能同时双向传输 全双工 - 能双向传输并且可以同时双向传输 Tips Socket是一种应用接口，TCP/IP是网络传输协议，虽然接口相同，但是不同的协议有不同的服务性质...创建Socket连接时候，可以指定使用的传输层协议。Socket可以支持不同的传输层协议(TCP或者UDP，当使用TCP协议进行连接时候，该Socket链接就是一个TCP链接，就是TCP链接。Socket跟TCP/IP并没有必然的联系。Socket编程接口在设计的时候，就希望也能适应其他网络协议。所以，Sockets(TCP)通信是全双工的方式。 "},"pages/Spring/":{"url":"pages/Spring/","title":"Spring","keywords":"","body":"Spring系列 Please Go Forward "},"pages/Spring/1266003513490538513.html":{"url":"pages/Spring/1266003513490538513.html","title":"说说你对Spring的IOC机制的理解可以吗?","keywords":"","body":"没有Spring之前 写一套系统，web服务器，tomcat，一旦启动之后，他就可以监听一个端口号的http请求，然后可以把请求转交给你的servlet，jsp，配合起来使用的，servlet处理请求。比如在我们的一个tomcat + servlet的这样的一个系统里，有几十个地方，都是直接用MyService myService = new MyServiceImpl()，直接创建、引用和依赖了一个MyServiceImpl这样的一个类的对象。这个系统里，有几十个地方，都跟MyServiceImpl类直接耦合在一起了。如果我现在不想要用MyServiceImpl了，我们希望用的是NewServiceManagerImpl，implements MyService这个接口的，所有的实现逻辑都不同了，此时我们很麻烦，我们需要在系统里，几十个地方，都去修改对应的MyServiceImpl这个类，切换为NewServiceManagerImpl这个类。改动代码成本很大，改动完以后的测试的成本很大，改动的过程中可能很复杂，出现一些bug，此时就会很痛苦。归根结底，代码里，各种类之间完全耦合在一起，出现任何一丁点的变动，都需要改动大量的代码，重新测试，可能还会有bug。 有Spring之后 Spring IoC, Spring容器，根据XML配置或注解，去实例化你的一些bean对象，然后根据XML或注解，去对bean对象之间的引用关系，去进行依赖注入。底层核心技术是反射。通过反射技术，直接根据你的类去自己构建对应的对象出来。 "},"pages/Spring/1266003513670893618.html":{"url":"pages/Spring/1266003513670893618.html","title":"说说你对Spring的AOP机制的理解可以吗?","keywords":"","body":"定义 AOP（Aspect Orient Programming），一般称为面向切面编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态代理则以Spring AOP为代表。静态代理是编译期实现，动态代理是运行期实现，可想而知前者拥有更好的性能。 代理类型 静态代理是编译阶段生成AOP代理类，也就是说生成的字节码就织入了增强后的AOP对象；动态代理则不会修改字节码，而是在内存中临时生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。 动态代理 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB(Code Generation Library)，是一个代码生成的类库，可以在运行时动态的生成某个类的子类。注意，CGLIB是通过继承的方式做的动态代理。因此，如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的，诸如private的方法也是不可以作为切面的。 "},"pages/Spring/1266003513821888530.html":{"url":"pages/Spring/1266003513821888530.html","title":"了解过cglib动态代理吗?他和jdk动态代理的区别什么?","keywords":"","body":"jdk动态代理 需要有顶层接口才能使用，但是在只有顶层接口的时候也可以使用。常见是mybatis的mapper文件是代理，使用反射完成。使用了动态生成字节码技术。 cglib动态代理 可以直接代理类，使用字节码技术，不能对 final 类进行继承。使用了动态生成字节码技术。 区别 动态代理就是动态的创建一个代理类出来，创建这个代理类的实例对象，在这个里面引用你真正自己写的类，所有的方法的调用，都是先走代理类的对象，他负责做一些代码上的增强，再去调用你写的那个类。Spring里使用aop，比如说你对一批类和他们的方法做了一个切面，定义好了要在这些类的方法里增强的代码，Spring必然要对那些类生成动态代理，在动态代理中去执行你定义的一些增强代码。如果你的类是实现了某个接口的，spring aop会使用jdk动态代理，生成一个跟你实现同样接口的一个代理类，构造一个实例对象出来，jdk动态代理，他其实是在你的类有接口的时候，就会来使用。很多时候我们可能某个类是没有实现接口的，spring aop会改用cglib来生成动态代理，他是生成你的类的一个子类，他可以动态生成字节码，覆盖你的一些方法，在方法里加入增强的代码。"},"pages/Spring/1266003513964494868.html":{"url":"pages/Spring/1266003513964494868.html","title":"能说说Spring中的Bean是线程安全的吗?","keywords":"","body":"singleton(默认) 单例模式，在整个Spring IoC容器中，使用singleton定义的Bean将只有一个实例。 prototype 原型模式，每次通过容器的getBean方法获取prototype定义的Bean时，都将产生一个新的Bean实例，一般来说下面几种作用域，在开发的时候一般都不会用，99.99%的时候都是用singleton单例作用域。 request 对于每次HTTP请求，使用request定义的Bean都将产生一个新实例，即每次HTTP请求将会产生不同的Bean实例。只有在Web应用中使用Spring时，该作用域才有效，在请求完成以后，bean会失效并被垃圾回收器回收。 session 对于每次HTTP Session，使用session定义的Bean豆浆产生一个新实例。同样只有在Web应用中使用Spring时，该作用域才有效，在session过期后，bean会随之失效。 globalsession 每个全局的HTTP Session，使用session定义的Bean都将产生一个新实例。典型情况下，仅在使用portlet context的时候有效。同样只有在Web应用中使用Spring时，该作用域才有效。 Tips 其中比较常用的是singleton和prototype两种作用域。对于singleton作用域的Bean，每次请求该Bean都将获得相同的实例。容器负责跟踪Bean实例的状态，负责维护Bean实例的生命周期行为；如果一个Bean被设置成prototype作用域，程序每次请求该id的Bean，Spring都会新建一个Bean实例，然后返回给程序。在这种情况下，Spring容器仅仅使用new 关键字创建Bean实例，一旦创建成功，容器不在跟踪实例，也不会维护Bean实例的状态。如果不指定Bean的作用域，Spring默认使用singleton作用域。Java在创建Java实例时，需要进行内存申请；销毁实例时，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此，prototype作用域Bean的创建、销毁代价比较大。而singleton作用域的Bean实例一旦创建成功，可以重复使用。因此，除非必要，否则尽量避免将Bean被设置成prototype作用域。 spring管理的bean的线程安全跟bean的创建作用域和bean所在的使用环境是否存在竞态条件有关，spring并不能保证bean的线程安全。 "},"pages/Spring/1266003514161627157.html":{"url":"pages/Spring/1266003514161627157.html","title":"Spring的事务实现原理是什么?能聊聊你对事物传播机制的理解吗?","keywords":"","body":"[测试用例]https://blog.csdn.net/qq_26323323/article/details/81908955 实现原理 加一个@Transactional注解，Spring会使用AOP，对这个方法在执行前，先开启事务，在执行完毕后，根据方法是否报错，来决定是回滚还是提交事务。 传播机制 @Transactional(propagation=Propagation.REQUIRED) (默认)如果有事务则加入事务，如果没有事务，则创建一个新的(默认值)。 @Transactional(propagation=Propagation.NOT_SUPPORTED)Spring不为当前方法开启事务，相当于没有事务,每条执行语句单独执行，单独提交。 @Transactional(propagation=Propagation.REQUIRES_NEW)不管是否存在事务，都创建一个新的事务，原来的方法挂起，新的方法执行完毕后，继续执行老的事务。 @Transactional(propagation=Propagation.MANDATORY)MANDATORY必须在已有事务下被调用，否则报错;NOT_SUPPORTED执行数据库层面的事务操作，故当前测试中，insert方法成功执行，delete方法的抛错并不影响insert方法的执行。 @Transactional(propagation=Propagation.SUPPORTS)SUPPORTS类型的事务传播机制，是否使用事务取决于调用方法是否有事务，如果有则直接用，如果没有则不使用事务。 @Transactional(propagation=Propagation.NESTED)如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与REQUIRED类似的操作。 "},"pages/Spring/1266003514312622174.html":{"url":"pages/Spring/1266003514312622174.html","title":"能画一张图说说Spring Boot的核心架构吗?","keywords":"","body":"图解 特征 独立运行Spring项目Spring boot 可以以jar包形式独立运行，运行一个Spring Boot项目只需要通过java -jar xx.jar来运行。 内嵌servlet容器Spring Boot可以选择内嵌Tomcat、jetty或者Undertow，这样我们无须以war包形式部署项目。 提供starter简化Maven配置spring提供了一系列的start pom来简化Maven的依赖加载。例如，当你使用了spring-boot-starter-web，会自动加入依赖包。 自动装配Spring SpringBoot会根据在类路径中的jar包，类。为jar包里面的类自动配置Bean，这样会极大地减少我们要使用的配置。当然，SpringBoot只考虑大多数的开发场景，并不是所有的场景，若在实际开发中我们需要配置Bean，而SpringBoot没有提供支持，则可以自定义自动配置。 准生产的应用监控SpringBoot提供基于http ssh telnet对运行时的项目进行监控。 无代码生产和xml配置SpringBoot不是借助与代码生成来实现的，而是通过条件注解来实现的，这是Spring4.x提供的新特性。 "},"pages/Spring/1266003514547503179.html":{"url":"pages/Spring/1266003514547503179.html","title":"能画一张图说说Spring的核心架构吗?","keywords":"","body":"生命周期 创建 -> 使用 -> 销毁 用xml或注解，定义一堆bean 流程 实例化bean 通过反射创建bean对象实例。 设置对象属性(依赖注入) 实例化后的对象被封装在BeanWrapper对象中，Spring根据BeanDefinition中的信息以及通过BeanWrapper提供的设置属性接口完成依赖注入。这个bean依赖了谁，把依赖的bean也创建出阿里，给你进行一个注入，比如通过构造函数或setter方法。 处理Aware接口 Spring检查该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给Bean。 如果这个Bean实现了BeanNameAware接口，则调用它的实现setBeanName(String beanid)方法，传递就是Spring配置文件中的Bean的id值； 如果这个Bean实现了BeanFactoryAware接口，则调用它实现的setBeanFactory()方法，传递的是Spring工厂自身； 如果这个Bean实现了ApplicationContextAware接口，则调用setApplicationContext(ApplicationContext)方法，传入Spring上下文； BeanPostProcessor 如果想在bean实例构建之后，在这个时间点对bean进行自定义处理，则可以让bean实现BeanPostProcessor接口，会调用postProcessBeforeInitialiazation(Object obj, String s)方法。 InitalizingBean与init-method 如果bean在Spring配置文件中配置了init-method属性，则会自动调用其配置的初始化方法。 BeanPostProcessor 在bean初始化完成后，如果这个bean实现了BeanPostProcessor接口，会调用postProcessAfterInitialization(Object obj, String s)方法。 DisposableBean 当bean不再需要时，如果bean实现了DisposableBean接口，会调用其他实现的destroy()方法。 destroy-method 如果配置了destroy-method属性，会调用配置的销毁方法。 "},"pages/Spring/1266003514706886713.html":{"url":"pages/Spring/1266003514706886713.html","title":"能说说Spring中都使用了哪些设计模式吗?","keywords":"","body":"工厂模式   Spring IOC核心的设计模式的思想提现，他自己就是一个大的工厂，把所有的bean实例都给放在了spring容器里（大工厂），如果你要使用bean，就找spring容器就可以了，你自己不用创建对象了。 单例模式   Spring默认来说，对每个bean走的都是一个单例模式，确保说你的一个类在系统运行期间只有一个实例对象，只有一个bean，用到了一个单例模式的思想，保证了每个bean都是单例的。 代理模式   如果说你要对一些类的方法切入一些增强的代码，会创建一些动态代理的对象，让你对那些目标对象的访问，先经过动态代理对象，动态代理对象先做一些增强的代码，调用你的目标对象。 "},"pages/Spring/1266003514803355688.html":{"url":"pages/Spring/1266003514803355688.html","title":"能画一张图说说Spring Web MVC的核心架构吗?","keywords":"","body":"图解 流程 Tomcat的工作线程将请求转交给spring mvc框架的DispatcherServlet。 DispatcherServlet查找@Controller注解的controller，我们一般会给controller加上你@RequestMapping的注解，标注说哪些controller用来处理哪些请求，此时根据请求的uri，去定位到哪个controller来进行处理。 根据@RequestMapping去查找，使用这个controller内的哪个方法来进行请求的处理，对每个方法一般也会加@RequestMapping的注解。 会直接调用我们的controller里面的某个方法来进行请求的处理。 我们的controller的方法会有一个返回值，以前的时候，一般来说还是走jsp、模板技术，我们会把前端页面放在后端的工程里面，返回一个页面模板的名字，spring mvc的框架使用模板技术，对html页面做一个渲染(现在一般返回一个json串，前后端分离，可能前端发送一个请求过来，我们只要返回json数据。) "},"pages/SpringCloud/":{"url":"pages/SpringCloud/","title":"Spring Cloud","keywords":"","body":"Spring Cloud系列 Please Go Forward "},"pages/SpringCloud/1266003503914942509.html":{"url":"pages/SpringCloud/1266003503914942509.html","title":"你们的系统使用了哪种服务框架?为什么要这样技术选型?","keywords":"","body":"Spring Cloud && Dubbo对比 区别 并发性能 注册中心 分布式配置中心 网关 负载均衡 熔断功能 社区活跃度 Spring 使用的是http协议,性能与dubbo对比稍微差点 有全家桶配置中心: eurake nacos,亦可以选择zookeeper nacos / spring cloud config zuul / srping cloud gateway ribbon hystrix 活跃,版本更新快 Dubbo 是一款优秀的RPC框架,并发能力比springcloud强 一般选择zookeeper 阿波罗 需引入其他网关组件 自带负载均衡 需引入其他熔断框架 不活跃 Tips 所以现在一般都会选择spring cloud全家桶做微服务，因为spring cloud胜在功能更全，有一些列可以开箱即用的组件，满足服务化后的各种场景需求。或者说dubbo就是一个纯正的RPC框架，对于服务之间远程调用，性能非常优秀，并发高，响应快，但是也仅仅是一个RPC框架，如果需要其他的功能，则需要引入其他的组件，因此在引入其他组件的过程中，可能会带来更多的问题。所以对于易用性这一块，spring cloud已经集成了各方面微服务所需要的组件，上手更快，拆坑更少，团队上手更容易，学习成本更低。可以开箱即用，快速上手。 "},"pages/SpringCloud/1266003504225320982.html":{"url":"pages/SpringCloud/1266003504225320982.html","title":"看过Dubbo源码吗?说说Dubbo的底层架构原理?","keywords":"","body":"简介 Dubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合(或者最大限度地松耦合)。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方(Provider)和服务消费方(Consumer)两个角色。 是什么 简单说呢，Dubbo用起来就和EJB、WebService差不多，调用一个远程的服务(或者JavaBean)的时候在本地有一个接口，就像调用本地的方法一样去调用，它底层帮你实现好你的方法参数传输和远程服务运行结果传回之后的返回，就是RPC的一种封装啦~ 特点 它主要是使用高效的网络框架和序列化框架，让分布式服务之间调用效率更高。 采用注册中心管理众多的服务接口地址，当你想调用服务的时候只需要跟注册中心询问即可，不用像使用WebService一样每个服务都得记录好接口调用方式。注册中心主要就是负责dubbo的所有服务地址列表维护，并且可以通过在ZooKeeper节点中设置相应的值来实现对这个服务的权重、优先级、是否可用、路由、权限等的控制。之后在Dubbo的管理控制台对服务的一堆治理策略设置和调整，实际上就是修改了注册中心中的服务对应的配置数据(即修改了zookeeper中服务对应的节点的配置数据)。之后Consumer从注册中心请求到服务的数据时就能根据这些配置数据进行相应的治理配置参数的代码执行生效。 监控中心实现对服务方和调用方之间运行状态的监控，还能控制服务的优先级、权限、权重、上下线等，让整个庞大的分布式服务系统的维护和治理比较方便。 高可用有个服务宕机了?注册中心就会从服务列表去掉该节点。还是调用到了?客户端会向注册中心请求另一台可用的服务节点重新调用。注册中心宕机?注册中心也能实现高可用(ZooKeeper)。 负载均衡：采用软负载均衡算法实现对多个相同服务的节点的请求负载均衡。 RPC之Dubbo实现 主要为三点，动态代理、反射、socket网络编程 客户端使用动态代理的方式，“假装”实现了createOrder方法。 方法相关的数据通过序列化，进入到socket服务器。dubbo的socket实现为Netty。 服务端从socket服务器取出数据，通过反射的方式找到“真实”的服务实现。 服务端的方法在服务启动时已注入。 服务发现层，可用zookeeper。zookeeper保证了CP(一致性，分区容错性)。缺点：master节点挂掉时，需要时间重新选择master，这段时间内注册中心将不可用。 注意：服务端可消费端注册成功后，通讯只走socket服务器，不会经过注册中心。 核心技术简介 客户端发起接口调用； 服务中间件进行路由选址：找到具体接口实现的服务地址； 客户端将请求信息进行编码(序列化: 方法名，接口名，参数，版本号等)； 建立与服务端的通讯(不是调度中心，而是客户端与服务端直连)； 服务端将接收到的信息进行反编码(反序列化)； 根据信息找到服务端的接口实现类； 将执行结果反馈给客户端。 "},"pages/SpringCloud/1266003504359538773.html":{"url":"pages/SpringCloud/1266003504359538773.html","title":"咱们来聊点深入的,说说Dubbo底层的网络通信机制原理?","keywords":"","body":"基本信息 连接个数: 单连接 连接方式: 长连接 传输协议: TCP 传输方式: NIO异步传输 序列化: Hessian二进制序列化 适用范围： 传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。 适用场景: 常规远程服务方法调用 同步远程调用 客户端线程调用远程接口，向服务端发送请求，同时当前线程应该处于“暂停”状态，即线程不能向后执行了，必需要拿到服务端给自己的结果后才能向后执行； 服务端接到客户端请求后，处理请求，将结果给客户端； 客户端收到结果，然后当前线程继续往后执行； 基本原理 client一个线程调用远程接口，生成一个唯一的ID（比如一段随机字符串，UUID等），Dubbo是使用AtomicLong从0开始累计数字的； 将打包的方法调用信息（如调用的接口名称，方法名称，参数值列表等），和处理结果的回调对象callback，全部封装在一起，组成一个对象object； 向专门存放调用信息的全局ConcurrentHashMap里面put(ID, object)； 将ID和打包的方法调用信息封装成一对象connRequest，使用IoSession.write(connRequest)异步发送出去； 当前线程再使用callback的get()方法试图获取远程返回的结果，在get()内部，则使用synchronized获取回调对象callback的锁， 再先检测是否已经获取到结果，如果没有，然后调用callback的wait()方法，释放callback上的锁，让当前线程处于等待状态； 服务端接收到请求并处理后，将结果（此结果中包含了前面的ID，即回传）发送给客户端，客户端socket连接上专门监听消息的线程收到消息，分析结果，取到ID，再从前面的ConcurrentHashMap里面get(ID)，从而找到callback，将方法调用结果设置到callback对象里； 监听线程接着使用synchronized获取回调对象callback的锁（因为前面调用过wait()，那个线程已释放callback的锁了），再notifyAll()，唤醒前面处于等待状态的线程继续执行（callback的get()方法继续执行就能拿到调用结果了,这里的callback对象是每次调用产生一个新的，不能共享，否则会有问题；另外ID必需至少保证在一个Socket连接里面是唯一的。），至此，整个过程结束。 当前线程怎么让它\"暂停\",等结果回来后,再向后执行? 答: 先生成一个对象obj，在一个全局map里put(ID,obj)存放起来，再用synchronized获取obj锁，再调用obj.wait()让当前线程处于等待状态，然后另一消息监听线程等到服务端结果来了后，再map.get(ID)找到obj，再用synchronized获取obj锁，再调用obj.notifyAll()唤醒前面处于等待状态的线程。 正如前面所说,Socket通信是一个全双工的方式,如果有多个线程同时进行远程方法调用,这时建立在client server之间的socket连接上会有很多双方发送的消息传递,前后顺序也可能是乱七八糟的,server处理完结果后,将结果消息发送给client,client收到很多消息,怎么知道哪个消息结果是原先哪个线程调用的? 答: 使用一个ID，让其唯一，然后传递给服务端，再服务端又回传回来，这样就知道结果是原先哪个线程的了。 "},"pages/SpringCloud/1266003504476979219.html":{"url":"pages/SpringCloud/1266003504476979219.html","title":"Dubbo框架从架构设计角度,是怎么保证极高的可扩展性?","keywords":"","body":"Dubbo SPI特点 对Dubbo进行扩展，不需要改动Dubbo的源码。 自定义的Dubbo的扩展点实现，是一个普通的Java类，Dubbo没有引入任何Dubbo特有的元素，对代码侵入性几乎为零。 将扩展注册到Dubbo中，只需要在ClassPath中添加配置文件。使用简单。而且不会对现有代码造成影响。符合开闭原则。 Dubbo的扩展机制支持IoC,AoP等高级功能。 Dubbo的扩展机制能很好的支持第三方IoC容器，默认支持Spring Bean，可自己扩展来支持其他容器，比如Google的Guice。 切换扩展点的实现，只需要在配置文件中修改具体的实现，不需要改代码。使用方便。 Dubbo底层架构原理图 "},"pages/SpringCloud/1266003504686694408.html":{"url":"pages/SpringCloud/1266003504686694408.html","title":"如果让你设计一个RPC框架,网络通信 代理机制 负载均衡?","keywords":"","body":"什么是RPC RPC的全称是Remote Procedure Call，远程过程调用。RPC框架有很多，比如hsf、dubbo等等。借助RPC框架，我们在写业务代码的时候可以不需要去考虑服务之间的通信等问题，在调用远程服务的时候就像调用本地的方法那么简单。 组成部分 简化本地调用流程 既然我们要像调用本地方法那样调用远程服务， 那么就应该生成代理来隐藏调用远程服务的细节。 这些细节包括但不限于以下所列出的关注点。 服务发现与服务注册 如果我们想在Service A中调用Service B，那么我们首先得知道Service B的地址。 所以，我们需要有一个服务注册中心，通过这个中心，服务可以把自己的信息注册进来，也可以获取到别的服务的信息。 客户端也需要watch服务注册中心的目标服务的地址的变化。 网络通信 服务和服务之间的网络通信模型， NIO/IO等等。 客户端如何复用与服务端的连接， 而不是每次请求都重新创建一个新连接？ 客户端收到返回后，如何知道是哪个请求的返回并且做出正确处理？ 消息的序列化 服务间通信的消息通过什么方式进行序列化？ hessian，XML、JSON、Protobuf、……, 甚至Java原生的序列化方式， 你总得选择一个。 负载均衡 客户端通过服务注册中心拿到一堆地址，该调哪个呢？最简单的方式，可以通过RR、WRR的方式去做LB。 根据服务实例的metrics做出动态调整, 比如响应时间等。 利用一致性哈希， 提高本地缓存利用率。 容灾 健康监测: 在某一个服务节点挂掉的时候， 如何在服务注册中心删去这个服务地址？ 服务调用超时与重试: 在调用一个服务实例的时候，如果超时或者报错，怎么处理？ 服务限流: 如何限制最大并发数？这个又可以从客户端和服务端两个角度分析。 "},"pages/SpringCloud/1266003504686694508.html":{"url":"pages/SpringCloud/1266003504686694508.html","title":"能画一张图说说Spring Cloud的核心架构吗?","keywords":"","body":"图解 基本组件 Eureka 首先，我们需要一个注册中心 Eureka ，主要负责每个服务的注册和发现。每个微服务中都有一个Euraka client组件，专门负责将这个服务的服务id（serviceId）、ip、端口等信息注册到Eureka server中。Euraka Server是一个注册中心，该组件内部维护了一个注册表，保存了各个服务所在的机器ip和端口号等信息。 Feign 其次每个服务还需要一个远程服务调用的组件 Feign ，他主要负责与其他服务建立连接，构造请求，然后发起请求来调用其他服务来获取数据。 Ribbon 然后我们一个服务可能会部署很多台机器，那么我们使用Feign 去调用这个服务的时候，到底把请求发送到哪台机器上去呢？此时我们就需要一个组件来根据一定的策略来选择一台机器。不管怎么选的，总之得选一台机器给 Feign 去调用就好了。这个组件就是 Ribbon，Ribbon 主要负责就是负载均衡。Ribbon 会定期去从Eureka 注册中心拉取注册中心，缓存到本地，每次发起远程调用的时候，Ribbon 就会从 Eureka 注册表拉取下来的数据中挑选一个机器让 Feign 来发起远程调用。 Zuul 我们这么多的微服务，如果一个服务一个IP，使用方都需要进行调用的话，是不是得知道每一个服务的IP地址才行呢？那得记住多少才行呀，多不好管理。如果有一个统一的地址，然后根据不同的请求路径来跟我进行转发多少是不，比如 /user/* 是转发到用户服务 ，/product/* 是转向到商品服务等等。我使用的时候，只需要访问同一个IP ，只是路径不一样，就行了。Spring Cloud 也给我们提供了一个组件，那就是 Zuul ，他是一个网关，就是负责网络的路由的。每个请求都经过这个网关，我们还可以做统一鉴权等等很多事情。 Hystrix 还有一个东西也得说一下，就是 Hystrix，它是一个隔离、熔断以及降级的一个框架 。在微服务的相互调用过程中，可能会出现被调用服务错误或者超时的情况，从而导致整个系统崩溃不可用，也就是我们常说的服务雪崩问题，Hystrix 的存在就是为了解决这种问题的。 调用流程 首先每个服务启动的时候都需要往注册中心进行注册。 用户先对网关发起下单请求，网关收到请求后发现呃，是下单操作，要到订单系统，然后把请求路由到订单系统。 订单系统啪啦啪啦一顿操作，然后通过 Feign 去调用 库存系统减库存，通知仓储服务发货，调用积分系统加积分。 在发起调用之前，订单系统还得通过Ribbon 去注册中心去拉取各系统的注册表信息，并且挑一台机器给 Feign 来发起网络调用。 "},"pages/SpringCloud/1266003504770580518.html":{"url":"pages/SpringCloud/1266003504770580518.html","title":"平时除了使用外,有研究过Spring Cloud的底层架构原理吗?","keywords":"","body":"SpringCloud架构原理图 Spring Cloud核心组件 Eureka 各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里。 Ribbon 服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台。 Feign 基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求。 Hystrix 发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题。 Zuul 如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务。 "},"pages/SpringCloud/1266003505043210273.html":{"url":"pages/SpringCloud/1266003505043210273.html","title":"从底层实现原理的角度,对比一下Dubbo和Spring Cloud的区别?","keywords":"","body":"Dubbo && SpringCloud原理图 RPC && SpringCloud原理图 相同点 都需要 服务提供方，注册中心，服务消费方。 Dubbo Provider: 暴露服务的提供方，可以通过jar或者容器的方式启动服务。 Consumer: 调用远程服务的服务消费方。 Registry: 服务注册中心和发现中心。 Monitor: 统计服务和调用次数，调用时间监控中心。(dubbo的控制台页面中可以显示，目前只有一个简单版本) Container: 服务运行的容器。 Spring Cloud Service Provider: 暴露服务的提供方。 Service Consumer: 调用远程服务的服务消费方。 EureKa Server: 服务注册中心和服务发现中心。 比较 从核心要素来看 Spring Cloud 更胜一筹，在开发过程中只要整合Spring Cloud的子项目就可以顺利的完成各种组件的融合，而Dubbo缺需要通过实现各种Filter来做定制，开发成本以及技术难度略高。Dubbo只是实现了服务治理，而Spring Cloud子项目分别覆盖了微服务架构下的众多部件，而服务治理只是其中的一个方面。Dubbo提供了各种Filter，对于上述中“无”的要素，可以通过扩展Filter来完善。 分布式配置：可以使用淘宝的diamond、百度的disconf来实现分布式配置管理 服务跟踪：可以使用京东开源的Hydra，或者扩展Filter用Zippin来做服务跟踪 批量任务：可以使用当当开源的Elastic-Job、tbschedule 从协议上看 Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况，二进制的传输，占用带宽会更少。Spring Cloud 使用HTTP协议的REST APIdubbo支持各种通信协议，而且消费方和服务方使用长链接方式交互，http协议传输，消耗带宽会比较多，同时使用http协议一般会使用JSON报文，消耗会更大。通信速度上Dubbo略胜Spring Cloud，如果对于系统的响应时间有严格要求，长链接更合适。 从服务依赖方式看 Dubbo服务依赖略重，需要有完善的版本管理机制，但是程序入侵少。而Spring Cloud通过Json交互，省略了版本管理的问题，但是具体字段含义需要统一管理，自身Rest API方式交互，为跨平台调用奠定了基础。 从组件运行流程看 Dubbo每个组件都是需要部署在单独的服务器上，gateway用来接受前端请求、聚合服务，并批量调用后台原子服务。每个service层和单独的DB交互。 SpringCloud所有请求都统一通过 API 网关(Zuul)来访问内部服务。网关接收到请求后，从注册中心（Eureka）获取可用服务。由Ribbon进行均衡负载后，分发到后端的具体实例。微服务之间通过 Feign 进行通信处理业务。业务部署方式相同，都需要前置一个网关来隔绝外部直接调用原子服务的风险。Dubbo需要自己开发一套API 网关，而Spring Cloud则可以通过Zuul配置即可完成网关定制。使用方式上Spring Cloud略胜一筹。 "},"pages/SpringCloud/1266003505391337531.html":{"url":"pages/SpringCloud/1266003505391337531.html","title":"你们的服务注册中心进行过选型调研吗?对比一Eureka和Zookeeper?","keywords":"","body":"Eureka && Zookeeper Eureka (AP)   peer-to-peer，部署一个集群，但是集群里每个机器的地位是对等的，各个服务可以向任何一个Eureka实例服务注册和服务发现，集群里任何一个Eureka实例接收到写请求之后，会自动同步给其他所有的Eureka实例。Eureka是peer模式，可能还没同步数据过去，结果自己就死了，此时还是可以继续从别的机器上拉取注册表，但是看到的就不是最新的数据了，但是保证了可用性，强一致，最终一致性。 单点问题eureka需要部署服务，服务自身需要做集群，增加了系统部署的复杂性。 数据同步各服务之间数据同步是异步的，定时的，这会导致节点间一定时间内，数据不一致；并且，在数据复制的过程中，如果持有新实例注册信息的注册中心自身挂掉了，这个实例就无法得到注册； 自我保护机制注册中心自身如果监测到某个实例的心跳成功比例一定时间内小于一定的阈值，这个实例注册信息会被保护起来，不会注销掉，等到这个心跳成功比例大于阈值时，退出自我保护机制。在这个保护期内，如果服务挂了，那这个实例信息其实时有问题的，应该被剔除。 心跳压力如果注册中心注册的实例过多，比如500个，每个间隔30s发出一次续约心跳，那30s内，就是15000个心跳连接，这个心跳的请求可能大于实际业务发出的请求。 健康检查机制健康检查比较单一，仅仅检查心跳是不够的，心跳还在，说明服务进程没死，那服务所在的硬件问题如内存满载，关联的db挂了等，这些都无法得到反应，所以服务可能并不能提供服务了，但是服务还在注册中心的列表中。 维护风险官方宣布2.0的开源工作停止了，继续使用的责任自负。 Zookeeper (CP)   Leader + Follower两种角色，只有Leader可以负责写也就是服务注册，他可以把数据同步给Follower，读的时候leader/follower都可以读。ZooKeeper是有一个leader节点会接收数据， 然后同步写其他节点，一旦leader挂了，要重新选举leader，这个过程里为了保证C，就牺牲了A，不可用一段时间，但是一个leader选举好了，那么就可以继续写数据了，保证一致性。 重java开发，引入依赖多，对于服务器而言太重，部署复杂，不支持多数据中心。对服务侵入大。 健康检查检查方式单一，需要消费者自己实现，也是靠心跳连接保活，连接断开，就是服务挂了，服务就会被剔除。 更新非常稳定，更新少，微服务架构下，对于做专业的注册中心而言，功能匮乏，丧失了快速迭代的能力，不够与时俱进，不够灵活。 算法paxos算法，复杂难懂。 etcd 未使用过，资料了解，其本质上是一个比zk轻量的分布式键值对存储系统，但是需要搭配其他小工具才能较好较易用的实现注册中心功能。但是，为了实现A功能，又额外引入了B和C工具，不是一个优雅的实现方案，而且不支持多数据中心,无web管理页面。 consul (CP) 数据一致性 raft算法，实现思路从源头上避免了数据不一致性。注册时，超过半数没有拿到信息，那就注册失败。 开箱即用 集成简单，不依赖其他工具，使用也简单，支持2种服务注册方式：配置文件，http api。 kv存储 支持和zk和etcd一样的kv存储，可做配置中心。 健康检查 健康检查支持好，提供多种健康检查功能，比如服务返回的状态码，内存利用率等。 心跳 服务状态的检查，不是直接向注册中心发心跳，而是agent向服务发出健康监测。 web管理页面 官方提供良好的web管理页面。 活跃 社区很活跃，更新频繁。 Nacos 这个最近也挺火，待了解。 Tips 一致性保障: CP or AP CAP: C是一致性，A是可用性，P是分区容错性。 ZooKeeper是有一个leader节点会接收数据， 然后同步写其他节点，一旦leader挂了，要重新选举leader，这个过程里为了保证C，就牺牲了A，不可用一段时间，但是一个leader选举好了，那么就可以继续写数据了，保证一致性。Eureka是peer模式，可能还没同步数据过去，结果自己就死了，此时还是可以继续从别的机器上拉取注册表，但是看到的就不是最新的数据了，但是保证了可用性，强一致，最终一致性。 "},"pages/SpringCloud/1266003505634607158.html":{"url":"pages/SpringCloud/1266003505634607158.html","title":"画图阐述一下你们的服务注册中心部署架构,生产环境下怎么保证高可用?","keywords":"","body":"图略 高可用 Eureka高可用，至少2台做集群。两个分支内相互配置另一台的ip和端口号。 "},"pages/SpringCloud/1266003505915625504.html":{"url":"pages/SpringCloud/1266003505915625504.html","title":"你们系统遇到过服务发现过慢的问题吗?怎么优化和解决的?","keywords":"","body":"客户端的有效负载缓存应该更新的时间间隔,默认为30 * 1000ms eureka.server.responseCacheUpdateIntervalMs = 30000(30s) -> 3000(3s) 从eureka服务器注册表中获取注册信息的时间间隔(s),默认为30s eureka.client.registryFetchIntervalSeconds = 30000 -> 3000 客户端多长时间发送心跳给eureka服务器,表明它仍然活着,默认为30s eureka.client.leaseRenewalIntervalInSeconds = 30 -> 3 过期实例应该剔除的时间间隔,单位为毫秒,默认为60 * 1000 eureka.server.evictionIntervalTimerInMs = 60000 -> 6000(6s) Eureka服务器在接收到实例的最后一次发出的心跳后,需要等待多久才可以将此实例删除,默认为90s eureka.instance.leaseExpirationDurationInSeconds = 90 -> 9(s) 服务发现的时效性变成秒级,几秒钟可以感知服务的上线和下线 "},"pages/SpringCloud/1266003506066620430.html":{"url":"pages/SpringCloud/1266003506066620430.html","title":"说一下自己公司的服务注册中心怎么技术选型的?生产环境中应该怎么优化?","keywords":"","body":"服务注册,故障和发现的时效性是多长时间?注册中心最大能支撑多少服务实例? 如何部署的，几台机器，每台机器的配置如何，会用比较高配置的机器来做，8核16G，16核32G的高配置机器来搞，基本上可以做到每台机器每秒钟的请求支撑几千绝对没问题。 可用性如何来保证? 有没有做过一些优化，服务注册、故障以及发现的时效性，是否可以优化一下，用eureka的话，可以尝试一下，配合我们讲解的那些参数，优化一下时效性，服务上线、故障到发现是几秒钟的时效性。zk，一旦服务挂掉，zk感知到以及通知其他服务的时效性，服务注册到zk之后通知到其他服务的时效性，leader挂掉之后可用性是否会出现短暂的问题，为了去换取一致性。 "},"pages/SpringCloud/1266003506205032504.html":{"url":"pages/SpringCloud/1266003506205032504.html","title":"你们对网关的技术选型是怎么考虑的?能对比一下各种网关的优劣吗?","keywords":"","body":"网关的核心功能 动态路由：新开发某个服务，动态把请求路径和服务的映射关系热加载到网关里去；服务增减机器，网关自动热感知 灰度发布 授权认证 性能监控：每个API接口的耗时、成功率、QPS 系统日志 数据缓存 限流熔断 Zuul && Spring Cloud Gateway zuul是Netflix的产品，gateway是spring全家桶的亲儿子。zuul 更新维护不积极，所以gateway自己做了网关，就是为了替代zuul zuul 1.0和 2.0差别很大，1.0版本是基于servlet的同步阻塞io，2.0是基于netty通信的异步io，并发能力2.0版本大大提升。但是2.0文档相对不友好。gateway本身是基于netty通信的异步io，并发能力很强。 gateway文档齐全，架构清晰简单。容易上手，团队学习成本低，gateway有很多可以开箱即用的功能，非常方便。 gateway功能性更强，有非常多的predicate实现和filter，直接配置化就可以使用。同时还可以基于Redis记性流量控制。 "},"pages/SpringCloud/1266003506511216704.html":{"url":"pages/SpringCloud/1266003506511216704.html","title":"说说生产环境下,你们是怎么实现网关对服务的动态路由的?","keywords":"","body":"方案一: 数据库 如果映射关系写死，每次路由关系更改，就需要重启网关，影响会非常大，因此需要实现网关动态的更新路由关系。 可以使用第三方组件保存路由关系，然后在网关里面通过定时任务去定时刷新组件中保存的路由信息。 因此就可以基于mqsql去做路由关系的保存，然后通过后台管理系统去操作db，再由网关去定时查询db更新路由表，实现动态效果。Nginx（Kong、Nginx+Lua）：Nginx抗高并发的能力很强，少数几台机器部署一下，就可以抗很高的并发，精通Nginx源码，很难，c语言，很难说从Nginx内核层面去做一些二次开发和源码定制。 方案二: Config配置 将Spring Cloud Zuul的路由信息，配置在 Config Server 的env.yml中，将网关服务注册为Config Client，从Config Server获取路由信息。微服务架构的系统中，我们通常会使用轻量级的消息代理来构建一个共用的消息主题让系统中所有微服务实例都连接上来，由于该主题中产生的消息会被所有实例监听和消费，所以我们称它为消息总线。在总线上的各个实例都可以方便地广播一些需要让其他连接在该主题上的实例都知道的消息，例如配置信息的变更或者其他一些管理操作等。Bus就是Spring Cloud中的消息总线。 其他方案: Apollo, Redis... "},"pages/SpringCloud/1266003506809012225.html":{"url":"pages/SpringCloud/1266003506809012225.html","title":"如果网关需要抗每秒10万的高并发访问,你应该怎么对网关进行生产优化?","keywords":"","body":"方案 Zuul网关部署的是什么配置的机器，部署32核64G，对网关路由转发的请求，每秒抗个小几万请求是不成问题的，几台Zuul网关机器。每秒是1万请求，8核16G的机器部署Zuul网关，5台机器就够了。 "},"pages/SpringCloud/1266003506968395844.html":{"url":"pages/SpringCloud/1266003506968395844.html","title":"你们公司的网关是怎么技术选型的,假设有高并发场景?","keywords":"","body":"测试结果 实际压测经验，gateway包含鉴权、日志等业务操作。2C4G的机器两台。500TPS CPU才30% 左右。一般的系统，妥妥的没压力。如果需要更高并发。直接加机器配置即可。 "},"pages/SpringCloud/1266003507165528135.html":{"url":"pages/SpringCloud/1266003507165528135.html","title":"如果需要部署上万服务实例,现有的服务注册中心能否抗住?如何优化?","keywords":"","body":"服务注册中心结构图 核心思想 注册中心主从架构，分片存储服务注册表，服务按需主动拉取注册表，不用全量拉取/推送，避免反向通知瞬时高并发。 自研注意点 客户端 服务拉取: 不用全量拉取，按需拉取(有疑问，怎么设计按需拉取)。还需要一个用于校验拉取增量数据之后数据是否完整的过程。 心跳发送 服务下线 服务端 服务注册: 服务注册表注意读写高并发控制，保证线程安全，也要降低锁的争用。 健康检查: 单位时间内，如果所注册服务没有续约，则要将其下线。 集群同步: 根据具体业务需求，制定合适的集群架构方案，保证吞吐量。 "},"pages/SpringCloud/1266003507534626867.html":{"url":"pages/SpringCloud/1266003507534626867.html","title":"你们是如何基于网关实现灰度发布的?说说你们的灰度发布方案?","keywords":"","body":"解决思路 通过网关(Zuul, ZuulFilter)的发布开关，把少量流量导入到一两台部署了新版本的服务器上，进行测试，这个就叫灰度发布。 开发流程 准备一个数据库和一个表（也可以用Apollo配置中心、Redis、ZooKeeper，其实都可以），放一个灰度发布启用表，存入具体uri以及是否灰度发布的一些信息，然后搞一张映射表。 启动1个线程每隔多少时间就去刷新灰度发布表的数据写到ConcurrentHashMap里面。 接着搞一个filter继承ZuulFilter，重写里面几个函数，其中shouldFilter根据返回值去判断执不执行run。 因此再should里面遍历map去看这次请求是否有开启灰度发布，如果有就执行run里面的逻辑，就自定义一些分发逻辑，这里用的时通过version去判断和分发。 发布流程 首先通过后台系统更改灰度发布标识，后台线程更新了map后，就会去执行根据version分发的策略，将少部分流量分发到new的服务上，然后监控和对应的后台，如果没问题，就更改为current，全线上线，最后将灰度发布表示改回来。 "},"pages/SpringCloud/1266003507681427533.html":{"url":"pages/SpringCloud/1266003507681427533.html","title":"说说你们一个服务从开发到上线,服务注册 网关路由 服务调用的流程?","keywords":"","body":"调用流程 开发了一个新的服务，线上部署，配合网关动态路由的功能，在网关里配置一下路径和新服务的映射关系，此时请求过来直接就可以走到新的服务里去。对已有服务进行迭代和开发，新版本，灰度发布，新版本部署少数几台机器，通过一个界面，开启这个服务的灰度发布，此时zuul filter启用，按照你的规则，把少量的流量打入到新版本部署的机器上去。观察一下少量流量在新版本的机器上运行是否正常。版本改成current，全量机器部署，关闭灰度发布功能，网关就会把流量均匀分发给那个服务了。 "},"pages/SpringCloud/1266003507773702201.html":{"url":"pages/SpringCloud/1266003507773702201.html","title":"画一下你们系统架构的整体架构图?说说各个服务在生产环境怎么部署的?","keywords":"","body":"核心 服务框架,注册中心,网关 部署 中小型系统，拆分10-20个微服务。大型互联网公司，一般几百个，几千个微服务。 中小型，一般2-3台机器足够，把服务上线，服务发现优化到极致。 服务上线：注册表多级缓存同步至1秒，拉取频率降低至1秒。 服务心跳：1秒报1次。 故障发现：1秒检查一次，2，3秒没有认为没有故障等。 服务注册中心没有压力，服务注册中心部署2台机器，每台4C8G，高可用，每秒轻松几百请求，甚至上千。前提是数据库SQL别写的太烂。 网关机器配置稍微高一些，4C8G，一台扛每秒几百个请求，部署3~4台，保证每台网关机器压力较小，进一步保证可靠性。 "},"pages/SpringCloud/1266003507886948414.html":{"url":"pages/SpringCloud/1266003507886948414.html","title":"你们系统每天有多大的访问量?每个服务高峰QPS多少?压测过服务最大QPS吗?","keywords":"","body":"解决思路 每天服务多少请求量，高峰每秒qps，在代码里稍微加一些metrics代码，对自己运行过程中各种请求量，每秒请求量，成功次数，失败次数，在内存里直接做一些计数。在负责的核心服务里，核心接口，开发一个简单的metric统计机制，AtomicLong，保证原则性，并发数据统计准确。每个接口被调用时，可以对每个接口每分钟做一个metric统计，每个接口每天统计计数。再通过Log4j, logback等日志组件，把次数直接打印到日志文件，统计出高峰期每秒系统被访问的次数，每条每个接口访问量。 响应延时 计算一下每个接口从请求到执行完毕，需要耗费多长时间，算一下每个接口平均的请求延时，TP99，TP95，TP90，TP50，TP99，99%的请求耗费的时间在100ms以内，但是1%的请求可能耗费的时间在100ms以上TP99 = 100ms TP95 = 50ms，95%的请求耗费的时间多在50ms以内，但是5%的请求耗费的时间在50ms以上压测工具，java压测工具，开源的可以用的，模拟出来同时有多少用户发起多少请求，每秒发起1000请求能抗住吗？每秒钟发起2000请求能抗住吗？假设你的系统每秒钟最多抗800请求，如果你的压测工具每秒发起了1000个请求，此时会发现最多只有800个请求同时可以被处理，剩余200个请求需要进行排队被阻塞住了，表示你这个系统每秒钟最多抗800个请求。 "},"pages/SpringCloud/1266003508033749072.html":{"url":"pages/SpringCloud/1266003508033749072.html","title":"如果系统访问量比现在增加10倍,你们考虑过系统的扩容方案吗?","keywords":"","body":"解决方案 网关直接多部署10倍的机器即可，前面的Nginx做会负载均衡，把流量均匀分发给各个网关机器。服务扩容，都很简单的，多加机器，部署启动，自动注册到注册中心去，此时其他服务会自动感知到你的服务多加了一些机器。服务实例变多了10倍，此时几十个服务实例，几百个服务实例，对eureka机器会造成每秒几百请求，没问题，eureka机器，8核16G的配置，单机抗上千请求，很轻松。数据库本来是每秒几百请求，10倍，每秒高峰期是三四千请求，横向扩容很麻烦，此时可以考虑给单个数据库部署的机器提高配置，32核128G高配物理机，每秒钟抗几千请求问题不大。 总结(最基本的操作就是扩容) 网关: 横向加机器。 注册中心: 纵向升配置。 数据库: 纵向升配置。 当然还有很多其他专门针对分布式，高并发的优化和操作，不过加机器都是最简单直接的。 "},"pages/SpringCloud/1266003508155383820.html":{"url":"pages/SpringCloud/1266003508155383820.html","title":"你们生产环境的服务是怎么配置超时和重试参数的?为什么要这样配置?","keywords":"","body":"背景 Spring Cloud生产优化，系统第一次启动的时候，调用请求经常出现timeout。 原因 每个服务第一次被请求的时候，他会去初始化一个Ribbon的组件，初始化这些组件需要耗费一定的时间，所以很容易会导致超时。 解决方案 让每个服务启动的时候就直接初始化Ribbon相关的组件，避免第一次请求的时候初始化。 ribbon: eager-load: enabled: true zuul: ribbon: eager-load: enabled: true feign: hystrix: enabled: false "},"pages/SpringCloud/1266003508289601556.html":{"url":"pages/SpringCloud/1266003508289601556.html","title":"如果出现服务请求重试,会不会出现类似重复下单的问题?","keywords":"","body":"答案 可能会 场景 订单服务 -> 创建订单 -> 库存服务 -> 扣减库存 -> wms服务 -> 通知发货 -> 积分服务 -> 增加积分 原因 订单服务调用库存服务的时候，因为网络抖动，请求超时了，超过了秒钟，此时订单服务会重试，再次调用一下库存服务，发送一模一样的请求过去。比如说，订单服务第一次请求库存服务，库存服务其实是把扣减库存的业务逻辑执行成功了，只不过网络问题，导致响应迟迟没有返回给订单服务，可能在1.2s之后返回了响应给订单服务。订单服务就认为请求超时了，他就再次发送了一个一模一样的请求给库存服务，库存服务可能会再次对库存进行扣减。 "},"pages/SpringCloud/1266003508415430739.html":{"url":"pages/SpringCloud/1266003508415430739.html","title":"对于核心接口的防重幂等性,你们是怎么设计的?怎么防止重复下单问题?","keywords":"","body":"方案 数据库唯一索引 基于Redis实现幂等性防重 原因 核心接口，幂等性都是自己保证，对应Create操作，通过DB唯一索引来保证；对于Update操作，建议在核心接口基于业务逻辑，配合Redis，来保证幂等性。比如库存，定制化的针对接口开发幂等性的机制，比如说一旦库存扣减成功之后，就立马要写一条数据到redis里去，order_id_11356_stock_deduct，写入redis中，如果写入成功，就说明之前这个订单的库存扣减，没人执行过。但是如果此时有一些重试的请求过来了，调用了你的库存扣减接口，他同时也进行了库存的扣减，但是他用同样的一个key，order_id_11356_stock_deduct，写入redis中，此时会发现已经有人写过key，key已经存在了。此时你就应该直接对刚才的库存扣减逻辑做一个反向的回滚逻辑，update product_stock set stock = stock - 100，update product_stock set stock = stock + 100，反向逻辑，回滚自己，避免重复扣减库存。 "},"pages/SpringCloud/1266003508566425662.html":{"url":"pages/SpringCloud/1266003508566425662.html","title":"画一下你们电商系统的核心交易链路图,说说分布式架构下存在什么问题?","keywords":"","body":"问题 分布式事务，分布式锁 原因 分布式系统，事务 -> 分布式事务，锁 -> 分布式锁 电商核心流程 订单服务 -> 创建订单 -> 库存服务 -> 扣减库存 -> 积分服务 -> 增加积分 -> 仓储服务 -> 通知发货 "},"pages/SpringCloud/1266003508725809155.html":{"url":"pages/SpringCloud/1266003508725809155.html","title":"针对电商核心交易链路,你们是怎么设计分布式事务技术方案的?","keywords":"","body":"方案 TCC 订单服务、库存服务、积分服务 -> 绑定为一个TCC事务 撤销刚才创建订单时，回滚刚才扣减库存和增加积分 可靠消息最终一致性 可以去发送一个请求给消息中间件，由中间件保证一定会把消息交给下游的库存服务去扣减库存，仓储服务去通知发货等，如果这个过程中有消息发送失败，则可靠消息中间件应该保证不停的重试投递消息。 原因 一个要求强一致，一个要求最终一致。强一致主要用于核心模块，例如交易/订单等。最终一致一般用于边缘模块例如库存，通过mq去通知，保证最终一致性，也可以业务解耦。 "},"pages/SpringCloud/1266003508860026894.html":{"url":"pages/SpringCloud/1266003508860026894.html","title":"对于TCC事务,最终一致性事务的技术选型,你们是怎么做的?如何调研的?","keywords":"","body":"选型方案 TCC阿里开源了分布式事务框架，fescar，seata。seata类似TCC事务，经历过阿里生产环境大量考验的框架。支持Dubbo，Spring Cloud。 可靠消息最终一致性基于ActiveMQ，RabbitMQ, RocketMQ等，自己开发一个可靠消息服务。收到消息之后，尝试投递到MQ，如果投递失败，重试投递。现在大量用RocketMQ，作为MQ中间件，提供了分布式事务支持，已经把可靠消息服务需要实现的功能逻辑已经做好了。 "},"pages/SpringCloud/1266003508860026900.html":{"url":"pages/SpringCloud/1266003508860026900.html","title":"你们公司的核心链路是否有事务问题?分布式事务方案?","keywords":"","body":"分布式事务实现的几种方案 两阶段提交方案/XA方案 这种分布式事务方案，比较适合单块应用里。跨多个库的分布式事务，由于因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。如果要玩儿，那么基于 Spring + JTA 就可以搞定。这个方案，很少用，一般来说某个系统内部如果出现跨多个库的这么一个操作，是不合规的。如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库。 TCC(Try, Confirm, Cancel)方案 使用补偿机制,分三个阶段 Try阶段: 这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留。 Confirm阶段: 这个阶段说的是在各个服务中执行实际的操作。 Cancel阶段: 如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。(把那些执行成功的回滚) 缺点与业务耦合太紧，事务回滚严重依赖自己的写的代码来回滚和补偿。 适用场景与钱打交道的场景，支付，交易。需要TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性。 本地消息表 流程 A系统在处理本地事务的同时插入一条数据到消费表。 然后A系统将这个消息发送到MQ。 B系统接收到消息后，在一个事务里，先往自己本地消息表插入一条记录，然后执行业务处理；如果这个消息已经被处理过，则消息表插入失败，事务回滚，保证不会重复处理消息。 如果B系统处理成功，则更新自己本地消费表状态和A系统消费表状态。 如果B系统处理失败，则不会更新消息表状态，A系统会定期扫描自己的消息表，如果有未处理的消息，会再次发送到MQ中，让B系统再次处理。 这个方案保证最终一致性，哪怕B系统事务失败，但A会不断重发消息，直到B成功为止。 缺点严重依赖数据库的消息表来管理事务。高并发场景怎么办，访问消息表瓶颈，不容易扩展。 可靠消息最终一致性方案(国内互联网流行) 定义不用本地消费表，直接基于MQ来实现事务。比如阿里的RocketMQ就支持消息事务。 流程 A系统发一个prepared消息到MQ，如果这个消息失败则直接取消操作。 如果这个prepared消息发送成功，则执行本地事务，如果事务执行成功就发送confirm消息到MQ，如果失败就告诉MQ回滚消息。 如果发送了confirm消息，则MQ让B系统消费这条confirm消息，然后执行本地事务。 MQ会定时轮询所有prepared消息，然后回调A系统接口，查看这个消息是回滚还是要重发一次confirm消息。一般情况A系统查看本地事务是否执行成功，如果回滚了，则消息也回滚。避免本地事务执行成功，而confirm消息发送失败。 如果B系统事务失败，则不断重试直到成功。如果实在不行，则想办法通知A系统回滚，或发送报警由人工来手动回滚或补偿。 你们公司怎么处理分布式事务? 如果是严格资金场景，用的TCC方案； 如果是订单插入之后要调用库存服务更新库存，可以用可靠消息最终一致性方案。一般情况不应该使用分布式事务，代码复杂，性能太差。普通的A调用B，C，D，根本不用做分布式事务。一般就是监控(发邮件，发短信报警)，记录日志(一旦出错，完整的日志)，事后快速的定位，排查和解决方案，临时修复数据。比做分布式事务的成本要低很多。 CAP理论 定义 C: Consistency一致性 A: Availability可用性 P: Partition tolerance分区容错性 定理一个分布式系统不可能同时满足CAP三个要求，最多只能同时满足其中两项 选择 CA放弃分区容错性，所有数据放一个节点，退回单机模式。 CP放弃可用性，一旦网络故障，受影响服务需要等待恢复时间，系统处于不可用状态。 AP放弃一致性，这里指放弃强一致性，确保最终一致性。大多数分布式系统的选择。 BASE理论 定义 BASE: Base Available(基本可用) Soft state(软状态) Eventually consistent(最终一致性) BASE是对CAP一致性和可用性权衡的结果 基本可用指分布式系统出现不可预知故障时，允许损失部分可用性，响应时间合理延长，服务上适当降级。 软状态允许分布式系统中的数据处于中间状态，允许各节点数据同步时存在延时。 最终一致性允许系统中所有数据副本，在经过一段时间同步后，最终能够达到一个一致的状态。不需要实时保证系统的数据一致性。 两阶段提交(2PC) 数据库支持2PC，又叫XA transactions。MySQL从5.5版，Oracle从7版，SQL Server 2005开始支持。 XA是一个两阶段提交协议，协议分两阶段 第一阶段: 事务协调器要求每个涉及到事务的数据库预提交/投票(pre commit)此操作，并反映是否可以提交。 第二阶段: 事务协调器要求每个数据库提交数据。 如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务中的那部分信息。 预提交/投票阶段 事务协调者(事务管理器)给每个参与者(资源管理器)发送 Prepare 消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的 redo 和 undo 日志，但不提交。 提交阶段 如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源) 2PC缺点 同步阻塞 执行过程中，所有节点都是事务阻塞的。 单点故障 协调者正常，参与者宕机 协调者无法收集到所有参与者反馈，会陷入阻塞。 协调者宕机，参与者正常 无论哪个阶段，协调者挂了，则无法发送提交请求，参与者会陷入阻塞。 协调者与参与者都宕机发生在第一阶段，由于参与者都没有真正commit，则可以重新选出协调者，再执行2PC。 发生在第二阶段，并且挂了的参与者在挂之前并没有收到协调者指令。这种情况，新的协调者重新执行2PC。 发生在第二阶段，有部分参与者已经commit，产生数据不一致(脑裂)。2PC无法解决！ 协调者发出commit后挂了，唯一接收到这条消息的参与者同时也挂了。则即使选举出新的协调者，这条事务状态也不确定，没人知道事务是否被已经提交。 三阶段提交(3PC) 改进点 同时在协调者和参与者引入超时机制。 在2PC的第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与者状态时一致的。 三个阶段 CanCommit阶段2PC的第一阶段是本地事务执行结束后，最后不Commit。3PC的CanCommit是指尝试获取数据库锁，如果可以就返回Yes，进入预备状态，否则返回No。 PreCommit阶段如果上一阶段所有参与者都返回Yes，则进入PreCommit阶段进行事务预提交。这里协调者和参与者都引入超时机制。假如有任何一个参与者向协调者发送No，或者等待超时之后，协调者还没有收到参与者响应，则执行事务中断。 DoCommit阶段 真正进行事务提交,包括: 协调者发送提交请求； 参与者提交事务； 参会者响应反馈(向协调者发送ACK)； 协调者确定事务完成。 TCC事务 定义 Try/Confirm/Cancel，可归纳为补偿型事务。 Try针对业务操作做检测(一致性)和资源预留(隔离性)。 Confirm对业务进行确认提交。默认Try成功并开始执行Confirm，Confirm一定成功。 Cancel在业务执行错误，需要回滚时执行业务补偿，释放预留资源。 核心思想针对每个操作，都有有一个与其对应的确认和补偿(撤销)操作。 优点 解决协调者单点故障的问题。 引入超时后进行补偿，并不会锁定整个资源，事务颗粒的变小。 通过补偿机制，由业务操作管理数据一致性。 缺点开发复杂，每个目标字段都需要一个预留(冻结)字段，需要写很多补偿代码，在一些业务场景不太好定义和处理。 使用场景钱，金融等对事务要求非常高的核心业务场景。 总结 TCC使用于大部分接口是同步调用的场景，要么一起成功，要么一起回滚。但在实际系统中，可能服务之间的调用时异步的，通过消息中间件。 "},"pages/SpringCloud/1266003509036187661.html":{"url":"pages/SpringCloud/1266003509036187661.html","title":"在搭建的电商系统里,落地开发对交易链路的TCC分布式事务方案?","keywords":"","body":"图解 方案 seata (https://github.com/seata/seata-samples.git) 特点 自动回滚数据库事务 原因 把seata所有的示例代码拷贝下来，里面提供的例子就是跟我们说的电商的核心例子是类似的.然后先要下载一个seata-server到本地，在这里下载：https://github.com/seata/seata/releases，然后启动起来，这是分布式事务管理中心，负责维护每一个分布式事务的状态，触发分布式事务的提交和回滚。 "},"pages/SpringCloud/1266003509468201025.html":{"url":"pages/SpringCloud/1266003509468201025.html","title":"你能说说一个TCC分布式事务框架的核心架构原理吗?","keywords":"","body":"Seata架构原理 https://github.com/seata/seata Seata中角色 Transaction Coordinator（TC）:协调器，单独的一个server。维护全局和分支事务的状态，驱动全局事务的提交或回滚。 Transaction Manager(TM)：全局事务的发起者，负责开始/提交/回滚一个全局事务。（对应订单服务） Resource Manager(RM)：管理分支事务（注册分支事务/状态/提交/回滚），并负责与TC通讯。 整个使用seata进行分布式事务管理的生命周期 TM向TC发起全局事务，TC返回XID作为标识。 XID通过调用链传播。 RM将本地的事务注册到TC中表示为XID的全局事务中，成为一个分支事务。 再由TM向TC请求标识为XID的全局事务提交/回滚。 最终，由TC去驱动所有的分支事务提交/回滚。 "},"pages/SpringCloud/1266003509602418771.html":{"url":"pages/SpringCloud/1266003509602418771.html","title":"现有的TCC事务方案的性能瓶颈在哪里?能支撑高并发交易场景吗?如何优化?","keywords":"","body":"瓶颈 使用分布式事务主要是保证核心链路要么全部成功，要么全部失败。当然也会带来一些性能的开销。seata模型里面频繁的网络通信，以及对应事务的状态持久化的IO等等。如果需要支撑高并发，那么TC服务也需要横向扩容。相应的，对于TC背后的DB也需要进行优化。 优化 "},"pages/SpringCloud/1266003509698887696.html":{"url":"pages/SpringCloud/1266003509698887696.html","title":"你了解RocketMQ对分布式事务支持的底层实现原理吗?","keywords":"","body":"图解 原理 核心链路使用seata这种类似于TCC的事务，而像wms这种相当于是分支链路，可以通过MQ进行解耦。但是通过MQ解耦也会带来一些问题，例如消息丢失，消息重复等等问题，因此也需要进行最终一致性的保证。 结合整个订单接口服务，分为两个支付链路，一个是核心链路（订单业务），一个是非核心链路（wms） 整个流程。先向RocketMQ发送half msg，然后调用核心链路。核心链路要是返回失败，就会走失败的逻辑：退款，更改订单状态为取消，再给rocketmq发送callback废弃掉刚才的消息。如果成功，就commit msg让消费者可以消费。如果在等待期间，一直没有callback/commit那么mq就会走回调查询具体的状态。最终消费者接收到消息后，消费完成就回复mq一个ack， 如果消费失败了，mq就会重新投递或者换一个服务投递。使用rocketmq的half msg机制，可以实现这一套固定模式的最终一致性，很完善。 这个将wms的操作放在核心链路前面的这个问题，是为了提升整个订单接口服务的效率，因为需要保证最终一致性，那么必然会有消息生产者对MQ的一些操作，包括重试，ack等等，如果将这些逻辑全部都放在核心链路执行完成后再去一一完成，那么可能会耗费一些时间。而通过rocketmq这个模式，可以通过half msg的支持，来将整个与mq的交互过程拆解掉，从而提升效率。 "},"pages/SpringCloud/1266003509891825709.html":{"url":"pages/SpringCloud/1266003509891825709.html","title":"如果公司没有RocketMQ中间件,那你们如何实现最终一致性事务?","keywords":"","body":"方案 基于数据库自己开发一个可靠消息服务。接受上游Producer发送的haf msg, 存入DB，返回响应。本地可靠消息服务启动定时扫描本地DB的half msg，超过一定时间没有commit/rollback就回调Producer接口，确认本地事务是否成功，获取commit/rollback。如果消息commit就发送消息给下游服务或者发给RabbitMQ/Kafka/ActiveMQ，下游服务消费后，回调可靠消息服务接口进行ack，如果没有收到ack，重发消息给下游服务。 "},"pages/SpringCloud/1266003520390168640.html":{"url":"pages/SpringCloud/1266003520390168640.html","title":"对分布式系统进行核心链路追踪的时候,链路id是怎么管理...","keywords":"","body":"背景 通过增加应用层的标记对服务化中的请求和响应建立联系，例如通过HTTP协议头携带标记信息，标记信息包括标示调用链的唯一ID，这里叫作TraceID，以及标示调用层次和顺序的SpanID和ParentSpanID。 调用信息 调用端或者被调用端的ID、系统ID；本次请求的TraceID、SpanID和ParentSpanID；时间戳、调用的方法名称及远程调用信息的类型，等等。 过程 前端接收用户请求后会为用户分配一个TraceID，在内部服务调用时，会通过应用层的协议将TraceID传递到下层服务，直到整个调用链的每个节点都拥有TraceID，这样在系统出现问题时，可以使用这个唯一TraceID迅速问题发生的节点。 TraceID解决了系统串联的问题，但是我们无法标识和恢复这些请求和响应调用时的顺序和层级关系。因此我们需要附加的信息在系统之间的请求和响应消息中传递，它就是SpanID，这里SpanID包含SpanID和ParentSpanIDSpanID和ParentSpanID组合在一起就可以表示一个树形的调用关系，SpanID表示当前为一个调用节点，ParentSpanID表示这个调用节点的父节点。 当系统出现故障时 通过TraceID把一整条调用链的所有调用信息收集到一个集合中，包括请求和响应 通过SpanID和ParentSpanID恢复树形的调用树，ParentSpanID为-1的节点为根节点 识别调用链中出错或超时的节点，做出标记 把恢复的调用树和出错的节点信息通过某种图形显示到UI界面上。 如何产生SpanID 使用随机数产生SpanID，理论上有可能重复，但是由于64位长整型，重复的可能性微乎其微，并且本地生成随机数的效率高于其他方法。 使用分布式的全局唯一的流水号生成方式，可参考互联网发好器Vesta。 每个SpanID包含所有父亲及前辈节点的SpanID，使用圆点符号作为分隔符，不再需要ParentSpanID字段，这种方案实现起来简单，但是如果调用链有太多的节点和层次时，SpanID会携带太多的冗余信息，导致服务间调用的性能下降。 "},"pages/SpringCloud/1266003520717324352.html":{"url":"pages/SpringCloud/1266003520717324352.html","title":"唯一id生成机制中的snowflake算法的时钟回拨问题...","keywords":"","body":"定义 SnowFlake算法生成id的结果是一个64bit大小的整数, 其中的41位时间戳部分依赖服务器的时间, 当服务器发生时钟回拨时, 在开源的实现中不可避免的会出现报错. 关于解决时钟回拨的问题, 网上已有各种方案, 比如适当等待直到时间被追回, 在内存中保存一段时间内使用过的最大序列号 方案 首先, SnowFlake的末尾12位是序列号, 用来记录同一毫秒内产生的不同id, 同一毫秒总共可以产生4096个id, 每一毫秒的序列号都是从0这个基础序列号开始递增假设我们的业务系统在单机上的QPS为3w/s, 那么其实平均每毫秒只需要产生30个id即可, 远没有达到设计的4096, 也就是说通常情况下序列号的使用都是处在一个低水位, 当发生时钟回拨的时候, 这些尚未被使用的序号就可以派上用场了.因此, 可以对给定的基础序列号稍加修改, 后面每发生一次时钟回拨就将基础序列号加上指定的步长, 例如开始时是从0递增, 发生一次时钟回拨后从1024开始递增, 再发生一次时钟回拨则从2048递增, 这样还能够满足3次的时钟回拨到同一时间点(发生这种操作就有点扯了)。 "},"pages/SpringCloud/1266003520981565524.html":{"url":"pages/SpringCloud/1266003520981565524.html","title":"实现灰度发布的时候,网关是可以灰度了,可是Dubbo服务...","keywords":"","body":"背景 Dubbo提供的Router，在进行负载均衡前，根据路由规则对服务提供者列表进行筛选。 定义 灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 "},"pages/SpringCloud/1266003521241612302.html":{"url":"pages/SpringCloud/1266003521241612302.html","title":"除了常见服务注册中心之外,你觉得Redis能作为服务注...","keywords":"","body":"方式 redis 作为dubbo的注册中心，实现的功能跟 zk相同，但是内部的实现机制大相径庭，因为zk 有临时节点，服务端在zk 中创建临时节点会一直保持连接，如果服务器出现崩溃，自动断连，而redis 则要靠主服务器进行定时轮询。 "},"pages/SpringCloud/1266003521409384470.html":{"url":"pages/SpringCloud/1266003521409384470.html","title":"我们一般到底用Zookeeper来干什么事儿?","keywords":"","body":"数据发布与订阅 典型场景描述 发布与订阅即所谓的配置管理，顾名思义就是将数据发布到zk节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，地址列表等就非常适合使用。 应用中的具体使用 索引信息和集群中机器节点状态存放在zk的一些指定节点，供各个客户端订阅使用。 系统日志（经过处理后的）存储，这些日志通常2-3天后被清除。 应用中用到的一些配置信息集中管理，在应用启动的时候主动来获取一次，并且在节点上注册一个Watcher，以后每次配置有更新，实时通知到应用，获取最新配置信息。 业务逻辑中需要用到的一些全局变量，比如一些消息中间件的消息队列通常有个offset，这个offset存放在zk上，这样集群中每个发送者都能知道当前的发送进度。 系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息。以前通常是暴露出接口，例如JMX接口，有了zk后，只要将这些信息存放到zk节点上即可。 Name Service(命名服务) 典型场景描述这个主要是作为分布式命名服务，通过调用zk的create node api，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。 分布通知/协调 典型场景描述 ZooKeeper 中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使用方法通常是不同系统都对 ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那么另一个系统能 够收到通知，并作出相应处理。 应用中的具体使用 另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过zk上某个节点关联，大大减少系统耦合。 另一种系统调度模式：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改 了ZK上某些节点的状态，而zk就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。 另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合。 分布式锁 典型场景描述分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性，即用户只要完全相信每时每刻，zk集群中任意节点（一个zk server）上的相同znode的数据是一定是相同的。锁服务可以分为两类，一个是保持独占，另一个是控制时序。所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指 定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。 分布式队列 典型场景描述 队列方面，我目前感觉有两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。对于第二种先进先出队列，和分布式锁服务中的控制时序场景基本原理一致，这里不再赘述。第二种队列其实是在FIFO队列的基础上作了一个增强。通常可以在 /queue 这个znode下预先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，决定是否可以开始执行 了。这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。 集群管理 典型场景描述 集群机器监控这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群 机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题：(1)集群中机器有变动的时候，牵连修改的东西比较多。(2)有一定的延时。利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统：a. 客户端在节点 x 上注册一个Watcher，那么如果 x 的子节点变化了，会通知该客户端。b. 创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。例如，监控系统在 /clusterServers 节点上注册一个Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。 Master选举(zookeeper中最为经典的使用场景)在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行， 其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。另外，这种场景演化一下，就是动态Master选举。这就要用到 EPHEMERAL_SEQUENTIAL类型节点的特性了。上文中提到，所有客户端创建请求，最终只有一个能够创建成功。在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终 在ZK上创建结果的一种可能情况是这样： /currentMaster/{sessionId}-1 , /currentMaster/{sessionId}-2 , /currentMaster/{sessionId}-3 ….. 每次选取序列号最小的那个机器作为Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。 应用中的具体使用 在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的Master来进行全量索引的生成， 然后同步到集群中其它机器。 另外，Master选举的容灾措施是，可以随时进行手动指定master，就是说应用在zk在无法获取master信息时，可以通过比如http方式，向一个地方获取master。 "},"pages/SpringCloud/1266003521564573786.html":{"url":"pages/SpringCloud/1266003521564573786.html","title":"有哪些开源的分布式系统中使用了Zookeeper?","keywords":"","body":"系统 Hadoop、HBase、Kafka "},"pages/SpringCloud/1266003521728151639.html":{"url":"pages/SpringCloud/1266003521728151639.html","title":"为什么我们在分布式系统架构中需要使用Zookeeper集群?","keywords":"","body":"单点问题 单点问题是分布式环境中最常见也是最经典的问题之一，在很多分布式系统中都会存在这样的单点问题。具体地说，单点问题是指在一个分布式系统中，如果某一个组件出现故障就会引起整个系统的可用性大大下降甚至是处于瘫痪状态，那么我们就认为该组件存在单点问题。ZooKeeper 确实已经很好地解决了单点问题。我们已经了解到，基于“过半”设计原则，ZooKeeper 在运行期间，集群中至少有过半的机器保存了最新的数据。因此，只要集群中超过半数的机器还能够正常工作，整个集群就能够对外提供服务。 容灾 在进行 ZooKeeper 的容灾方案设计过程中，我们要充分考虑到“过半原则”。也就是说，无论发生什么情况，我们必须保证 ZooKeeper 集群中有超过半数的机器能够正常工作。"},"pages/SpringCloud/1266003521937866845.html":{"url":"pages/SpringCloud/1266003521937866845.html","title":"Zookeeper为了满足分布式系统的需求要有哪些特点?","keywords":"","body":"构造高可用集群 zookeeper的选举模式保证了集群的相对稳定性，从而使得集群是高可用的。 集群全局配置文件管理 即统一资源配置，在一个偌大的集群环境中，假设你需要对该集群的配置文件作修改，假设集群很庞大，手动去修改是一件不太现实的事，不但费时费力，还极有可能造成差错，zookeeper可以自动帮我们完成配置文件的分发，既高效又准确。 发布与订阅 支持服务发布与状态监听。 分布式锁 在集群环境下，同样会存在对资源的竞争，zookeeper提供了分布式锁实现了同步。 保证数据强一致性 在集群环境下，对集群中某个节点的数据的改变，会被zookeeper同步到其他机器上。 额外补充 cversion: 子节点版本号 ephemeralOwner: 用于判断节点是持久的还是临时的 "},"pages/SpringCloud/1266003522118221855.html":{"url":"pages/SpringCloud/1266003522118221855.html","title":"Zookeeper集群的三种角色: Leader,Follower,Observer","keywords":"","body":"Zookeeper服务器的三种节点类型 群首(leader)，追随者(follower)，观察者(observer) Leader Leader作为整个ZooKeeper集群的主节点，负责响应所有对ZooKeeper状态变更的请求。它会将每个状态更新请求进行排序和编号，以便保证整个集群内部消息处理的FIFO。 Follower Follower的逻辑就比较简单了。除了响应本服务器上的读请求外，follower还要处理leader的提议，并在leader提交该提议时在本地也进行提交。 Observer 如果ZooKeeper集群的读取负载很高，或者客户端多到跨机房，可以设置一些observer服务器，以提高读取的吞吐量。Observer和Follower比较相似，只有一些小区别：首先observer不属于法定人数，即不参加选举也不响应提议；其次是observer不需要将事务持久化到磁盘，一旦observer被重启，需要从leader重新同步整个名字空间。"},"pages/SpringCloud/1266003522411823194.html":{"url":"pages/SpringCloud/1266003522411823194.html","title":"客户端与Zookeeper之间的长连接和会话是什么?","keywords":"","body":"会话概述 在ZooKeeper中，客户端和服务端建立连接后，会话随之建立，生成一个全局唯一的会话ID(Session ID)。服务器和客户端之间维持的是一个长连接，在SESSION_TIMEOUT时间内，服务器会确定客户端是否正常连接(客户端会定时向服务器发送heart_beat，服务器重置下次SESSION_TIMEOUT时间)。因此，在正常情况下，Session一直有效，并且ZK集群所有机器上都保存这个Session信息。在出现网络或其它问题情况下（例如客户端所连接的那台ZK机器挂了，或是其它原因的网络闪断），客户端与当前连接的那台服务器之间连接断了，这个时候客户端会主动在地址列表（实例化ZK对象的时候传入构造方法的那个参数connectString）中选择新的地址进行连接。"},"pages/SpringCloud/1266003524215373909.html":{"url":"pages/SpringCloud/1266003524215373909.html","title":"为什么网关Zuul之前还要配置Nginx?","keywords":"","body":"原因 Nginx反向代理，软负载，把请求均匀负载到多台Zuul的机器上。LVS和Nginx处于不同的负载维度，主要是运维工程师负责管理。数据库，MYSQL，16C32G，物理机最佳，平时扛每秒几百请求，高峰期最多每秒扛三四千请求。扛几千请求时机器会负载很高，CPU，IO，网络负载很高。DBA在优化一下。 "},"pages/SpringCloud/1266003524362174475.html":{"url":"pages/SpringCloud/1266003524362174475.html","title":"Dubbo用ZooKeeper,Spring Cloud用Eureka作为各种的注册中心,为什么要这样设计?","keywords":"","body":"背景 著名的CAP理论指出，一个分布式系统不可能同时满足C(一致性)、A(可用性)和P(分区容错性)。由于分区容错性在是分布式系统中必须要保证的，因此我们只能在A和C之间进行权衡。在此Zookeeper保证的是CP, 而Eureka则是AP。 Zookeeper的设计理念就是分布式协调服务，保证数据（配置数据，状态数据）在多个服务系统之间保证一致性，这也不难看出Zookeeper是属于CP特性（Zookeeper的核心算法是Zab，保证分布式系统下，数据如何在多个服务之间保证数据同步）。Eureka是吸取Zookeeper问题的经验，先保证可用性。 Zookeeper作为服务发现的问题 对于服务发现而言，就是返回了包含不及时的信息结果也比什么都不返回要好！宁可返回某个服务5分钟之前在哪几个服务上可用的信息，也不能因为暂时的网络故障而找不到可用的服务器而不返回结果。Zookeeper中，如果在同一个网络分区(partition)的节点数(nodes)数达不到Zookeeper选取leader节点的法定人数时，它们会从zookeeper中断开，同时也就不能提供服务发现了。 ZooKeeper三机房容灾5节点部署结构 当同机房的ZK注册中心不可用，应用服务svcB无法注册到同机房ZK，就会访问ZK集群的其他节点，上图由于出现了网络分区故障，机房3无法与其他机房通信,所以svcB不能注册到任何ZK上，而且应用服务svcA也无法访问任何ZK，无法调用svcB；此时，当机房3出现网络分区(Network Partitioned)的时候，即机房3在网络上成了孤岛，我们知道虽然整体 ZooKeeper 服务是可用的，但是机房3的节点ZK5是不可写的，因为联系不上 Leader。因为机房3节点ZK5不可写，这时候机房3的应用服务 svcB 是不可以新部署，重新启动，扩容或者缩容的，但是站在网络和服务调用的角度看，机房3的 svcA虽然无法调用机房1和机房2的 svcB,但是与机房3的svcB之间的网络明明是 OK 的啊，为什么不让我调用本机房的服务？现在因为注册中心自身为了保脑裂(P)下的数据一致性（C）而放弃了可用性，导致了同机房的服务之间出现了无法调用，这是绝对不允许的！可以说在实践中，注册中心不能因为自身的任何原因破坏服务之间本身的可连通性。 "},"pages/SpringCloud/1266003524819353634.html":{"url":"pages/SpringCloud/1266003524819353634.html","title":"Eureka原理?Eureka对等怎么同步?路由策略?","keywords":"","body":"图解 分布式系统数据在多个副本之间的复制方式 主从复制(Master-Slave) 对等复制(Peer to Peer)[Eureka] 同步过程 Eureka Server本身依赖了Eureka Client，也就是每个Eureka Server是作为其他Eureka Server的Client。Eureka Server启动后，会通过Eureka Client请求其他Eureka Server节点中的一个节点，获取注册的服务信息，然后复制到其他peer节点。Eureka Server每当自己的信息变更后，例如Client向自己发起注册、续约、注销请求，就会把自己的最新信息通知给其他Eureka Server，保持数据同步。 怎么解决数据同步死循环? Eureka Server在执行复制操作的时候，使用HEADER_REPLICATION这个http header来区分普通应用实例的正常请求，说明这是一个复制请求，这样其他peer节点收到请求时，就不会再对其进行复制操作，从而避免死循环。具体实现方式其实很简单，就是接收到Service Provider请求的Eureka Server，把请求再次转发到其它的Eureka Server，调用同样的接口，传入同样的参数，除了会在header中标记isReplication=true，从而避免重复的replicate。 怎么解决数据冲突?serverA向serverB发起同步请求,如果A数据比B数据旧,不可能接受,B如何知道A数据旧,A又应该怎么解决? 数据的新旧一般是通过版本号来定义的，Eureka是通过lastDirtyTimestamp这个类似版本号的属性来实现的，表示此服务实例最近一次变更时间。 比如A向B复制数据，数据冲突有2种情况 A的数据比B的新，B返回404，A重新把这个应用实例注册到B。 A的数据比B的旧，B返回409，要求A同 B的数据。 hearbeat心跳机制 即续约操作，来进行数据的最终修复，因为节点间的复制可能会出错，通过心跳就可以发现错误，进行弥补。例如发现某个应用实例数据与某个server不一致，则server放回404，实例重新注册即可。 Eureka数据存储结构 Eureka Client在拉取服务信息时，先从缓存层获取(相当于Redis)，如果获取不到，先把数据存储层的数据加载到缓存中(相当于 Mysql)，再从缓存中获取。值得注意的是，数据存储层的数据结构是服务信息，而缓存中保存的是经过处理加工过的、可以直接传输到Eureka Client的数据结构。 数据存储层 因为rigistry本质上是一个双层的ConcurrentHashMap，存储在内存中的，所以是存储层不是持久层。第一层的key是spring.application.name（应用名），value 是第二层 ConcurrentHashMap；第二层 ConcurrentHashMap 的 key 是服务的 InstanceId(实例id)，value 是 Lease 对象；Lease 对象包含了服务详情和服务治理相关的属性。 缓存层 Eureka实现了二级缓存来保存即将要对外传输的服务信息，数据结构完全相同。一级缓存：ConcurrentHashMap readOnlyCacheMap，本质上是HashMap，无过期时间，保存服务信息的对外输出数据结构。二级缓存：Loading readWriteCacheMap，本质上是guava的缓存，包含失效机制，保存服务信息的对外输出数据结构。 缓存更新机制 更新机制包含删除和加载两个部分，上图黑色箭头表示删除缓存的动作，绿色表示加载或触发加载的动作。删除二级缓存:Eureka Client发送register、renew和cancel请求并更新 registry 注册表之后，删除二级缓存；Eureka Server自身的Evict Task剔除服务后，删除二级缓存；二级缓存本身设置了guava的失效机制，隔一段时间后自己自动失效；加载二级缓存:Eureka Client 发送getRegistry请求后，如果二级缓存中没有，就触发guava的load，即从registry中获取原始服务信息后进行处理加工，再加载到二级缓存中。Eureka Server更新一级缓存的时候，如果二级缓存没有数据，也会触发guava的load。更新一级缓存:Eureka Server内置了一个TimerTask，定时将二级缓存中的数据同步到一级缓存（这个动作包括了删除和加载）。 服务注册机制 服务提供者、服务消费者、以及服务注册中心自己，启动后都会向注册中心注册服务（如果配置了注册）。 注册中心服务接收到register请求后: 保存服务信息，将服务信息保存到registry中； 更新队列，将此事件添加到更新队列中，供Eureka Client增量同步服务信息使用; 清空二级缓存，即readWriteCacheMap，用于保证数据的一致性; 更新阈值，供剔除服务使用; 同步服务信息，将此事件同步至其他的Eureka Server节点。 服务续约机制 服务注册后，要定时（默认30S，可自己配置）向注册中心发送续约请求，告诉注册中心“我还活着”，即续约。 注册中心收到续约请求后 更新服务对象的最近续约时间，即Lease对象的lastUpdateTimestamp; 同步服务信息，将此事件同步至其他的Eureka Server节点。 服务注销机制 服务正常停止之前会向注册中心发送注销请求，告诉注册中心“我要下线了”。 注册中心服务接收到cancel请求后 删除服务信息，将服务信息从registry中删除； 更新队列，将此事件添加到更新队列中，供Eureka Client增量同步服务信息使用。 清空二级缓存，即readWriteCacheMap，用于保证数据的一致性。 更新阈值，供剔除服务使用。 同步服务信息，将此事件同步至其他的Eureka Server节点。 服务剔除机制 Eureka Server提供了服务剔除的机制，用于剔除没有正常下线的服务。 Eureka自我保护机制是为了防止误杀服务而提供的一个机制。Eureka的自我保护机制“谦虚”的认为如果大量服务都续约失败，则认为是自己出问题了（如自己断网了），也就不剔除了；反之，则是Eureka Client的问题，需要进行剔除。而自我保护阈值是区分Eureka Client还是Eureka Server出问题的临界值:如果超出阈值就表示大量服务可用，少量服务不可用，则判定是Eureka Client出了问题。如果未超出阈值就表示大量服务不可用，则判定是Eureka Server出了问题。 执行剔除服务后 删除服务信息，从registry中删除服务; 更新队列，将当前剔除事件保存到更新队列中; 清空二级缓存，保证数据的一致性。 服务同步机制 Eureka Client获取服务有两种方式，全量同步和增量同步。无论是全量同步还是增量同步，都是先从缓存中获取，如果缓存中没有，则先加载到缓存中，再从缓存中获取。Eureka Server启动后，遍历eurekaClient.getApplications获取服务信息，并将服务信息注册到自己的registry中。 启动时同步 Eureka Server启动后，遍历eurekaClient.getApplications获取服务信息，并将服务信息注册到自己的registry中。 运行过程中同步 当Eureka Server节点有register、renew、cancel请求进来时，会将这个请求封装成TaskHolder放到acceptorQueue队列中，然后经过一系列的处理，放到batchWorkQueue中。TaskExecutor.BatchWorkerRunnable是个线程池，不断的从batchWorkQueue队列中poll出TaskHolder，然后向其他Eureka Server节点发送同步请求。 "},"pages/SpringCloud/1266003525356224548.html":{"url":"pages/SpringCloud/1266003525356224548.html","title":"怎么样定义一个微服务,或划分服务比较合理?业务导向的共性?","keywords":"","body":"对应服务拆分 先设计高内聚低耦合的领域模型(DD)，再实现相应的分布式系统是一种比较合理的方式。微服务是手段，不是目的。目的是为了让系统更容易扩展，富有弹性，支持高并发，高可用，易于运维等等。使用DDD(领域驱动建模)进行业务建模，从业务中获取抽象的模型（例如用户，订单），根据模型的关系进行划分界限上下文。界限上下文可理解为逻辑上得微服务，或单体应用中一个组件。 界限上下文评审原则 原则1上下文之间相互依赖越少越好，依赖上游不应该知道下游信息。(订单依赖商品，商品不应该知道订单信息) 原则2使用潜在业务进行适配，如果能在一定程度响应业务变化，则证明该微服务可以在相当长一段时间内支撑应用开发。 从DDD的界限上下文往微服务转化，并得到系统架构、API列表、集成方式等。拆分微服务是一个过程，内部高内聚，外部的解耦。要半年到一年才根据对业务的深入理解进行合理的划分设计微服务。 设计微服务依赖关系 被依赖的服务不需要知道调用方的信息，否则就不是一个合理的依赖。例如，用户服务对于访问他的来源不应该知晓，应该对订单、商品、物流等调用方提供无差别的服务。 设计微服务的集成方式 采用PRC远程调用方式集成(Dubbo, gRPC, Thrift等，耦合高) 采用消息的方式集成(异步传输，订阅-发布) 采用RESTful方式集成(HTTP协议，耦合低) "},"pages/SpringCloud/1266003525456887891.html":{"url":"pages/SpringCloud/1266003525456887891.html","title":"为什么会有Dubbo和Spring Cloud两个微服务框架的存在,各自的优势?最重要的区别?","keywords":"","body":"Dubbo: 远程服务调用的分布式框架，专注RPC领域 远程通讯长连接，NIO通讯，支持多种序列化(Hessian 2/ProtoBuf)，请求-响应模式交换信息。 集群容错提供基于接口的RPC，负载均衡，失败容错(failover/failback)，地址路由，动态配置等。 自动发现基于注册中心目录服务，服务消费者能动态查找服务提供者，地址透明，服务提供者可以平滑扩容缩容。 Spring Cloud 微服务全面解决方案，全家桶，服务注册与发现，网关路由，负载均衡，服务间调用，服务保护断路器，分布式配置管理，分布式链路追踪，分布式消息传递等 区别 Dubbo是RPC通信，Spring Cloud是基于HTTP的REST方式。 因为Dubbo采用单一长连接和NIO异步通讯（保持连接/轮询处理），使用自定义报文的TCP协议，并且序列化使用定制Hessian2框架，二进制传输，占用带宽少。适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况，但不适用于传输大数据的服务调用。而Spring Cloud直接使用HTTP协议（但也不是强绑定，也可以使用RPC库，或者采用HTTP2.0+长链接方式（Feign可以灵活设置），JSON报文，消耗大。Dubbo的RPC痛点:服务提供方和调用方接口依赖太强;服务平台敏感，难以简单复用。 Dubbo强依赖阿里，社区更新不及时，现在又开始更新，未来会不会停，不好说。Spring Cloud属于Spring社区，开源社区活跃。基于Spring boot，快速开发部署，方便测试。 "},"pages/SpringCloud/1266003525628854352.html":{"url":"pages/SpringCloud/1266003525628854352.html","title":"你了解Hystrix吗?简单的说一说?","keywords":"","body":"什么是Hystrix? Hystrix可以让我们在分布式系统中对服务间的调用进行控制，加入一些调用延迟或者依赖故障的容错机制。 Hystrix 的设计原则 对依赖服务调用时出现的调用延迟和调用失败进行控制和容错保护。 在复杂的分布式系统中，阻止某一个依赖服务的故障在整个系统中蔓延。比如某一个服务故障了，导致其它服务也跟着故障。 提供 fail-fast（快速失败）和快速恢复的支持。 提供fallback优雅降级的支持。 支持近实时的监控、报警以及运维操作。 Hystrix更加细节的设计原则 阻止任何一个依赖服务耗尽所有的资源，比如 tomcat 中的所有线程资源。 避免请求排队和积压，采用限流和 fail fast 来控制故障。 提供fallback降级机制来应对故障。 使用资源隔离技术，比如bulkhead（舱壁隔离技术）、swim lane（泳道技术）、circuit breaker（断路技术）来限制任何一个依赖服务的故障的影响。 通过近实时的统计/监控/报警功能，来提高故障发现的速度。 通过近实时的属性和配置热修改功能，来提高故障处理和恢复的速度。 保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况。 Hystrix资源隔离? 定义 要把对某一个依赖服务的所有调用请求，全部隔离在同一份资源池内，不会去用其它资源了，这就叫资源隔离。哪怕对这个依赖服务，比如说商品服务，现在同时发起的调用量已经到了 1000，但是线程池内就10个线程，最多就只会用这 10 个线程去执行。不会对商品服务的请求，因为接口调用延时，将tomcat内部所有的线程资源全部耗尽。Hystrix进行资源隔离，其实是提供一个抽象，叫Command。把对某一个依赖服务的所有调用请求，全部隔离在同一份资源池内，对这个依赖服务的所有调用请求，全部走这个资源池内的资源，不会去用其他的资源。 Hystrix最基本的资源隔离技术,就是线程池隔离技术 利用HystrixCommand获取单条数据 利用HystrixObservableCommand批量获取数据 从Nginx开始，缓存都失效了，那么Nginx通过缓存服务去调用商品服务。缓存服务默认的线程大小是10个，最多就只有10个线程去调用商品服务的接口。即使商品服务接口故障了，最多就只有 10 个线程会 hang 死在调用商品服务接口的路上，缓存服务的 tomcat 内其它的线程还是可以用来调用其它的服务。 Hystrix实现资源隔离，主要有两种技术线程池和信号量。默认情况下，Hystrix使用线程池模式。 线程池机制 HystrixCommand command = new HystrixCommand(arg1, arg2); //HystrixCommand主要用于仅仅返回一个结果的调用 HystrixObservableCommand command = new HystrixObservableCommand(arg1, arg2); //HystrixObservableCommand主要用于可能会返回多条结果的调用 执行command要从4个方法选一个: execute(), queue(), observe(), toObservable() execute(), queue()仅对HystrixCommand适用 execute(): 同步调用，调用后block，直到依赖服务返回单条结果或异常 queue(): 异步调用，返回一个Future，后面可以通过future获取结果 observe(): 订阅一个Observable对象，Observable代表是依赖服务的返回结果，获取一个代表结果的Observable对象的拷贝对象。是立即执行construct方法，拿到多行结果。 toObservable(): 返回一个Observab对象，没有执行construct方法，延迟调用。如果订阅这个对象subscribe方法时，才会执行command获取返回结果。 信号量机制 信号量的资源隔离只是起到一个开关的作用。比如，服务A的信号量大小为10，那么就是说它同时只允许有10个tomcat线程来访问服务A，其它的请求都会被拒绝，从而达到资源隔离和限流保护的作用。 线程池与信号量区别 线程池隔离技术，是用Hystrix自己的线程去执行调用；而信号量隔离技术，是直接让tomcat线程去调用依赖服务。信号量隔离，只是一道关卡，信号量有多少，就允许多少个tomcat线程通过它，然后去执行。 适用场景线程池技术，适合绝大多数场景，比如说我们对依赖服务的网络请求的调用和访问、需要对调用的timeout进行控制（捕捉timeout超时异常）。信号量技术，适合说你的访问不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，并且系统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要去捕获timeout类似的问题。 Hystrix执行流程 Hystrix请求缓存(request cache)如果command开启了请求缓存，而且这个调用结果在缓存中存在，就直接从缓存返回结果 短路器0检测command对应的依赖服务是否打开短路器，如果打开，hystrix不执行command，执行fallback降级机制。 检测线程池/队列/semaphore是否满如果以上已满，不会执行command，直接执行fallback降级机制。 执行command如果基于线程池，有一个timeout机制。即HystrixCommand.run()或HystrixObservableCommand.construct()的执行，超过了timeout时长的话，那么command所在线程会抛出一个TimeoutException,timeout也会执行fallback降级机制，不会管run()或construct()返回值。 注意点不可能终止Hystrix管理线程池中一个调用依赖服务timeout的线程，只能给外部抛出一个TimeoutException，由主线程来捕获再降级处理。 4种调用fallback的降级机制的时机 run()或construct()抛异常 短路器打开 线程池/队列/信号量满了 command执行超时 Hystrix的8大执行流程 构建一个HystrixCommand或HystrixObservableCommand,HystrixCommand主要用于仅仅返回一个结果的调用,HystrixObservableCommand主要用 于可能会返回多条结果的调用。 调用Command的执行方法,执行Command发起一次对依赖服务的调用,执行command要从4个方法选一个：execute(), queue(), observe(), toObservable()。 execute(),queue()仅对HystrixCommand适用; execute(): 同步调用，调用后block，直到依赖服务返回单条结果或异常; queue(): 异步调用，返回一个Future，后面可以通过future获取结果; observe(): 订阅一个Observable对象，Observable代表是依赖服务的返回结果，获取一个代表结果的Observable对象的拷贝对象。是立即执行construct方法，拿到多行结果。 toObservable(): 返回一个Observab对象，没有执行construct方法，延迟调用。如果订阅这个对象subscribe方法时，才会执行command获取返回结果。 检查是否开启请求缓存 如果开启request cache, 而这个调用结果在缓存中存在，那么直接从缓存中返回。 检查是否开启短路器 如果短路器打开，那么hystrix就不会执行command，直接执行fallback降级机制。 检测线程池/队列/semaphore是否已满 如果已满，不会执行command，而直接走fallback降级机制。 执行command 调用HystrixObservableCommand.construct()或HystrixCommand.run()来实际执行这个command。 HystrixCommand.run()返回一个单条结果，或者抛出一个异常 HystrixObservableCommand.construct()返回一个Observable对象，可以获取多条结果 如果command执行超时，那么改线程会抛出TimeoutException，会执行fallback降级机制，不会管run()或construct()的返回值。 短路健康检查 Hystrix会将每一个依赖服务的调用成功，失败，拒绝，超时等事件，都会发送给circuit breaker断路器。短路器就会对调用成功/失败/拒绝/超时等事件的次数进行统计。 调用fallback降级机制 run()或construct()抛出一个异常 短路器打开 线程池/队列/信息量满 Command超时，Hystrix会调用fallback降级机制 降级机制设置一些默认返回值 Hystrix核心技术之请求缓存 用法 检测是否开启请求缓存(request cache)，是否由请求缓存，如果有，直接取缓存返回结果。 概念 请求上下文，每个web应用中, Hystrix在一个filter中，对每个请求增加一个请求上下文。Tomcat中每次请求，就是一个请求上下文。一个请求上下文中会执行N多代码，调用N多个依赖服务。在一个请求上下文中，如果有多个command（假设参数一样，调用结构一样，返回结果也就一样），可以让第一次的command执行返回的结果，缓存在内存中，然后这个请求上下文中，后续对这个command的执行都从内存中取缓存结果。 好处 不用在一次请求上下文中反复多次执行一样的command，避免重复执行网络请求，提升整个请求的性能。 具体使用 实现Hystrix请求上下文过滤器并注册// 定义HystrixRequestContextFilter类，实现Filter接口 public class HystrixRequestContextFilter implements Filter{ ... } ...... // 然后将该filter对象注册到SpringBoot Application中 @Bean public FilterRegistrationBean filterRegistrationBean() { FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new HystrixRequestContextFilter()); filterRegistrationBean.addUrlPatterns(\"/*\"); return filterRegistrationBean; } command重写getCacheKey()方法 public class GetProductInfoCommand extends HystrixCommand { private static final HystrixCommandKey KEY = HystrixCommandKey.Factory.asKey(\"GetProductInfoCommand\"); ... /** * 每次请求的结果，都会放在Hystrix绑定的请求上下文上 * * @return cacheKey 缓存key */ @Override public String getCacheKey() { return \"product_info_\" + productId; } /** * 将某个商品id的缓存清空 * * @param productId 商品id */ public static void flushCache(Long productId) { HystrixRequestCache.getInstance(KEY, HystrixConcurrencyStrategyDefault.getInstance()).clear(\"product_info_\" + productId); } } } 基于本地缓存的fallback降级 Hystrix出现以下四种情况,都会去调用fallback降级机制 断路器处于打开的状态 资源池已满（线程池+队列/信号量） Hystrix调用各种接口，或者访问外部依赖，比如MySQL、Redis、Zookeeper、Kafka等等，出现了任何异常的情况。 访问外部依赖的时候，访问时间过长，报了TimeoutException异常。 两种典型降级机制 纯内存数据内存中维护一个 ehcache，作为一个纯内存的基于 LRU 自动清理的缓存，让数据放在缓存内，fallback从ehcache中获取数据 默认值fallback直接返回一个默认值在HystrixCommand，降级逻辑的书写，是通过实现getFallback()接口；而在HystrixObservableCommand中，则是实现resumeWithFallback()方法。 Hystrix 断路器执行原理 RequestVolumeThreshold请求数 HystrixCommandProperties.Setter().withCircuitBreakerRequestVolumeThreshold(int) 表示在滑动窗口中，至少有多少个请求，才可能触发断路Hystrix经过断路器的流量超过了一定的阈值，才有可能触发断路。 ErrorThresholdPercentage异常比例 HystrixCommandProperties.Setter().withCircuitBreakerErrorThresholdPercentage(int) 表示异常比例达到多少，才会触发断路，默认值是 50(%)。如果断路器统计到的异常调用的占比超过了一定的阈值，比如说在 10s 内，经过断路器的流量达到了 30 个，同时其中异常访问的数量也达到了一定的比例，比如 60% 的请求都是异常（报错 / 超时 / reject），就会开启断路。 SleepWindowInMilliseconds 断路休息时间 HystrixCommandProperties.Setter().withCircuitBreakerSleepWindowInMilliseconds(int) 断路开启，也就是由 close 转换到 open 状态（close -> open）。那么之后在 SleepWindowInMilliseconds 时间内，所有经过该断路器的请求全部都会被断路，不调用后端服务，直接走 fallback 降级机制。而在该参数时间过后，断路器会变为 half-open 半开闭状态，尝试让一条请求经过断路器，看能不能正常调用。如果调用成功了，那么就自动恢复，断路器转为 close 状态。 Enabled断路器开关 HystrixCommandProperties.Setter().withCircuitBreakerEnabled(boolean) 如果设置为true的话，直接强迫打开断路器，相当于是手动断路了，手动降级，默认值是false。 ForceClosed手动断路开关: 关 HystrixCommandProperties.Setter().withCircuitBreakerForceClosed(boolean) 如果设置为 true，直接强迫关闭断路器，相当于手动停止断路了，手动升级，默认值是 false。 Hystrix线程池隔离与接口限流 原理 Hystrix 通过判断线程池或者信号量是否已满，超出容量的请求，直接 Reject 走降级，从而达到限流的作用。限流是限制对后端的服务的访问量，比如说你对 MySQL、Redis、Zookeeper 以及其它各种后端中间件的资源的访问的限制，其实是为了避免过大的流量直接打死后端的服务。 线程隔离技术Hystrix 对每个外部依赖用一个单独的线程池，这样的话，如果对那个外部依赖调用延迟很严重，最多就是耗尽那个依赖自己的线程池而已，不会影响其他的依赖调用。 线程池机制的优点 隔离服务。任何一个依赖服务被隔离在线程池内，即使自己线程池资源满了，也不会影响其他服务调用。 方便引入新的依赖服务。即使新的依赖服务有问题，也不影响其他服务调用。 故障恢复。当一个有故障的服务变好后，可以通过清空线程池，快速恢复该服务调用。 健康报告。线程池的健康状态随时报告，比如成功、失败、拒绝、超时的次数统计，然后接近实时的热修改调用配置，不用停机。 基于线程池的异步本质，在同步调用之上，构建一层异步调用层。 线程池机制的缺点 增加CPU开销。 每个command的执行依托独立线程，会进行排队，调度，上下文切换。Hystrix官方统计过额外开销，相比于可用性和稳定性的提升，是可以接受的。Hystrix semaphore 技术可以用来限流和削峰，但是不能用来对调研延迟的服务进行timeout和隔离。 基于timeout机制为服务接口调用超时提供安全保护如果你不对各种依赖服务接口的调用做超时控制，来给你的服务提供安全保护措施，那么很可能你的服务就被各种垃圾的依赖服务的性能给拖死了。 Hystrix核心总结 Hystrix内部工作原理，8大执行步骤和流程 资源隔离多个依赖服务，做资源隔离，避免任何一个依赖服务故障导致服务资源耗尽而崩溃，高可用。 请求缓存对同一个request内多个相同command，使用request cache，提供性能。 熔断基于断路器，采集异常情况，如报错，超时，拒绝，短路，一段时间不能访问，直接降级。 降级服务提供的容错机制，fallback逻辑。 限流通过线程池，或信号量，限制对某个后端服务或资源的访问量，直接降级。 超时避免因某个依赖服务性能太差，导致大量线程卡住在这个依赖服务。 "},"pages/SpringCloud/1266003526841008138.html":{"url":"pages/SpringCloud/1266003526841008138.html","title":"Zookeeper都有哪些使用场景?","keywords":"","body":"分布式协调 场景A系统发请求到MQ，B系统消费之后，A系统怎么知道B系统的处理结果? 解决方案 用Zookeeper实现分布式系统之间协调工作。A系统发请求之后，在Zookeeper上对某个节点的值注册监听器，一旦B系统处理完值后就修改Zookeeper的节点值，A系统就立马收到通知。 分布式锁 场景对某一个数据需要2个修改操作，两台机器同时收到请求，但需要一台执行后另一台才能执行。 解决方案使用ZK分布式锁。机器A收到请求后，在ZK创建一个znode，接着执行操作；另外一个机器B也尝试创建znode，发现创建不了，注册这个锁的监听器，只能等待机器A执行完成之后再执行。ZK发现机器A释放锁后，ZK会通知机器B, 这样B可以获取锁。 实现 zookeeper.create(path…)尝试创建临时节点，创建成功就获取锁；如果被别的客户端获取了，就注册一个监听器监听这个锁，可以尝试用CountDownLatch await或者别的方式等待，或者不断循环查询，如果监听这个节点被释放，就把latch countDown或者把等待release，重新尝试获取锁。也可以基于zookeeper的临时顺序节点来实现，不用while true的循环。多人竞争一把锁时，会排队，后面每个排队的都去监听排在自己前面那个人创建的znode。 元数据/配置信息管理 场景 ZK可以作为很多系统的配置信息管理，比如Kafka, Storm，Dubbo。 HA高可用 场景 大数据系统基于ZK开发HA高可用机制，比如Hadoop，HDFS，Yarm。一个进程/服务做主备两个，主挂了立马通过Zookeeper感知切换到备用进程或服务。 "},"pages/Network/":{"url":"pages/Network/","title":"网络","keywords":"","body":"网络 Please Go Forward "},"pages/Network/1266003517290577997.html":{"url":"pages/Network/1266003517290577997.html","title":"你能聊聊TCP/IP四种网络模型吗?OSI七层网络模型也说一下!","keywords":"","body":"图解 数据链路层(以太网协议) 一堆0/1电路信号，封装成数据包，包含头(head)和数据(data)，head里包含从哪儿来到哪儿去，从一台电脑的一个网卡，发送到另外一台电脑的一个网卡，以太网发送的数据包指定目标电脑网卡的mac地址。 网络层(IP协议) IPv4和IPv6，IPv4由32个二进制组成，一般用4个十进制数字表示，从0.0.0.0到255.255.255.255之间。IP地址前24位(前3个十进制数字)代表网络，后8位(最后一个十进制数字)代表主机。前3个十进制数字相同表示同一个子网的。子网掩码：用于判断两个IP地址是不是同一个子网。判断方法就是分别把两个IP地址和自己的子网掩码进行二进制与运算，比较代表网络那部分是否相同。 路由器 负载将多个子网进行连接，实际就是配置了多个网卡的设备，可以通过不同网卡接入不同的网络。网关，其实是路由器的一种，运作在网络层。可以就把路由器上的ip地址认为是网关，路由器上每个网卡都有mac地址和对应的ip地址。路由器虽然有mac地址，但是不能通过mac地址寻址的，必须通过ip地址寻址，所以路由器其实是工作在网络层的设备。 网络交换机 通过mac地址来寻址和传输数据包的；但是路由器是通过ip地址寻址和传输数据包的。网络交换机主要用在局域网的通信，一般你架设一个局域网，里面的电脑通信是通过数据链路层发送数据包，通过mac地址来广播的，广播的时候就是通过网络交换机这个设备来把数据广播到局域网内的其他机器上去的。 一个子网内的机器之间通信，就是在数据包里写上对方的mac地址，然后交换机广播出去ok了；但是如果是跨子网的通信，就是写上对方的ip地址，然后先通过mac地址广播到路由器，让路由器再根据另外一个子网的ip地址转换为mac地址，通过另外一个子网的交换机广播过去。 传输层(TCP协议) 端口，发送数据包到某个机器的一个网卡的某个端口上去，然后那个机器上监听那个端口的程序，就可以提取发送到这个端口的数据，知道是自己的数据。端口号是0~65536的范围内，0~1023被系统占用了，别的应用程序就用1024以上的端口。网络层，是基于ip协议，进行主机和主机间的寻址和通信的，然后传输层，其实是建立某个主机的某个端口，到另外一个主机的某个端口的连接和通信的。这个通信，就是通过socket来实现的，通过socket就可以基于tcp/ip协议完成刚才上面说的一系列的比如基于ip地址和mac地址转换和寻址啊，通过路由器通信啊之类的，而且会建立一个端口到另外一个端口的连接。 应用层(HTTP协议) 针对各种不同的应用，邮件、网页之类的，都是定义不同的应用层协议的。比如最常见的，应用层的协议就是http协议，进行网络通信。电子邮件协议，SMTP、POP3、IMAP4等。GET http://localhost:8080/ http/1.1 key:value"},"pages/Network/1266003517642899552.html":{"url":"pages/Network/1266003517642899552.html","title":"浏览器请求www.baidu.com的全过程大概是怎样的?","keywords":"","body":"图解 假设我们电脑设置了几个东西如下:ip地址：192.168.31.37 子网掩码：255.255.255.0 网关地址：192.168.31.1 DNS地址：8.8.8.8 流程 请求www.baidu.com地址，这个时候找DNS服务器，DNS服务器解析域名之后，返回一个ip地址，比如172.194.26.108。 判断本机和访问的IP是不是同一个子网，用子网掩码坐与运算。通常不在一个子网，就发送数据包给网关，也就是路由器。 通过浏览器访问网站，走应用层的http协议，把浏览器发出的请求打包为数据包。把http协议请求，有请求头，空行，请求数据，就构成http请求报文，封装到一个应用层数据包里。 接下来走到传输层，按照TCP协议，TCP协议会让你设置端口，发送方端口随机选择，接收端一般默认80端口。这时会把应用层数据包封装到TCP数据包，再加一个TCP头，TCP头放了端口信息。 走网络层，会把TCP头和TCP数据包，放到IP数据包里，再做了一个IP头，IP头包括本机和目标机器的IP地址。通过IP 协议，判断两个IP不在一个子网内，则将数据包通过以太网协议广播到网关，通过网关在发生出去。 最后走到数据链路层，把IP头和IP数据包封装到以太网数据包，再增加一个以太网数据包头，头里放了本机网卡MAC地址和网关MAC地址。但以太网数据包有1500字节的限制，超过要切分为多个数据包，每个数据包包含以太网头、IP头和切割后的IP数据包。以太网数据包通过交换机发送到网关，然后通过路由器转发到别的子网或者别的路由器，以此类推，通过N个路由器或网关转发，最终到达目标服务器，比如172.194.26.108。目标服务器接收到以太网数据包后，从IP数据包，拿出TCP数据包，再从TCP数据包取出HTTP数据包，读取出HTTP数据包里各种协议内容，比如html页面，或者业务处理，然后再把响应结果封装成http响应报文，封装到http数据包里，再封装TCP数据包，封装IP数据包，封装以太网数据包，再通过网关发送回去，完成整个请求过程。 "},"pages/Network/1266003518020386883.html":{"url":"pages/Network/1266003518020386883.html","title":"画一下TCP三次握手流程图?为啥是三次而不是二次或者四次呢?","keywords":"","body":"图解 三次握手   建立三次握手的时候，TCP报头用到了下面几个东西，ACK、SYN、FIN。第一次握手，客户端发送连接请求报文，此时SYN=1、ACK=0，这就是说这是 个连接请求，seq = x，接着客户端处于SYN_SENT状态，等待服务器响应。第二次握手，服务端收到SYN=1的请求报文，需要返回一个确认报文，ack = x + 1， SYN=1，ACK = 1，seq = y，发送给客户端，自己处于SYN_RECV状态。第三次握手，客户端收到了报文，将ack = y + 1，ACK = 1，seq = x + 1 二次握手   假设两次握手就ok了，要是客户端第一次握手过去，结果卡在某个地方了，没到服务端；完了客户端再次重试发送了第一次握手过去，服务端收到了， ok了，大家来回来去，三次握手建立了连接。结果，尴尬的是，后来那个卡在哪儿的老的第一次握手发到了服务器，服务器直接就返回一个第二次握手， 这个时候服务器开辟了资源准备客户端发送数据啥的，结果呢？客户端根本就不会理睬这个发回去的二次握手，因为之前都通信过了。但是如果是三次握手， 那个二次握手发回去，客户端发现根本不对，就会发送个复位的报文过去，让服务器撤销开辟的资源，别等着了。 四次挥手   第一次挥手，客户端发送报文，FIN=1，seq=u，此时进入FIN-WAIT-1状态。第二次挥手，服务端收到报文，这时候进入CLOSE_WATI状态，返回一个报文， ACK=1，ack=u+1，seq=v。客户端收到这个报文之后，直接进入FIN-WAIT-2状态，此时客户端到服务端的连接就释放了。第三次挥手，服务端发送连接释放报 文，FIN=1，ack=u+1，seq=w，服务端进入LAST-ACK状态。第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK=1，ack=w+1，seq=u+1，进入 TIME_WAIT状态，等待一会儿客户端进入CLOSED状态，服务端收到报文之后就进入CLOSED状态。 "},"pages/Network/1266003518125244420.html":{"url":"pages/Network/1266003518125244420.html","title":"聊聊HTTP协议的工作原理!","keywords":"","body":"http的工作流程   http请求封装到应用层数据包，封装在tcp数据包，封装在ip数据包，封装在以太网数据包，如果过大，可能会拆成几个包，走以太网协议+交换机 -> 广播 -> 网关 -> 多个网关 -> 目标的机器 -> 一层一层拆包 -> http请求报文 -> 传递给tomcat -> spring mvc -> http响应 -> 一样的路 径会去。浏览器 -> 网站，互相之间是先要通过tcp三次握手，建立一个连接，浏览器和网站互相都给对方留出一份资源，浏览器发起http请求 -> tcp -> ip -> 以太网，网站上面去，网站返回一个响应，连接关闭，tcp四次挥手。释放掉浏览器和网站各自给对方保持的一份资源。 http1.0、http1.1、http2.0具体有哪些区别?   http 1.0要指定keep-alive来开启持久连接，默认是短连接，就是浏览器每次请求都要重新建立一次tcp连接，完事儿了就释放tcp连接。早期的 网页都很low，没啥东西，就一点文字，就用这个没问题。2000年之前，那个时候网页，都很low，当时你打开一个网页，就是说现场底层tcp三次握手， 跟网站建立一个tcp连接，然后通过这个tcp连接，发送一次http请求，网站返回一个http响应（网页的html，里面有一大段文字），浏览器收到html渲 染成网页，浏览器就走tcp四次挥手，跟网站断开连接了。2000之后，2010之后更不用说了，网页发展很迅猛，一个网页包含着大量的css、js、图片等 资源。比如你请求一个网页，这个网页的html先过来，过来之后，浏览器再次发起大量的请求去加载css、js、图片，打开一个网页可能浏览器要对网站 服务器发送几十次请求。再频繁建立和释放tcp连接，会很慢很慢。 http 1.1默认支持长连接，就是说，浏览器打开一个网页之后，底层的tcp连接就保持着，不会立马断开，之后加载css、js之类的请求，都会基于 这个tcp连接来走。http 1.1还支持host头，也就可以支持虚拟主机；而且对断点续传有支持。浏览器，第一次请求去一个网站的一个页面的时候，就会 打开一个tcp连接，接着就在一段时间内都不关闭了，然后接下来这个网页加载css、js、图片大量的请求全部走同一个tcp连接，频繁的发送请求获取响 应，最后过了一段时间，这些事儿都完了，然后才会去释放那一个tcp连接。大幅度的提升复杂网页的打开的速度，性能。 未来http 2.0，支持多路复用，基于一个tcp连接并行发送多个请求以及接收响应，解决了http 1.1对同一时间同一个域名的请求有限制的问题。 二进制分帧，将传输数据拆分为更小的帧（数据包），frame（数据包，帧），提高了性能，实现低延迟高吞吐。 "},"pages/Network/1266003518389485581.html":{"url":"pages/Network/1266003518389485581.html","title":"聊聊HTTPS的工作原理?为啥用HTTPS就可以加密通信?","keywords":"","body":"图解 流程 浏览器把自己支持的加密规则发送给网站。 网站从这套加密规则里选出来一套加密算法和hash算法，然后把自己的身份信息用证书的方式发回给浏览器，证书里有网站地址、加密公钥、证书颁发机构。 浏览器验证证书的合法性，然后浏览器地址栏上会出现一把小锁；浏览器接着生成一串随机数密码，然后用证书里的公钥进行加密，这块走的非对称加密；用约定好的hash算法生成握手消息的hash值，然后用密码对消息进行加密，然后把所有东西都发给网站，这块走的是对称加密。 网站，从消息里面可以取出来公钥加密后的随机密码，用本地的私钥对消息解密取出来密码，然后用密码解密浏览器发来的握手消息，计算消息的hash值，并验证与浏览器发送过来的hash值是否一致，最后用密码加密一段握手消息，发给浏览器。 浏览器解密握手消息，然后计算消息的hash值，如果跟网站发来的hash一样，握手就结束，之后所有的数据都会由之前浏览器生成的随机密码，然后用对称加密来进行进行加密。(常用的非对称加密是RSA算法，对称加密是AES、RC4等，hash算法就是MD5。) "},"pages/Network/1266003518746001443.html":{"url":"pages/Network/1266003518746001443.html","title":"聊聊http的长连接的工作原理到底是啥?","keywords":"","body":"工作原理   http本身没什么所谓的长连接短连接之说，其实说白了都是http下层的tcp连接是长连接还是短连接，tcp连接保持长连接，那么多个http请求和响应都可以通过一个链接来走。其实http 1.1之后，默认都是走长连接了，就是底层都是一个网页一个tcp连接，一个网页的所有图片、css、js的资源加载，都走底层一个tcp连接，来多次http请求即可。http 1.0的时候，底层的tcp是短连接，一个网页发起的请求，每个请求都是先tcp三次握手，然后发送请求，获取响应，然后tcp四次挥手断开连接；每个请求，都会先连接再断开。短连接，建立连接之后，发送个请求，直接连接就给断开了。http 1.1，tcp长连接，tcp三次握手，建立了连接，无论有多少次请求都是走一个tcp连接的，走了n多次请求之后，然后tcp连接被释放掉了。 "},"pages/Network/1266003518951522362.html":{"url":"pages/Network/1266003518951522362.html","title":"聊聊Socket的工作原理?Socket和TCP IP之间是啥关系?","keywords":"","body":"定义   socket属于传输层的一个编程规范。socket就是在传输层把tcp/ip协议给封装了，Java原生支持socket网络编程。一般都是面试socket来编程。 "},"pages/Network/1266003519102517325.html":{"url":"pages/Network/1266003519102517325.html","title":"你能聊聊BIO,NIO,AIO分别都是啥?有什么区别?","keywords":"","body":"BIO 图解 定义同步阻塞式IO 原理服务端创建一个ServerSocket，客户端用一个Socket去连接那个ServerSocket，然后ServerSocket接收到Socket连接请求就创建一个Socket和一个线程去和客户端Socket通信。 缺陷客户端socket发送一个请求，服务端socket进行处理后返回响应，响应必须是等处理完成之后才能返回，这期间不能做其他事，只能等待(卡住)...而且每一个客户端接入，服务端就需要创建一个线程来服务，会导致客户端大量增加时，服务端线程会负责过高(可能几千几万个线程。。)，最后服务端崩溃。 优化可以用线程池，固定线程来处理客户端请求，但是高并发时，会导致大量排队和延时。 NIO 图解 定义同步非阻塞IO,基于Reactor模型 构成 Channel表示为一个已经建立好的支持I/O操作的实体（如文件和网络）的连接，在此连接上进行数据的读写操作，使用的是缓冲区来实现读写。 Buffer在内存中预留指定大小的存储空间用来对输入/输出(I/O)的数据作临时存储。好处是减少实际的物理读写次数缓冲区在创建时就被分配内存，这块内存区域一直被重用，可以减少动态分配和回收内存的次数好比从A工地搬1w块砖到B工地，路途远(IO性能消耗大)，没有工具时(缓冲区)，一次搬1块，要搬1w次(IO读写1w次)。用卡车(缓冲区)，一次运送5K块，2次就运完了，性能大大提高了。 Selector(多路复用器)selector会不断轮询注册的channel，如果某个channel上发生了读写事件，selector就会将这些channel获取出来，我们通过SelectionKey获取有读写事件的channel，就可以进行IO操作。一个Selector就通过一个线程，就可以轮询成千上万的channel，这就意味着你的服务端可以接入成千上万的客户端。 原理核心就是非阻塞，selector一个线程可以不停轮询channel，所有客户端都不会阻塞，最多排队。只有某个客户端发送了一个请求，才会启动一个线程来处理。客户端接入不会耗费一个线程，只会创建一个channel连接，然后注册到selector上，一个selector线程不断轮询所有的socket连接(channel)，发现有事件就通知，启动工作线程处理一个请求。工作线程，从channel-buffer读数据，如果数据没有读完卡住，等待，然后处理后往buffer-channel里写数据，也是自己做，写数据时数据没有写完，也卡住等待，是同步的。 AIO(基于Proactor模型的,就是异步非阻塞模型) 原理每个请求会绑定一个buffer，通知操作系统去异步完成读写，此时工作线程可以做别的事情（异步），等操作系统完成之后，回调接口，把操作系统完成的数据给工作线程。 "},"pages/Network/1266003520100761655.html":{"url":"pages/Network/1266003520100761655.html","title":"让所有工程师闻风色变的DDoS攻击到底是什么东西?","keywords":"","body":"定义   DDoS(英文Distributed Denial of Service，即分布式拒绝服务)，这是一种网络攻击方式，主要目的是以分布式攻击来让指定目标无法提供正 常服务，甚至从互联网上消失。说白了就是一定时间内增大访问量，使其无法正常提供服务。看过最形象也最好笑的比喻是，春运抢火车票导致12306网 站瘫痪，就是DDOS攻击。DDOS只不过是一个概称，其下有各种攻击方式，比如“CC攻击、SYN攻击、NTP攻击、TCP攻击、DNS攻击等等”   攻击者利用大量“肉鸡”对攻击目标发动大量的正常或非正常请求、耗尽目标主机资源或网络资源，从而使被攻击的主机不能为合法用户提供服务。大 家应该还听过DoS攻击。DoS（拒绝服务，Denial of Service）就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。 这是早期非常基本的网络攻击方式。 "},"pages/database/":{"url":"pages/database/","title":"数据库","keywords":"","body":"数据库 Please Go Forward "},"pages/database/Mysql/":{"url":"pages/database/Mysql/","title":"MYSQL","keywords":"","body":"Mysql Please Go Forward "},"pages/database/Mysql/1266003522869002329.html":{"url":"pages/database/Mysql/1266003522869002329.html","title":"MYSQL集群会产生哪些问题?","keywords":"","body":"自增id问题 如何解决 UUID(不推荐, 不能建索引) 设置id步长(缺点：需要在设计数据库时需要确定库的数量，才能定好步长间隔) 雪花算法(sharding-jdbc使用雪花算法)或Redis 数据关联查询问题(水平拆分) 数据同步问题 "},"pages/database/Mysql/1266003523527508014.html":{"url":"pages/database/Mysql/1266003523527508014.html","title":"mysql定位慢查询?","keywords":"","body":"慢查询日志存放的位置 slow_query_log_file; 查询超过多少秒才记录 long_query_time; 查询慢查询配置 show variables like 'slow_query%'; 查询慢查询限制时间 show variables like 'long_query_time'; 将slow_query_log全局变量设置为“ON”状态 set global slow_query_log='ON'; 查询超过2秒就记录 set global long_query_time=2; 索引为什么会失效? 索引字段存了null值 条件中有or like以%开头 联合索引,不是使用最左原则 字符串没有用引号引起来 联合索引为什么需要遵循左前缀原则? 因为索引底层采用B+树叶子节点顺序排列，必须通过左前缀索引才能定位到具体的节点范围。 "},"pages/database/Mysql/1266003523657531470.html":{"url":"pages/database/Mysql/1266003523657531470.html","title":"你能说说Mysql如何实现主从复制?读写分离?分表分库?","keywords":"","body":"主从复制 MySQL主从复制是MySQL本身自带功能。从库生成两个线程，一个I/O线程，一个SQL线程；I/O线程去请求主库 的binlog，并将得到的binlog日志写到relay log（中继日志） 文件中；主库会生成一个 log dump 线程，用来给从库 i/o线程传binlog；SQL线程，会读取relay log文件中的日志，并解析成具体操作，来实现主从的操作一致，而最终数据一致。 读写分离 MYCAT 原理MyCAT主要是通过对SQL的拦截，然后经过一定规则的分片解析、路由分析、读写分离分析、缓存分析等，然后将SQL发给后端真实的数据块，并将返回的结果做适当处理返回给客户端。 特点第三方客户端，反向代理 SpringBoot动态切换数据源 原理动态切换数据源，根据配置的文件，业务动态切换访问的数据库:此方案通过Spring的AOP，AspactJ来实现动态织入，通过编程继承实现Spring中的AbstractRoutingDataSource，来实现数据库访问的动态切换，不仅可以方便扩展，不影响现有程序，而且对于此功能的增删也比较容易。在Spring 2.0+中引入了AbstractRoutingDataSource, 该类充当了DataSource的路由中介, 能有在运行时, 根据某种key值来动态切换到真正的DataSource上。 流程 项目中需要集成多个数据源分别为读和写的数据源，绑定不同的key； 采用AOP技术进行拦截业务逻辑层方法，判断方法的前缀是否需要写或者读的操作； 如果方法的前缀是写的操作的时候，直接切换为写的数据源，反之切换为读的数据源也可以自己定义注解进行封装。 分表分库 垂直拆分 定义根据不同业务，分位不同数据库。比如会员DB，订单DB，支付DB等等。 优点业务清晰，系统间整合和扩展容易。 缺点业务表不能join，只能通过接口调用，系统复杂度挺高，还有分布式事务问题。 水平拆分把同一个表的数据按字段拆分到不同数据库，或者把同一个表拆分多份到不同数据库。 Sharding-JDBC 与MyCat的区别MyCat是一个基于第三方应用中间件数据库代理框架，客户端所有的jdbc请求都必须要先交给MyCat，再有MyCat转发到具体的真实服务器中。Sharding-Jdbc是一个Jar形式，在本地应用层重写Jdbc原生的方法，实现数据库分片形式。MyCat属于服务器端数据库中间件，而Sharding-Jdbc是一个本地数据库中间件框架。 Sharding-JDBC实现读写分离原理需要在项目中集成主和从的数据源,Sharding-Jdbc根据DML和DQL语句类型连接主或者从数据源。(PS: 查看MasterSlaveDataSource即可查看该类getDataSource方法获取当前数据源名称) SpringBoot整合Sharding-Jdbc分为两种方式 原生配置方式,自己需要实现接口分库算法类需要实现SingleKeyDatabaseShardingAlgorithm接口 分表算法类需要实现SingleKeyTableShardingAlgorithm接口 通过配置文件形式配置e.g: t_order 拆分成 t_order_0; t_order _1 Sharding-Jdbc原理 Sharding-JDBC中的路由结果是通过分片字段和分片方法来确定的,如果查询条件中有 id 字段的情况还好，查询将会落到某个具体的分片。 如果查询没有分片的字段，会向所有的db或者是表都会查询一遍，让后封装结果级给客户端。 "}}