{"./":{"url":"./","title":"interview of sonin","keywords":"","body":"   "},"pages/Java/":{"url":"pages/Java/","title":"Java","keywords":"","body":""},"pages/Java/base/":{"url":"pages/Java/base/","title":"基础","keywords":"","body":""},"pages/Java/base/1266003510067986476.html":{"url":"pages/Java/base/1266003510067986476.html","title":"为什么在Java面试中一定会深入考察HashMap?","keywords":"","body":"解析 HashMap作为一个键值对(key-value)的常见集合，在整个java的使用过程中都起着举足轻重的作用。比如从DB中取值、数据的加工、数据回传给前端、数据转换为json等都可能使用到HashMap；且HashMap作为一个可以允许空键值对的集合，也能实现自动的扩容，扩容的参数值为0.75，达到后自动扩容一倍，这样给一些处理未知数据量大小的数据来说，是很方便的。虽然HashMap是线程不安全的，主要体现在1.7和1.8上。1.7的hashMap在扩容的时候回形成循环链，导致死循环而报错，或者数据的丢失情况，在1.8上，虽然对这方面做了改进，但是仍然是线程不安全的，主要是体现在，若多线程操作数据，如线程A B同时进行数据的put操作，在put操作前，会进行key的hash碰撞，但是线程A B有可能同时碰撞且碰撞的值相同，那么就会发生线程A先插入到了碰撞的地方值，然后B也随后插入到同样的地方，导致线程B会覆盖线程A所插入的值，导致数据丢失。所以，在面试的时候，都很喜欢问HashMap。 "},"pages/Java/base/1266003510239952957.html":{"url":"pages/Java/base/1266003510239952957.html","title":"你知道HashMap底层的数据结构是什么吗?","keywords":"","body":"基本结构 数组 + 链表 + 红黑树 HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫Entry，这些个键值对（Entry）分散存储在一个数组之中，这个数组就是HashMap的主干，HashMap数组每一个元素的初始值都是null。 "},"pages/Java/base/1266003510374170667.html":{"url":"pages/Java/base/1266003510374170667.html","title":"JDK1.8中对hash算法和寻址算法是如何优化的?","keywords":"","body":"源码解析 // JDK1.8以后的HashMap里面的一段源码 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); } 运算 高低16位参与运算: 比如有一个key的hash值: 原值: 1111 1111 1111 1111 1111 1010 0111 1100 右移16位: 0000 0000 0000 0000 1111 1111 1111 1111 异或运算: 1111 1111 1111 1111 0000 0101 1000 0011 -> 转换成int值表示hash值 寻址算法优化: (n - 1) & hash -> 算出数组里的一个位置下标 取模运算性能差一些，为了优化数组寻址过程，数组长度2的n次方，hash & (n – 1)效果跟hash对n取模效果一样，与运算性能更高。核心在于低16的与运算。 hash算法的优化 对每个hash值，在他的低16位中，让高低16位进行了异或，让他的低16位同时保持了高低16位的特征，尽量避免一些hash值后续出现冲突，大家可能会进入数组的同一个位置。 "},"pages/Java/base/1266003510550331466.html":{"url":"pages/Java/base/1266003510550331466.html","title":"你知道HashMap是如何解决hash碰撞问题的吗?","keywords":"","body":"基本结构 链表+红黑树: O(n)和O(logn) 解决方案 利用“拉链法”处理HashCode的碰撞问题；当我们将键值对传递给put方法时，他调用键对象的hashCode()方法来计算hashCode，然后找到bucket（哈希桶）位置来存储对象；当用get方法获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当碰撞发生了，对象将会存储在链表的下一个节点中。hashMap在每个链表节点存储键值对对象。当两个不同的键却有相同的hashCode时，他们会存储在同一个bucket位置的链表中。键对象的equals()来找到键值对。 "},"pages/Java/base/1266003510697132063.html":{"url":"pages/Java/base/1266003510697132063.html","title":"说说HashMap是如何进行扩容的可以吗?","keywords":"","body":"扩容值 2的N次方扩容: 16,32,64... 方案 rehash:如果数组的长度扩容之后 = 32，重新对每个hash值进行寻址，也就是用每个hash值跟新数组的length - 1进行与操作。 n-1 0000 0000 0000 0000 0000 0000 0001 1111 hash1 1111 1111 1111 1111 0000 1111 0000 0101 &结果 0000 0000 0000 0000 0000 0000 0000 0101 = 5(index = 5的位置) n-1 0000 0000 0000 0000 0000 0000 0001 1111 hash2 1111 1111 1111 1111 0000 1111 0001 0101 &结果 0000 0000 0000 0000 0000 0000 0001 0101 = 21(index = 21的位置) 判断二进制结果中是否多出一个bit的1，如果没多，那么就是原来的index，如果多了出来，那么就是index + oldCap，通过这个方式，就避免了rehash的时候，用每个hash对新数组.length取模，取模性能不高，位运算的性能比较高。 "},"pages/Java/base/1266003510818766945.html":{"url":"pages/Java/base/1266003510818766945.html","title":"HashMap默认的初始长度是多少?为什么这么规定?","keywords":"","body":"初始值 HaspMap的默认初始长度是16 原因 每次扩展长度或者手动初始化时，长度必须是2的次幂。之所以是16，是为了服务于从Key值映射到index的hash算法。前面说到了，从Key值映射到数组中所对应的位置需要用到一个hash函数：index = hash(\"Java\");那么为了实现一个尽量分布均匀的hash函数，利用的是Key值的HashCode来做某种运算。因此问题来了，如何进行计算，才能让这个hash函数尽量分布均匀呢？一种简单的方法是将Key值的HashCode值与HashMap的长度进行取模运算，即 index = HashCode(Key)% hashMap.length，但是，但是！这种取模方式运算固然简单，然而它的效率是很低的， 而且，如果使用了取模%， 那么HashMap在容量变为2倍时， 需要再次rehash确定每个链表元素的位置，浪费了性能。因此为了实现高效的hash函数算法，HashMap的发明者采用了位运算的方式。那么如何进行位运算呢？可以按照下面的公式：index = HashCode(Key) & (hashMap.length - 1); "},"pages/Java/base/1266003510948790365.html":{"url":"pages/Java/base/1266003510948790365.html","title":"高并发情况下,HashMap会出现死锁吗?","keywords":"","body":"答案 会 原因 由于HashMap的容量是有限的，如果HashMap中的数组的容量很小，假如只有2个，那么如果要放进10个keys的话，碰撞就会非常频繁，此时一个O(1)的查找算法，就变成了链表遍历，性能变成了O(n)，这是Hash表的缺陷。为了解决这个问题,HashMap设计了一个阈值，其值为容量的0.75，当HashMap所用容量超过了阈值后，就会自动扩充其容量。在多线程的情况下，当重新调整HashMap大小的时候，就会存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历。如果条件竞争发生了，那么就会产生死循环了。 "},"pages/Java/base/1266003511787651113.html":{"url":"pages/Java/base/1266003511787651113.html","title":"ConcurrentHashMap实现线程安全的底层原理到底是什么?","keywords":"","body":"曾经   在ConcurrentHashMap没有出现以前，jdk使用hashtable来实现线程安全，但是hashtable是将整个hash表锁住，所以效率很低下。 ConcurrentHashMap将数据分别放到多个Segment中，默认16个，每一个Segment中又包含了多个HashEntry列表数组，对于一个key， 需要经过三次hash操作，才能最终定位这个元素的位置，这三次hash分别为: 对于一个key，先进行一次hash操作，得到hash值h1，也即h1 = hash1(key)； 将得到的h1的高几位进行第二次hash，得到hash值h2，也即h2 = hash2(h1高几位)，通过h2能够确定该元素的放在哪个Segment； 将得到的h1进行第三次hash，得到hash值h3，也即h3 = hash3(h1)，通过h3能够确定该元素放置在哪个HashEntry。 每一个Segment都拥有一个锁，当进行写操作时，只需要锁定一个Segment，而其它Segment中的数据是可以访问的。 现在 JDK1.8之前，多个数组，分段加锁，一个数组一个锁。JDK1.8之后，优化细粒度，一个数组，每个元素进行CAS，如果失败，则有线程已经用synchronized对元素加锁。链表+红黑树处理，对数组每个元素加锁。多个线程要访问同一个数据，synchronized加锁，CAS去进行安全的累加，去实现多线程场景下的安全的更新一个数据的效果。JDK1.8 [一个大的数组]，数组里每个元素进行put操作，都是有一个不同的锁，刚开始进行put的时候，如果两个线程都是在数组[5]这个位置进行put，这个时候，对数组[5]这个位置进行put的时候，采取的是CAS的策略，同一个时间，只有一个线程能成功执行这个CAS，就是说他刚开始先获取一下数组[5]这个位置的值，是null，然后执行CAS，线程1，比较一下，put进去我的这条数据，同时间，其他的线程执行CAS，都会失败。通过对数组每个元素执行CAS的策略，如果是很多线程对数组里不同的元素执行put，大家是没有关系的，可以并行。如果其他线程失败了，其他线程此时会发现数组[5]这位置，已经给刚才有线程放进去值了，就需要在这个位置基于链表+红黑树来进行处理，synchronized(数组[5])，加锁，基于链表或者是红黑树在这个位置插进去自己的数据，如果你是对数组里同一个位置的元素进行操作，才会加锁串行化处理；如果是对数组不同位置的元素操作，此时大家可以并发执行的。 "},"pages/Java/advance/":{"url":"pages/Java/advance/","title":"进阶","keywords":"","body":""},"pages/Java/advance/1266003511150116913.html":{"url":"pages/Java/advance/1266003511150116913.html","title":"说说synchronized的关键字的底层原理是什么?","keywords":"","body":"实现代码 synchronized(myObject) { // code... synchronized(myObject) { // code... } } 作用 用于线程同步，加锁。可用于类，对象，块。一般是对一个对象进行加锁。synchronize底层原理与JVM指令和monitor有关系。深入涉及CPU硬件原理，原则性、可见性、有序性、指令重排、偏向锁、JDK的对其进行的优化。synchronized关键字，底层编译后的JVM指令中，使用monitorenter和monitorexit指令。monitorenter：加锁,monitorexit：解锁。如果一个线程第一次synchronized那里，获取到了myObject对象的monitor的锁，计数器加1，然后第二次synchronized那里，会再次获取myObject对象的monitor的锁，这个就是重入加锁了，然后计数器会再次加1，变成2。这个时候，其他的线程在第一次synchronized那里，会发现说myObject对象的monitor锁的计数器是大于0的，意味着被别人加锁了，然后此时线程就会进入block阻塞状态，什么都干不了，就是等着获取锁。接着如果出了synchronized修饰的代码片段的范围，就会有一个monitorexit的指令，在底层。此时获取锁的线程就会对那个对象的monitor的计数器减1，如果有多次重入加锁就会对应多次减1，直到最后，计数器是0。 "},"pages/Java/advance/1266003511292723238.html":{"url":"pages/Java/advance/1266003511292723238.html","title":"能聊聊你对CAS的理解以及其底层原理可以吗?","keywords":"","body":"图解 定义 CAS会操作3个数字，当前内存中的值，旧的预期值，新的修改值，只有当旧的预期值跟内存中的值一样的时候，才会将内存中的值修改为新的修改值。举个例子吧，比如int a = 3，这是内存中的当前值，然后你CAS（3, 5），第一个是旧的预期值，如果3和a是一样的，那么就将a修改为5。其实吧，这里比较关键的一点就是cpu的compareAndSwap操作的原理是啥，以CPU（Intel X86）来举个例子。这块底层指令，会根据当前处理器类型，来决定要不要对一个cmpxchg指令加lock前缀，如果是单处理器，就不要加，因为自动保证顺序；但是如果是多处理器，就加个lock。intel对lock的定义，就是说加了lock之后，就会自动锁掉一块内存区域，然后同一时间只有一个处理器可以读写这块内存区域，其他处理器就不行了。 CAS缺点 ABA问题：如果某个值一开始是A，后来变成了B，然后又变成了A，你本来期望的是值如果是第一个A才会设置新值，结果第二个A一比较也ok， 也设置了新值，跟期望是不符合的。所以atomic包里有AtomicStampedReference类，就是会比较两个值的引用是否一致，如果一致，才会设置新值 假设一开始变量i = 1，你先获取这个i的值是1，然后累加了1，变成了2。但是在此期间，别的线程将i -> 1 -> 2 -> 3 -> 1这个期间，这个值是 被人改过的，只不过最后将这个值改成了跟你最早看到的值一样的值。结果你后来去compareAndSet的时候，会发现这个i还是1，就将它设置成了2， 就设置成功了。说实话，用AtomicInteger，常见的是计数，所以说一般是不断累加的，所以ABA问题比较少见 无限循环问题：大家看源码就知道Atomic类设置值的时候会进入一个无限循环，只要不成功，就不停循环再次尝试，这个在高并发修改一个值 的时候其实挺常见的，比如你用AtomicInteger在内存里搞一个原子变量，然后高并发下，多线程频繁修改，其实可能会导致这个compareAndSet()里 要循环N次才设置成功，所以还是要考虑到的。 多变量原子问题：一般的AtomicInteger，只能保证一个变量的原子性，但是如果多个变量呢？你可以用AtomicReference，这个是封装自定 义对象的，多个变量可以放一个自定义对象里，然后他会检查这个对象的引用是不是一个。 "},"pages/Java/advance/1266003511913480288.html":{"url":"pages/Java/advance/1266003511913480288.html","title":"你对JDK中的AQS理解吗?AQS的实现原理是什么?","keywords":"","body":"理解 AQS=Abstract Queue Synchronizer 抽象队列同步器 实现原理 ReentrantLock state变量 -> CAS -> 失败后进入队列等待 -> 释放锁之后唤醒 非公平锁 公平锁 "},"pages/Java/advance/1266003512047697966.html":{"url":"pages/Java/advance/1266003512047697966.html","title":"说说线程池的底层工作原理可以吗?","keywords":"","body":"运行代码 ExecutorService threadPool = Executors.newFixedThreadPool(3); threadPool.submit(new Callable() { public void run() {} }); 执行流程 在创建了线程池后，等待提交过来的任务请求。 在调用execute()方法添加一个请求任务时，线程池会做如下判断: 如果正在运行的线程数量小于corePoolSize=3，那么马上创建线程运行这个任务； 如果正在运行的线程数量大于或等于corePoolSize=3，那么将这个任务放入队列； 如果这时候队列满了且正在运行的线程数量还小于maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务： 如果队列满了且正在运行的线程数量大于或等于maximumPoolSize,那么线程池会启动饱和拒绝策略来执行。 当一个线程完成任务时，它会从队列中去下一个任务来执行。 当一个线程无事可做超过一定的时间（keepAliveTime）时，线程池会判断： 如果当前运行的线程数大于corePoolSize=3，那么这个线程就被停掉。所以线程池的所有任务完成后它最终会收缩到corePoolSize=3的大小。 "},"pages/Java/advance/1266003512169332821.html":{"url":"pages/Java/advance/1266003512169332821.html","title":"那你再说说线程池的核心配置参数都是干什么的?平时我们应该怎么用?","keywords":"","body":"背景 我们创建线程的常见方式一般有继承Thread类以及实现Runnable接口，其实Thread类也是实现了Runnable接口。通过这两种方式创建的线程，在执行完毕之后都会被销毁，这样频繁的创建和销毁线程是一件很浪费资源到的事情。那么，有没有什么办法解决这个问题呢?通过创建线程池就可以解决这个问题。通过线程池创建的线程执行完毕之后并不会销毁，而是会回到线程池继续重复利用，执行其他任务。 核心参数 corePoolSize(核心线程数) 核心线程会一直存在，即使没有任务执行； 当线程数小于核心线程数的时候，即使有空闲线程，也会一直创建线程直到达到核心线程数； 设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭。 queueCapacity(任务队列容量) 也叫阻塞队列，当核心线程都在运行，此时再有任务进来，会进入任务队列，排队等待线程执行。 maxPoolSize(最大线程数) 线程池里允许存在的最大线程数量； 当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务； 线程池里允许存在的最大线程数量。当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务。 keepAliveTime(线程空闲时间) 当线程空闲时间达到keepAliveTime时，线程会退出（关闭），直到线程数等于核心线程数； 如果设置了allowCoreThreadTimeout=true，则线程会退出直到线程数等于零。 allowCoreThreadTimeout(允许核心线程超时) rejectedExecutionHandler(任务拒绝处理器) 当线程数量达到最大线程数，且任务队列已满时，会拒绝任务； 调用线程池shutdown()方法后，会等待执行完线程池的任务之后，再shutdown()。如果在调用了shutdown()方法和线程池真正shutdown()之间提交任务，会拒绝新任务。 线程池参数默认值 corePoolSize = 1 queueCapacity = Integer.MAX_VALUE maxPoolSize = Integer.MAX_VALUE keepAliveTime = 60秒 allowCoreThreadTimeout = false rejectedExecutionHandler = AbortPolicy() ThreadPoolExecutor(线程池)执行顺序 当线程数小于核心线程数时，会一直创建线程直到线程数等于核心线程数； 当线程数等于核心线程数时，新加入的任务会被放到任务队列等待执行； 当任务队列已满，又有新的任务时，会创建线程直到线程数量等于最大线程数； 当线程数等于最大线程数，且任务队列已满时，新加入任务会被拒绝。 ThreadPoolExecutor已经实现4个拒绝策略 AbortPolicy: 直接抛异常 DiscardPolicy: 当前任务会强制调用run先执行，任务将由调用者线程(可能是主线程)去执行。缺点可能会阻塞主线程。 DiscardOldestPolicy: 抛弃任务队列中最旧任务 CallerRunsPolicy: 抛弃当前将要加入队列的任务 自定义: 如果后续慢慢的队列里没任务了，线程空闲了，超过corePoolSize的线程会自动释放掉，在keepAliveTime之后就会释放。 "},"pages/Java/advance/1266003512362270766.html":{"url":"pages/Java/advance/1266003512362270766.html","title":"如果在线程中使用无界阻塞队列会发生什么问题?","keywords":"","body":"问题 因为调用异常，会调用超时，线程处理任务时间是超时时间，线程池等待队列，会变得越来越大，此时会导致内存飙升起来，而且还可能导致OOM，内存溢出或者频繁的GC. "},"pages/Java/advance/1266003512504877152.html":{"url":"pages/Java/advance/1266003512504877152.html","title":"你知道如果线程池的队列满了之后,会发生什么事情吗?","keywords":"","body":"使用线程池的好处 降低资源消耗 —— 可以重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度 —— 当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性 —— 线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控 线程池的工作原理 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则执行第二步。 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里进行等待。如果工作队列满了，则执行第三步 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务 线程池饱和策略 AbortPolicy 为Java线程池默认的阻塞策略，不执行此任务，而且直接抛出一个运行时异常，切记ThreadPoolExecutor.execute需要try catch，否则程序会直接退出。 DiscardPolicy 直接抛弃，任务不执行，空方法。 DiscardOldestPolicy 从队列里面抛弃head的一个任务，并再次execute 此task。 CallerRunsPolicy 在调用execute的线程里面执行此command，会阻塞入口。 用户自定义拒绝策略（最常用） 实现RejectedExecutionHandler，并自己定义策略模式。 Tips 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。 如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。 如果无法将任务加入BlockingQueue（队列已满），则在非corePool中创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。 如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。 ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，尽可能地避免获取全局锁（那将会是一个严重的可伸缩瓶颈）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。 "},"pages/Java/advance/1266003512655872046.html":{"url":"pages/Java/advance/1266003512655872046.html","title":"如果线上机器突然宕机,线程池的阻塞队列中的请求怎么办?","keywords":"","body":"问题 机器宕机，必然会导致线程池里的积压的任务丢失 如何解决? 在提交一个任务到线程池里去，提交之前，将这个任务信息持久化到数据库里，此时的状态为 未提交，提交成功之后，更新任务信息的状态为 提交成功，当任务完成的时候，更新任务信息的状态为 已完成当宕机的机器重启的时候，可以开启一个后台线程，扫描数据库里 未提交和已提交的任务，可以把任务读取出来，重新提交到线程池中，继续进行执行，被调用的方法一定做好幂等操作，防止请求重复执行。 "},"pages/Java/advance/1266003512857198645.html":{"url":"pages/Java/advance/1266003512857198645.html","title":"谈谈你对Java内存模型的理解可以吗?","keywords":"","body":"基本指令 lock、unlock、read、load、use、assign、store、write两个线程同时执行data++; "},"pages/Java/advance/1266003512966250566.html":{"url":"pages/Java/advance/1266003512966250566.html","title":"你知道Java内存模型中的原子性,有序性,可见性是什么?","keywords":"","body":"可见性 定义是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的，也就是一个线程修改的结果。另一个线程马上就能看到。线程1操作i++后，强制线程2操作i时，必须从主内存中刷新更新后的i的值。 e.g: 用volatile修饰的变量，就会具有可见性。volatile修饰的变量不允许线程内部缓存和重排序，即直接修改内存。所以对其他线程是可见的volatile只能让被他修饰内容具有可见性，但不能保证它具有原子性。在 Java 中 volatile、synchronized 和 final 实现可见性 原子性:原子是世界上的最小单位，具有不可分割性 在Java中synchronized和在 lock、unlock 中操作保证原子性。线程1对i++时，线程2不能对i++同时进行。同时刻只有一个线程对一个值进行操作。i++必须独立执行，但默认时线程不安全的。 有序性:Java 语言提供了 volatile 和 synchronized 两个关键字来保证线程之间操作的有序性 volatile 是因为其本身包含“禁止指令重排序”的语义，synchronized 是由“一个变量在同一个时刻只允许一条线程对其进行 lock操作”这条规则获得的，此规则决定了持有同一个对象锁的两个同步块只能串行执行。对于代码，还有一个问题时指令重排序，编译器和指令器，有时候为了提高代码执行效率，会将指令重排序。具备有序性，不会发生指令重排导致代码异常；不具有有序性，会发生指令重排，导致代码可能会出现一些问题。 volatile关键字用法 public class Counter { public volatile static int count = 0; public static void inc() { //这里延迟1毫秒，使得结果明显 try { Thread.sleep(1); } catch (InterruptedException e) { } count++; } public static void main(String[] args) { //同时启动1000个线程，去进行i++计算，看看实际结果 for (int i = 0; i 由于volatile具有可见性，在不并发的情况下是1000，实际输出只有994，由于并发原因。 "},"pages/Java/advance/1266003513092079621.html":{"url":"pages/Java/advance/1266003513092079621.html","title":"能能从Java底层角度聊聊volatile关键字的原理吗?","keywords":"","body":"原理 volatile用来解决可见性和有序性，在有些罕见条件下，可以有限保证原则性，但主要不是保证原则性的。讲volatile要从内存模型开始讲起，还有原子性，可见性，有序性。使其他工作线程内存中的值缓存失效，强制从主内存中读取新值，即可见性。在很多开源中间件系统源码里都有多线程并发，大量使用volatile关键字。 "},"pages/Java/advance/1266003513297600516.html":{"url":"pages/Java/advance/1266003513297600516.html","title":"你知道指令重排以及happens-before原则是什么吗?","keywords":"","body":"指令重排 定义:   Java语言规范规定了JVM线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致。这个过程通过叫做指令的重排序。指令重排序存在的意义在于：JVM能够根据处理器的特性（CPU的多级缓存系统、多核处理器等）适当的重新排序机器指令，使机器指令更符合CPU的执行特点，最大限度的发挥机器的性能。 背景:   我们知道现代CPU的主频越来越高，与cache的交互次数也越来越多。当CPU的计算速度远远超过访问cache时，会产生cache wait，过多的cache wait就会造成性能瓶颈。针对这种情况，多数架构（包括X86）采用了一种将cache分片的解决方案，即将一块cache划分成互不关联地多个 slots (逻辑存储单元，又名 Memory Bank 或 Cache Bank)，CPU可以自行选择在多个 idle bank 中进行存取。这种 SMP 的设计，显著提高了CPU的并行处理能力，也回避了cache访问瓶颈。   一般 Memory bank 是按cache address来划分的。比如 偶数adress 0×12345000 分到 bank 0, 奇数address 0×12345100 分到 bank1 种类: 编译期重排。编译源代码时，编译器依据对上下文的分析，对指令进行重排序，以之更适合于CPU的并行执行。 运行期重排，CPU在执行过程中，动态分析依赖部件的效能，对指令做重排序优化。 happens-before原则 定义:   Java存储模型有一个happens-before原则，就是如果动作B要看到动作A的执行结果（无论A/B是否在同一个线程里面执行），那么A/B就需要满足happens-before关系。 要求: 同一个线程中的每个Action都happens-before于出现在其后的任何一个Action。 对一个监视器的解锁happens-before于每一个后续对同一个监视器的加锁。 对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。 Thread.start()的调用会happens-before于启动线程里面的动作。 Thread中的所有动作都happens-before于其他线程检查到此线程结束或者Thread.join（）中返回或者Thread.isAlive()==false。 一个线程A调用另一个另一个线程B的interrupt（）都happens-before于线程A发现B被A中断（B抛出异常或者A检测到B的isInterrupted（）或者interrupted()）。 一个对象构造函数的结束happens-before与该对象的finalizer的开始 如果A动作happens-before于B动作，而B动作happens-before与C动作，那么A动作happens-before于C动作。 理解:happens-before规则是用来判断一个动作对另一个动作是否可见的法则，它只是用来判断可见性的，而不是决定执行顺序的，就是说动作A和动作B 的执行顺序是可以通过指令重排发生变化的，而如果你要保证A和B的可见性关系，就必须采用其他控制手段（比如volatile修饰属性）来保证AB的执行顺序不被打乱，这样就能用happens-before规则来判断AB两个动作的可见性。 "},"pages/Java/senior/":{"url":"pages/Java/senior/","title":"高级","keywords":"","body":""},"pages/Java/senior/1266003515533164602.html":{"url":"pages/Java/senior/1266003515533164602.html","title":"JVM中有哪几块内存区域?Java8之后对内存做了什么改进?","keywords":"","body":"图解 区域 物理内存Metaspace(除jvm占用的内存,剩余的内存空间都可以被Metaspace占用) 方法区(常量,即时编译后的代码) 年轻代(eden space, from survivor, to survivor) 老年代 程序计数器PC 虚拟机栈(局部变量表, 操作数栈, 方法返回地址, 动态链接, 额外附加信息) 本地方法栈   Java 8以后的内存分代的改进，永久代里放了一些常量池+类信息，常量池 -> 堆里面，类信息 -> metaspace（元区域）。 "},"pages/Java/senior/1266003515960983567.html":{"url":"pages/Java/senior/1266003515960983567.html","title":"你知道JVM是如何运行起来的吗?我们的对象是如何分配的?","keywords":"","body":"图解 原理   有一个类里面包含了一个main方法，你去执行这个main方法，此时会启动一个jvm进程，他会默认就会有一个main线程，这个main线程就负责执行这个main方法的代码，进而创建各种对象。一般tomcat，类都会加载到jvm里去，spring容器而言都会对我们的类进行实例化成bean，有工作线程会来执行我们的bean实例对象里的方法和代码，进而也会创建其他的各种对象，实现业务逻辑。 "},"pages/Java/senior/1266003516292333626.html":{"url":"pages/Java/senior/1266003516292333626.html","title":"说说JVM在哪些情况下会触发垃圾回收可以吗?","keywords":"","body":"图解 条件 对象没有引用 作用域发生未捕获异常 程序在作用域正常执行完毕 程序执行了System.exit() 程序发生意外终止(被杀进程等) Tips   JVM的内存其实是有限制的，不可能是无限的，昂贵的资源，2核4G的机器，堆内存也就2GB左右，4核8G的机器，堆内存可能也就4G左右，栈内存也需要空间，metaspace区域放类信息也需要空间。在jvm里必然是有一个内存分代模型，年轻代和老年代。给年轻代一共是2GB内存，给老年代是2GB内存，默认情况下eden和2个s的比例：8:1:1，eden是1.6GB，S是0.2GB。如果说eden区域满了，此时必然触发垃圾回收，young gc(ygc)，没有人引用的对象就是垃圾对象。 "},"pages/Java/senior/1266003516485271593.html":{"url":"pages/Java/senior/1266003516485271593.html","title":"说说JVM的年轻代垃圾回收算法?对象什么时候转移到老年代?","keywords":"","body":"图解 何时   年轻代，大部分情况下，对象生存周期是很短的，可能在0.01ms之内，线程执行了3个方法，创建了几个对象，0.01ms之后就方法都执行结束了，此时那几个对象就会在0.01ms之内变成垃圾，可以回收的100个对象，可能90个对象都是垃圾对象，10个对象是存活的对象，5个复制算法，一次young gc，年轻代的垃圾回收。有的对象在年轻代里熬过了很多次垃圾回收，15次垃圾回收，此时会认为这个对象是要长期存活的对象，移到老年代。 "},"pages/Java/senior/1266003516749512749.html":{"url":"pages/Java/senior/1266003516749512749.html","title":"说说老年代的垃圾回收算法?常用的垃圾回收器都有什么?","keywords":"","body":" 对老年代而言，他里面垃圾对象可能是没有那么多的。 标记-清理   找出来那些垃圾对象，然后直接把垃圾对象在老年代里清理掉。 标记-整理   把老年代里的存活对象标记出来，移动到一起，存活对象压缩到一片内存空间里去。剩余的空间都是垃圾对象整个给清理掉，剩余的都是连续的可用的内存空间，解决了内存碎片的一个问题。 parnew+cms的组合   g1直接分代回收，新版本，慢慢的就是主推g1垃圾回收器了，以后会淘汰掉parnew+cms的组合，jdk 8~jdk 9比较居多一些，parnew+cms的组合比较多一些。 CMS   分成好几个阶段，刚开始用标记-清理，标记出垃圾对象，并发清理一些垃圾对象，整理，把存活的对象压缩到一起，避免内存碎片的产生。执行一个比较慢的垃圾回收，会stop the world，需要100mb，此时会导致系统停顿100ms，不能处理任何请求，应该尽可能垃圾回收和工作线程的运行，并发执行。 "},"pages/Java/senior/1266003516866953280.html":{"url":"pages/Java/senior/1266003516866953280.html","title":"你们生产环境中的Tomcat是如何设置JVM参数的?如何检查JVM运行情况?","keywords":"","body":"你们线上系统jvm参数是怎么配置的,为什么要这样配置,在这个配置参数之下,线上系统jvm运行情况如何?   一般web系统部署到tomcat，系统仅仅在tomcat的jvm进程来执行。tomcat有一个配置脚本，catalina对应有启动的一些jvm参数设置。主要是内存区域大小的分配，每个线程的栈大小，metaspace的大小，堆内存大小，年轻代和老年代分别大小，eden和survivor区域的大小分别是多少，如果没有设置，会有一个默认值。垃圾回收器，年轻代，老年代分别使用哪种垃圾回收器，每种垃圾回收器是否有对应的一些特殊参数设置，这些设置都是用来干什么的。 为什么要这样设置?jvm表现如何?   在一定业务背景下，进行系统运行时的对象数量的预估，对内存压力进行预估，对整个jvm运行状况进行预估，预估完毕之后，根据预估情况，可以去设置一些jvm参数，然后进行压测，压测时候，需要观察Jvm运行情况，jstat工具去分析jvm运行情况，年轻代的eden区域的对象增长情况，ygc的频率，每次ygc过后多少对象存活，survivor区能否放的下，老年代对象增加速率，老年代多久会触发一次fgc。可以根据压测的情况进行一定的jvm参数的调优。压测主要两点：一个系统QPS，一个是系统的接口性能。压测到一定程度时，了解机器的cpu, 内存，io, 磁盘的负载情况，jvm的表现等，由此需要对一些代码进行优化，比如优化性能，或减轻cpu, io磁盘负担等，如果发现jvm的gc过于频繁，内存泄漏，需要对jvm各内存区域的大小以及一些参数进行调优。在线上生产环境时，也需要基于一些监控工具，或者jstat，观察系统的QPS和性能，接口可用性，调用成功率，机器负载，jvm表现，gc频率，耗时，内存消耗等等。 "},"pages/Java/senior/1266003516984393818.html":{"url":"pages/Java/senior/1266003516984393818.html","title":"你在实际项目中是否做过JVM GC优化,怎么做的?","keywords":"","body":"背景   如果jvm出频繁full gc，有没有尝试过生产环境的系统去进行gc优化，对于这个问题，需要结合具体业务来分析。如何一步一步去分析系统的jvm的性能问题，如何去进行jvm gc调优? 分不同情况 自己做过jvm gc的生产调优，恭喜你了，直接实话实说，你当时怎么调优，你们的问题如何暴露出来的，你如何一步一步定位问题的，如何进行调优，最后的结果是什么? 你看了jvm专栏，在过程中，或者看完以后，在自己生产环境中根据专栏学习到的知识，去调优过jvm，这个时候，你可以专栏里学习到的知识，去讲。最好对自己系统的生产环境的jvm，进行一个分析，gc频繁的问题，尽可能的去调优一下参数。 发现分析了一下生产环境的jvm的运行情况，非常好，并发量很低，几十分钟才一次young gc，存活的对象特别少，几乎都在s区域，老年代几乎没什么对象，几天或者几周才发生一次full gc，在自己本地单机部署，测试环境里，去压测，每秒单机有500并发请求，去观察jvm的运行情况，这个时候他会不会存在频繁gc的问题，你就去调优一下，你就可以基于这个压测的例子去讲解。 "},"pages/Java/senior/1266003517114417182.html":{"url":"pages/Java/senior/1266003517114417182.html","title":"你知道发生OOM之后,应该如何排查和处理线上系统的OO...","keywords":"","body":"年老代堆空间被占满 异常java.lang.OutOfMemoryError: java heap space 说明这是最典型的内存泄漏方式，简单说就是所有堆空间都被无法回收的垃圾对象占满，虚拟机再也无法分配新空间 解决这种方式解决起来比较简单，一般就是根据垃圾回收前后的情况对比，同时根据对象引用情况（常见的集合对象引用）分析，基本都可以找到泄漏点。 持久代被占满 异常java.lang.OutOfMemoryError：PermGen space 说明Perm 空间被占满，无法为新的 class 分配存储空间而引发的异常。这个异常以前是没有的，但是在 java 大量使用反射的今天这个异常就比较常见了。 主要原因大量动态反射生成的类不断被加载，最终导致 Perm 区被占满。更可怕的是，不同的 classLoader 即便使用相同的类，但是都会对其进行加载，相当于同一个东西，如果有 N 个classLoader 那么它将会被加载 N 次。因此，在某些情况下，这个问题基本视为无解，当然，存在大量 classLoader 和大量反射类的情况并不多。 解决增加持久代内存 ，例如：-XX：MaxPermSize=16M 思考OOM可能发生在哪几个区域? 解决思路，在jvm里设置几个参数，一旦发生oom之后，就会导出一份内存快照，就会有当时线上内存里对象的一个情况，可以用MAT（eclipse的一个插件(MAT也可以单独使用)）这样的工具进行分析。无非就是找出来当时占用内存最大的对象，找出来这些对象在代码中哪些地方创建出来的，一般来说就是可能会对内存做一个调优。从业务背景出发，一步一步的说明，在什么样的业务背景下，为什么会产生oom的问题？当某个系统崩溃时，找到自动导出的内存快照，分析XX 对象，直接定位代码，修改代码。你一定要把案例的业务、背景和思想给吸收了，就得融入到自己的业务里去，我负责的业务系统，在什么样的情况下，可能说会出现一大批的对象卡在内存里，无法回收，导致我系统没法放更多的对象了。oom不是你自己的代码，可能是你依赖的第三方的组件，结合自己的项目去一步一步的分析，oom问题的产生，和解决的过程。 "},"pages/Spring/":{"url":"pages/Spring/","title":"Spring","keywords":"","body":""},"pages/Spring/1266003513490538513.html":{"url":"pages/Spring/1266003513490538513.html","title":"说说你对Spring的IOC机制的理解可以吗?","keywords":"","body":"没有Spring之前 写一套系统，web服务器，tomcat，一旦启动之后，他就可以监听一个端口号的http请求，然后可以把请求转交给你的servlet，jsp，配合起来使用的，servlet处理请求。比如在我们的一个tomcat + servlet的这样的一个系统里，有几十个地方，都是直接用MyService myService = new MyServiceImpl()，直接创建、引用和依赖了一个MyServiceImpl这样的一个类的对象。这个系统里，有几十个地方，都跟MyServiceImpl类直接耦合在一起了。如果我现在不想要用MyServiceImpl了，我们希望用的是NewServiceManagerImpl，implements MyService这个接口的，所有的实现逻辑都不同了，此时我们很麻烦，我们需要在系统里，几十个地方，都去修改对应的MyServiceImpl这个类，切换为NewServiceManagerImpl这个类。改动代码成本很大，改动完以后的测试的成本很大，改动的过程中可能很复杂，出现一些bug，此时就会很痛苦。归根结底，代码里，各种类之间完全耦合在一起，出现任何一丁点的变动，都需要改动大量的代码，重新测试，可能还会有bug。 有Spring之后 Spring IoC, Spring容器，根据XML配置或注解，去实例化你的一些bean对象，然后根据XML或注解，去对bean对象之间的引用关系，去进行依赖注入。底层核心技术是反射。通过反射技术，直接根据你的类去自己构建对应的对象出来。 "},"pages/Spring/1266003513670893618.html":{"url":"pages/Spring/1266003513670893618.html","title":"说说你对Spring的AOP机制的理解可以吗?","keywords":"","body":"定义 AOP（Aspect Orient Programming），一般称为面向切面编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态代理则以Spring AOP为代表。静态代理是编译期实现，动态代理是运行期实现，可想而知前者拥有更好的性能。 代理类型 静态代理是编译阶段生成AOP代理类，也就是说生成的字节码就织入了增强后的AOP对象；动态代理则不会修改字节码，而是在内存中临时生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。 动态代理 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB(Code Generation Library)，是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的，诸如private的方法也是不可以作为切面的。 "},"pages/Spring/1266003513821888530.html":{"url":"pages/Spring/1266003513821888530.html","title":"了解过cglib动态代理吗?他和jdk动态代理的区别什么?","keywords":"","body":"jdk动态代理 需要有顶层接口才能使用，但是在只有顶层接口的时候也可以使用，常见是mybatis的mapper文件是代理。使用反射完成。使用了动态生成字节码技术。 cglib动态代理 可以直接代理类，使用字节码技术，不能对 final 类进行继承。使用了动态生成字节码技术。 区别 动态代理就是动态的创建一个代理类出来，创建这个代理类的实例对象，在这个里面引用你真正自己写的类，所有的方法的调用，都是先走代理类的对象，他负责做一些代码上的增强，再去调用你写的那个类。Spring里使用aop，比如说你对一批类和他们的方法做了一个切面，定义好了要在这些类的方法里增强的代码，Spring必然要对那些类生成动态代理，在动态代理中去执行你定义的一些增强代码。如果你的类是实现了某个接口的，spring aop会使用jdk动态代理，生成一个跟你实现同样接口的一个代理类，构造一个实例对象出来，jdk动态代理，他其实是在你的类有接口的时候，就会来使用。很多时候我们可能某个类是没有实现接口的，spring aop会改用cglib来生成动态代理，他是生成你的类的一个子类，他可以动态生成字节码，覆盖你的一些方法，在方法里加入增强的代码。"},"pages/Spring/1266003513964494868.html":{"url":"pages/Spring/1266003513964494868.html","title":"能说说Spring中的Bean是线程安全的吗?","keywords":"","body":"singleton(默认) 单例模式，在整个Spring IoC容器中，使用singleton定义的Bean将只有一个实例。 prototype 原型模式，每次通过容器的getBean方法获取prototype定义的Bean时，都将产生一个新的Bean实例，一般来说下面几种作用域，在开发的时候一般都不会用，99.99%的时候都是用singleton单例作用域。 request 对于每次HTTP请求，使用request定义的Bean都将产生一个新实例，即每次HTTP请求将会产生不同的Bean实例。只有在Web应用中使用Spring时，该作用域才有效，在请求完成以后，bean会失效并被垃圾回收器回收。 session 对于每次HTTP Session，使用session定义的Bean豆浆产生一个新实例。同样只有在Web应用中使用Spring时，该作用域才有效，在session过期后，bean会随之失效。 globalsession 每个全局的HTTP Session，使用session定义的Bean都将产生一个新实例。典型情况下，仅在使用portlet context的时候有效。同样只有在Web应用中使用Spring时，该作用域才有效。 Tips 其中比较常用的是singleton和prototype两种作用域。对于singleton作用域的Bean，每次请求该Bean都将获得相同的实例。容器负责跟踪Bean实例的状态，负责维护Bean实例的生命周期行为；如果一个Bean被设置成prototype作用域，程序每次请求该id的Bean，Spring都会新建一个Bean实例，然后返回给程序。在这种情况下，Spring容器仅仅使用new 关键字创建Bean实例，一旦创建成功，容器不在跟踪实例，也不会维护Bean实例的状态。如果不指定Bean的作用域，Spring默认使用singleton作用域。Java在创建Java实例时，需要进行内存申请；销毁实例时，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此，prototype作用域Bean的创建、销毁代价比较大。而singleton作用域的Bean实例一旦创建成功，可以重复使用。因此，除非必要，否则尽量避免将Bean被设置成prototype作用域。 spring管理的bean的线程安全跟bean的创建作用域和bean所在的使用环境是否存在竞态条件有关，spring并不能保证bean的线程安全。 "},"pages/Spring/1266003514161627157.html":{"url":"pages/Spring/1266003514161627157.html","title":"Spring的事务实现原理是什么?能聊聊你对事物传播机制的...","keywords":"","body":"[测试用例]https://blog.csdn.net/qq_26323323/article/details/81908955 实现原理 加一个@Transactional注解，Spring会使用AOP，对这个方法在执行前，先开启事务，在执行完毕后，根据方法是否报错，来决定是回滚还是提交事务。 传播机制 @Transactional(propagation=Propagation.REQUIRED) (默认)如果有事务则加入事务，如果没有事务，则创建一个新的(默认值) @Transactional(propagation=Propagation.NOT_SUPPORTED)Spring不为当前方法开启事务，相当于没有事务,每条执行语句单独执行，单独提交 @Transactional(propagation=Propagation.REQUIRES_NEW)不管是否存在事务，都创建一个新的事务，原来的方法挂起，新的方法执行完毕后，继续执行老的事务 @Transactional(propagation=Propagation.MANDATORY)MANDATORY必须在已有事务下被调用，否则报错;NOT_SUPPORTED执行数据库层面的事务操作，故当前测试中，insert方法成功执行，delete方法的抛错并不影响insert方法的执行 @Transactional(propagation=Propagation.SUPPORTS)SUPPORTS类型的事务传播机制，是否使用事务取决于调用方法是否有事务，如果有则直接用，如果没有则不使用事务 @Transactional(propagation=Propagation.NESTED)如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与REQUIRED类似的操作 "},"pages/Spring/1266003514312622174.html":{"url":"pages/Spring/1266003514312622174.html","title":"能画一张图说说Spring Boot的核心架构吗?","keywords":"","body":"图解 结构特征 独立运行Spring项目Spring boot 可以以jar包形式独立运行，运行一个Spring Boot项目只需要通过java -jar xx.jar来运行。 内嵌servlet容器Spring Boot可以选择内嵌Tomcat、jetty或者Undertow,这样我们无须以war包形式部署项目。 提供starter简化Maven配置spring提供了一系列的start pom来简化Maven的依赖加载，例如，当你使用了spring-boot-starter-web，会自动加入依赖包。 自动装配Spring SpringBoot会根据在类路径中的jar包，类、为jar包里面的类自动配置Bean，这样会极大地减少我们要使用的配置。当然，SpringBoot只考虑大多数的开发场景，并不是所有的场景，若在实际开发中我们需要配置Bean，而SpringBoot灭有提供支持，则可以自定义自动配置。 准生产的应用监控SpringBoot提供基于http ssh telnet对运行时的项目进行监控。 无代码生产和xml配置SpringBoot不是借助与代码生成来实现的，而是通过条件注解来实现的，这是Spring4.x提供的新特性。 "},"pages/Spring/1266003514547503179.html":{"url":"pages/Spring/1266003514547503179.html","title":"能画一张图说说Spring的核心架构吗?","keywords":"","body":"生命周期 Spring生命周期: 创建 -> 使用 -> 销毁；用xml或注解，定义一堆bean。 流程 实例化bean 通过反射创建bean对象实例。 设置对象属性(依赖注入)   实例化后的对象被封装在BeanWrapper对象中，Spring根据BeanDefinition中的信息以及通过BeanWrapper提供的设置属性接口完成依赖注入。这个bean依赖了谁，把依赖的bean也创建出阿里，给你进行一个注入，比如通过构造函数或setter方法。 处理Aware接口 Spring检查该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给Bean。 如果这个Bean实现了BeanNameAware接口，则调用它的实现setBeanName(String beanid)方法，传递就是Spring配置文件中的Bean的id值； 如果这个Bean实现了BeanFactoryAware接口，则调用它实现的setBeanFactory()方法，传递的是Spring工厂自身； 如果这个Bean实现了ApplicationContextAware接口，则调用setApplicationContext(ApplicationContext)方法，传入Spring上下文； BeanPostProcessor   如果想在bean实例构建之后，在这个时间点对bean进行自定义处理，则可以让bean实现BeanPostProcessor接口，会调用postProcessBeforeInitialiazation(Object obj, String s)方法。 InitalizingBean与init-method   如果bean在Spring配置文件中配置了init-method属性，则会自动调用其配置的初始化方法。 BeanPostProcessor   在bean初始化完成后，如果这个bean实现了BeanPostProcessor接口，会调用postProcessAfterInitialization(Object obj, String s)方法。 DisposableBean   当bean不再需要时，如果bean实现了DisposableBean接口，会调用其他实现的destroy()方法。 destroy-method   如果配置了destroy-method属性，会调用配置的销毁方法。 "},"pages/Spring/1266003514706886713.html":{"url":"pages/Spring/1266003514706886713.html","title":"能说说Spring中都使用了哪些设计模式吗?","keywords":"","body":"工厂模式   Spring IOC核心的设计模式的思想提现，他自己就是一个大的工厂，把所有的bean实例都给放在了spring容器里（大工厂），如果你要使用bean，就找spring容器就可以了，你自己不用创建对象了。 单例模式   Spring默认来说，对每个bean走的都是一个单例模式，确保说你的一个类在系统运行期间只有一个实例对象，只有一个bean，用到了一个单例模式的思想，保证了每个bean都是单例的。 代理模式   如果说你要对一些类的方法切入一些增强的代码，会创建一些动态代理的对象，让你对那些目标对象的访问，先经过动态代理对象，动态代理对象先做一些增强的代码，调用你的目标对象。 "},"pages/Spring/1266003514803355688.html":{"url":"pages/Spring/1266003514803355688.html","title":"能画一张图说说Spring Web MVC的核心架构吗?","keywords":"","body":"图解 流程 Tomcat的工作线程将请求转交给spring mvc框架的DispatcherServlet DispatcherServlet查找@Controller注解的controller，我们一般会给controller加上你@RequestMapping的注解，标注说哪些controller用来处理哪些请求，此时根据请求的uri，去定位到哪个controller来进行处理。 根据@RequestMapping去查找，使用这个controller内的哪个方法来进行请求的处理，对每个方法一般也会加@RequestMapping的注解。 会直接调用我们的controller里面的某个方法来进行请求的处理。 我们的controller的方法会有一个返回值，以前的时候，一般来说还是走jsp、模板技术，我们会把前端页面放在后端的工程里面，返回一个页面模板的名字，spring mvc的框架使用模板技术，对html页面做一个渲染(现在一般返回一个json串，前后端分离，可能前端发送一个请求过来，我们只要返回json数据。) "},"pages/SpringCloud/":{"url":"pages/SpringCloud/","title":"Spring Cloud","keywords":"","body":""},"pages/SpringCloud/1266003503914942509.html":{"url":"pages/SpringCloud/1266003503914942509.html","title":"你们的系统使用了哪种服务框架?为什么要这样技术选型?","keywords":"","body":"Spring Cloud && Dubbo对比 区别 并发性能 注册中心 分布式配置中心 网关 负载均衡 熔断功能 社区活跃度 Spring 使用的是http协议,性能与dubbo对比稍微差点 有全家桶配置中心: eurake nacos,亦可以选择zookeeper nacos / spring cloud config zuul / srping cloud gateway ribbon hystrix 活跃,版本更新快 Dubbo 是一款优秀的RPC框架,并发能力比springcloud强 一般选择zookeeper 阿波罗 需引入其他网关组件 自带负载均衡 需引入其他熔断框架 不活跃 Tips 所以现在一般都会选择spring cloud全家桶做微服务，因为spring cloud胜在功能更全，有一些列可以开箱即用的组件，满足服务化后的各种场景需求。或者说dubbo就是一个纯正的RPC框架，对于服务之间远程调用，性能非常优秀，并发高，响应快，但是也仅仅是一个RPC框架，如果需要其他的功能，则需要引入其他的组件，因此在引入其他组件的过程中，可能会带来更多的问题。所以对于易用性这一块，spring cloud已经集成了各方面微服务所需要的组件，上手更快，拆坑更少，团队上手更容易，学习成本更低。可以开箱即用，快速上手。 "},"pages/SpringCloud/1266003504225320982.html":{"url":"pages/SpringCloud/1266003504225320982.html","title":"看过Dubbo源码吗?说说Dubbo的底层架构原理?","keywords":"","body":"简介 Dubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合(或者最大限度地松耦合)。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方(Provider)和服务消费方(Consumer)两个角色。 是什么 简单说呢，Dubbo用起来就和EJB、WebService差不多，调用一个远程的服务(或者JavaBean)的时候在本地有一个接口，就像调用本地的方法一样去调用，它底层帮你实现好你的方法参数传输和远程服务运行结果传回之后的返回，就是RPC的一种封装啦~ 特点 它主要是使用高效的网络框架和序列化框架，让分布式服务之间调用效率更高。 采用注册中心管理众多的服务接口地址，当你想调用服务的时候只需要跟注册中心询问即可，不用像使用WebService一样每个服务都得记录好接口调用方式。注册中心主要就是负责dubbo的所有服务地址列表维护，并且可以通过在ZooKeeper节点中设置相应的值来实现对这个服务的权重、优先级、是否可用、路由、权限等的控制。之后在Dubbo的管理控制台对服务的一堆治理策略设置和调整，实际上就是修改了注册中心中的服务对应的配置数据(即修改了zookeeper中服务对应的节点的配置数据)。之后Consumer从注册中心请求到服务的数据时就能根据这些配置数据进行相应的治理配置参数的代码执行生效。 监控中心实现对服务方和调用方之间运行状态的监控，还能控制服务的优先级、权限、权重、上下线等，让整个庞大的分布式服务系统的维护和治理比较方便。 高可用有个服务宕机了?注册中心就会从服务列表去掉该节点。还是调用到了?客户端会向注册中心请求另一台可用的服务节点重新调用。注册中心宕机?注册中心也能实现高可用(ZooKeeper)。 负载均衡：采用软负载均衡算法实现对多个相同服务的节点的请求负载均衡。 RPC之Dubbo实现 主要为三点，动态代理、反射、socket网络编程 客户端使用动态代理的方式，“假装”实现了createOrder方法。 方法相关的数据通过序列化，进入到socket服务器。dubbo的socket实现为Netty。 服务端从socket服务器取出数据，通过反射的方式找到“真实”的服务实现。 服务端的方法在服务启动时已注入。 服务发现层，可用zookeeper。zookeeper保证了CP(一致性，分区容错性)。缺点：master节点挂掉时，需要时间重新选择master，这段时间内注册中心将不可用。 注意：服务端可消费端注册成功后，通讯只走socket服务器，不会经过注册中心。 核心技术简介 客户端发起接口调用； 服务中间件进行路由选址：找到具体接口实现的服务地址； 客户端将请求信息进行编码(序列化: 方法名，接口名，参数，版本号等)； 建立与服务端的通讯(不是调度中心，而是客户端与服务端直连)； 服务端将接收到的信息进行反编码(反序列化)； 根据信息找到服务端的接口实现类； 将执行结果反馈给客户端。 "},"pages/SpringCloud/1266003504359538773.html":{"url":"pages/SpringCloud/1266003504359538773.html","title":"咱们来聊点深入的,说说Dubbo底层的网络通信机制原理?","keywords":"","body":"基本信息 连接个数: 单连接 连接方式: 长连接 传输协议: TCP 传输方式: NIO异步传输 序列化: Hessian二进制序列化 适用范围： 传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。 适用场景: 常规远程服务方法调用 同步远程调用 客户端线程调用远程接口，向服务端发送请求，同时当前线程应该处于“暂停”状态，即线程不能向后执行了，必需要拿到服务端给自己的结果后才能向后执行； 服务端接到客户端请求后，处理请求，将结果给客户端； 客户端收到结果，然后当前线程继续往后执行； 基本原理 client一个线程调用远程接口，生成一个唯一的ID（比如一段随机字符串，UUID等），Dubbo是使用AtomicLong从0开始累计数字的； 将打包的方法调用信息（如调用的接口名称，方法名称，参数值列表等），和处理结果的回调对象callback，全部封装在一起，组成一个对象object； 向专门存放调用信息的全局ConcurrentHashMap里面put(ID, object)； 将ID和打包的方法调用信息封装成一对象connRequest，使用IoSession.write(connRequest)异步发送出去； 当前线程再使用callback的get()方法试图获取远程返回的结果，在get()内部，则使用synchronized获取回调对象callback的锁， 再先检测是否已经获取到结果，如果没有，然后调用callback的wait()方法，释放callback上的锁，让当前线程处于等待状态； 服务端接收到请求并处理后，将结果（此结果中包含了前面的ID，即回传）发送给客户端，客户端socket连接上专门监听消息的线程收到消息，分析结果，取到ID，再从前面的ConcurrentHashMap里面get(ID)，从而找到callback，将方法调用结果设置到callback对象里； 监听线程接着使用synchronized获取回调对象callback的锁（因为前面调用过wait()，那个线程已释放callback的锁了），再notifyAll()，唤醒前面处于等待状态的线程继续执行（callback的get()方法继续执行就能拿到调用结果了,这里的callback对象是每次调用产生一个新的，不能共享，否则会有问题；另外ID必需至少保证在一个Socket连接里面是唯一的。），至此，整个过程结束。 当前线程怎么让它\"暂停\",等结果回来后,再向后执行? 答: 先生成一个对象obj，在一个全局map里put(ID,obj)存放起来，再用synchronized获取obj锁，再调用obj.wait()让当前线程处于等待状态，然后另一消息监听线程等到服务端结果来了后，再map.get(ID)找到obj，再用synchronized获取obj锁，再调用obj.notifyAll()唤醒前面处于等待状态的线程。 正如前面所说,Socket通信是一个全双工的方式,如果有多个线程同时进行远程方法调用,这时建立在client server之间的socket连接上会有很多双方发送的消息传递,前后顺序也可能是乱七八糟的,server处理完结果后,将结果消息发送给client,client收到很多消息,怎么知道哪个消息结果是原先哪个线程调用的? 答: 使用一个ID，让其唯一，然后传递给服务端，再服务端又回传回来，这样就知道结果是原先哪个线程的了。 "},"pages/SpringCloud/1266003504476979219.html":{"url":"pages/SpringCloud/1266003504476979219.html","title":"Dubbo框架从架构设计角度,是怎么保证极高的可扩展性?","keywords":"","body":"Dubbo SPI特点 对Dubbo进行扩展，不需要改动Dubbo的源码。 自定义的Dubbo的扩展点实现，是一个普通的Java类，Dubbo没有引入任何Dubbo特有的元素，对代码侵入性几乎为零。 将扩展注册到Dubbo中，只需要在ClassPath中添加配置文件。使用简单。而且不会对现有代码造成影响。符合开闭原则。 Dubbo的扩展机制支持IoC,AoP等高级功能。 Dubbo的扩展机制能很好的支持第三方IoC容器，默认支持Spring Bean，可自己扩展来支持其他容器，比如Google的Guice。 切换扩展点的实现，只需要在配置文件中修改具体的实现，不需要改代码。使用方便。 Dubbo底层架构原理图 "},"pages/SpringCloud/1266003504686694408.html":{"url":"pages/SpringCloud/1266003504686694408.html","title":"如果让你设计一个RPC框架,网络通信 代理机制 负载均衡?","keywords":"","body":"什么是RPC RPC的全称是Remote Procedure Call，远程过程调用。RPC框架有很多，比如hsf、dubbo等等。借助RPC框架，我们在写业务代码的时候可以不需要去考虑服务之间的通信等问题，在调用远程服务的时候就像调用本地的方法那么简单。 组成部分 简化本地调用流程既然我们要像调用本地方法那样调用远程服务， 那么就应该生成代理来隐藏调用远程服务的细节。 这些细节包括但不限于以下所列出的关注点。 服务发现与服务注册 如果我们想在Service A中调用Service B，那么我们首先得知道Service B的地址。 所以，我们需要有一个服务注册中心，通过这个中心，服务可以把自己的信息注册进来，也可以获取到别的服务的信息。 客户端也需要watch服务注册中心的目标服务的地址的变化。 网络通信 服务和服务之间的网络通信模型， NIO/IO等等 客户端如何复用与服务端的连接， 而不是每次请求都重新创建一个新连接？ 客户端收到返回后，如何知道是哪个请求的返回并且做出正确处理？ 消息的序列化服务间通信的消息通过什么方式进行序列化？ hessian，XML、JSON、Protobuf、……, 甚至Java原生的序列化方式， 你总得选择一个。 负载均衡 客户端通过服务注册中心拿到一堆地址，该调哪个呢？最简单的方式，可以通过RR、WRR的方式去做LB。 根据服务实例的metrics做出动态调整, 比如响应时间等 利用一致性哈希， 提高本地缓存利用率 容灾 健康监测: 在某一个服务节点挂掉的时候， 如何在服务注册中心删去这个服务地址？ 服务调用超时与重试: 在调用一个服务实例的时候，如果超时或者报错，怎么处理？ 服务限流: 如何限制最大并发数？这个又可以从客户端和服务端两个角度分析。 "},"pages/SpringCloud/1266003504686694508.html":{"url":"pages/SpringCloud/1266003504686694508.html","title":"能画一张图说说Spring Cloud的核心架构吗?","keywords":"","body":"图解 基本组件 Eureka   首先，我们需要一个注册中心 Eureka ，主要负责每个服务的注册和发现。每个微服务中都有一个Euraka client组件，专门负责将这个服务的服务id（serviceId）、ip、端口等信息注册到Eureka server中。Euraka Server是一个注册中心，该组件内部维护了一个注册表，保存了各个服务所在的机器ip和端口号等信息。 Feign   其次每个服务还需要一个远程服务调用的组件 Feign ，他主要负责与其他服务建立连接，构造请求，然后发起请求来调用其他服务来获取数据。 Ribbon   然后我们一个服务可能会部署很多台机器，那么我们使用Feign 去调用这个服务的时候，到底把请求发送到哪台机器上去呢？此时我们就需要一个组件来根据一定的策略来选择一台机器。不管怎么选的，总之得选一台机器给 Feign 去调用就好了。这个组件就是 Ribbon，Ribbon 主要负责就是负载均衡。Ribbon 会定期去从Eureka 注册中心拉取注册中心，缓存到本地，每次发起远程调用的时候，Ribbon 就会从 Eureka 注册表拉取下来的数据中挑选一个机器让 Feign 来发起远程调用。 Zuul   我们这么多的微服务，如果一个服务一个IP，使用方都需要进行调用的话，是不是得知道每一个服务的IP地址才行呢？那得记住多少才行呀，多不好管理。如果有一个统一的地址，然后根据不同的请求路径来跟我进行转发多少是不，比如 /user/ 是转发到用户服务 ，/product/ 是转向到商品服务等等。我使用的时候，只需要访问同一个IP ，只是路径不一样，就行了。Spring Cloud 也给我们提供了一个组件，那就是 Zuul ，他是一个网关，就是负责网络的路由的。每个请求都经过这个网关，我们还可以做统一鉴权等等很多事情。 Hystrix   还有一个东西也得说一下，就是 Hystrix，它是一个隔离、熔断以及降级的一个框架 。在微服务的相互调用过程中，可能会出现被调用服务错误或者超时的情况，从而导致整个系统崩溃不可用，也就是我们常说的服务雪崩问题，Hystrix 的存在就是为了解决这种问题的。 调用流程 首先每个服务启动的时候都需要往注册中心进行注册。 用户先对网关发起下单请求，网关收到请求后发现呃，是下单操作，要到订单系统，然后把请求路由到订单系统。 订单系统啪啦啪啦一顿操作，然后通过 Feign 去调用 库存系统减库存，通知仓储服务发货，调用积分系统加积分。 在发起调用之前，订单系统还得通过Ribbon 去注册中心去拉取各系统的注册表信息，并且挑一台机器给 Feign 来发起网络调用。 "},"pages/SpringCloud/1266003504770580518.html":{"url":"pages/SpringCloud/1266003504770580518.html","title":"平时除了使用外,有研究过Spring Cloud的底层架构原理吗?","keywords":"","body":"SpringCloud架构原理图 Spring Cloud核心组件 Eureka各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里 Ribbon服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台 Feign基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求 Hystrix发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题 Zuul如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务 "},"pages/SpringCloud/1266003505043210273.html":{"url":"pages/SpringCloud/1266003505043210273.html","title":"从底层实现原理的角度,对比一下Dubbo和Spring Cloud的区别?","keywords":"","body":"Dubbo && SpringCloud原理图 RPC && SpringCloud原理图 相同点 都需要 服务提供方，注册中心，服务消费方。 Dubbo Provider: 暴露服务的提供方，可以通过jar或者容器的方式启动服务。 Consumer: 调用远程服务的服务消费方。 Registry: 服务注册中心和发现中心。 Monitor: 统计服务和调用次数，调用时间监控中心。(dubbo的控制台页面中可以显示，目前只有一个简单版本) Container: 服务运行的容器。 Spring Cloud Service Provider: 暴露服务的提供方。 Service Consumer: 调用远程服务的服务消费方。 EureKa Server: 服务注册中心和服务发现中心。 比较 从核心要素来看 Spring Cloud 更胜一筹，在开发过程中只要整合Spring Cloud的子项目就可以顺利的完成各种组件的融合，而Dubbo缺需要通过实现各种Filter来做定制，开发成本以及技术难度略高。Dubbo只是实现了服务治理，而Spring Cloud子项目分别覆盖了微服务架构下的众多部件，而服务治理只是其中的一个方面。Dubbo提供了各种Filter，对于上述中“无”的要素，可以通过扩展Filter来完善。 分布式配置：可以使用淘宝的diamond、百度的disconf来实现分布式配置管理 服务跟踪：可以使用京东开源的Hydra，或者扩展Filter用Zippin来做服务跟踪 批量任务：可以使用当当开源的Elastic-Job、tbschedule 从协议上看Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况，二进制的传输，占用带宽会更少。Spring Cloud 使用HTTP协议的REST APIdubbo支持各种通信协议，而且消费方和服务方使用长链接方式交互，http协议传输，消耗带宽会比较多，同时使用http协议一般会使用JSON报文，消耗会更大。通信速度上Dubbo略胜Spring Cloud，如果对于系统的响应时间有严格要求，长链接更合适。 从服务依赖方式看Dubbo服务依赖略重，需要有完善的版本管理机制，但是程序入侵少。而Spring Cloud通过Json交互，省略了版本管理的问题，但是具体字段含义需要统一管理，自身Rest API方式交互，为跨平台调用奠定了基础。 从组件运行流程看Dubbo每个组件都是需要部署在单独的服务器上，gateway用来接受前端请求、聚合服务，并批量调用后台原子服务。每个service层和单独的DB交互。 SpringCloud所有请求都统一通过 API 网关(Zuul)来访问内部服务。网关接收到请求后，从注册中心（Eureka）获取可用服务。由Ribbon进行均衡负载后，分发到后端的具体实例。微服务之间通过 Feign 进行通信处理业务。业务部署方式相同，都需要前置一个网关来隔绝外部直接调用原子服务的风险。Dubbo需要自己开发一套API 网关，而Spring Cloud则可以通过Zuul配置即可完成网关定制。使用方式上Spring Cloud略胜一筹。 "},"pages/SpringCloud/1266003505391337531.html":{"url":"pages/SpringCloud/1266003505391337531.html","title":"你们的服务注册中心进行过选型调研吗?对比一Eureka和Zookeeper?","keywords":"","body":"Eureka && Zookeeper Eureka (AP)   peer-to-peer，部署一个集群，但是集群里每个机器的地位是对等的，各个服务可以向任何一个Eureka实例服务注册和服务发现，集群里任何一个Eureka实例接收到写请求之后，会自动同步给其他所有的Eureka实例。Eureka是peer模式，可能还没同步数据过去，结果自己就死了，此时还是可以继续从别的机器上拉取注册表，但是看到的就不是最新的数据了，但是保证了可用性，强一致，最终一致性。 单点问题eureka需要部署服务，服务自身需要做集群，增加了系统部署的复杂性。 数据同步各服务之间数据同步是异步的，定时的，这会导致节点间一定时间内，数据不一致；并且，在数据复制的过程中，如果持有新实例注册信息的注册中心自身挂掉了，这个实例就无法得到注册； 自我保护机制注册中心自身如果监测到某个实例的心跳成功比例一定时间内小于一定的阈值，这个实例注册信息会被保护起来，不会注销掉，等到这个心跳成功比例大于阈值时，退出自我保护机制。在这个保护期内，如果服务挂了，那这个实例信息其实时有问题的，应该被剔除。 心跳压力如果注册中心注册的实例过多，比如500个，每个间隔30s发出一次续约心跳，那30s内，就是15000个心跳连接，这个心跳的请求可能大于实际业务发出的请求。 健康检查机制健康检查比较单一，仅仅检查心跳是不够的，心跳还在，说明服务进程没死，那服务所在的硬件问题如内存满载，关联的db挂了等，这些都无法得到反应，所以服务可能并不能提供服务了，但是服务还在注册中心的列表中。 维护风险官方宣布2.0的开源工作停止了，继续使用的责任自负。 Zookeeper (CP)   Leader + Follower两种角色，只有Leader可以负责写也就是服务注册，他可以把数据同步给Follower，读的时候leader/follower都可以读。ZooKeeper是有一个leader节点会接收数据， 然后同步写其他节点，一旦leader挂了，要重新选举leader，这个过程里为了保证C，就牺牲了A，不可用一段时间，但是一个leader选举好了，那么就可以继续写数据了，保证一致性。 重java开发，引入依赖多，对于服务器而言太重，部署复杂，不支持多数据中心。对服务侵入大。 健康检查检查方式单一，需要消费者自己实现，也是靠心跳连接保活，连接断开，就是服务挂了，服务就会被剔除。 更新非常稳定，更新少，微服务架构下，对于做专业的注册中心而言，功能匮乏，丧失了快速迭代的能力，不够与时俱进，不够灵活。 算法paxos算法，复杂难懂。 etcd 未使用过，资料了解，其本质上是一个比zk轻量的分布式键值对存储系统，但是需要搭配其他小工具才能较好较易用的实现注册中心功能。但是，为了实现A功能，又额外引入了B和C工具，不是一个优雅的实现方案，而且不支持多数据中心,无web管理页面。 consul (CP) 数据一致性 raft算法，实现思路从源头上避免了数据不一致性。注册时，超过半数没有拿到信息，那就注册失败。 开箱即用 集成简单，不依赖其他工具，使用也简单，支持2种服务注册方式：配置文件，http api。 kv存储 支持和zk和etcd一样的kv存储，可做配置中心。 健康检查 健康检查支持好，提供多种健康检查功能，比如服务返回的状态码，内存利用率等。 心跳 服务状态的检查，不是直接向注册中心发心跳，而是agent向服务发出健康监测。 web管理页面 官方提供良好的web管理页面。 活跃 社区很活跃，更新频繁。 Nacos 这个最近也挺火，待了解。 Tips 一致性保障: CP or AP CAP: C是一致性，A是可用性，P是分区容错性。 ZooKeeper是有一个leader节点会接收数据， 然后同步写其他节点，一旦leader挂了，要重新选举leader，这个过程里为了保证C，就牺牲了A，不可用一段时间，但是一个leader选举好了，那么就可以继续写数据了，保证一致性。Eureka是peer模式，可能还没同步数据过去，结果自己就死了，此时还是可以继续从别的机器上拉取注册表，但是看到的就不是最新的数据了，但是保证了可用性，强一致，最终一致性。 "},"pages/SpringCloud/1266003505634607158.html":{"url":"pages/SpringCloud/1266003505634607158.html","title":"画图阐述一下你们的服务注册中心部署架构,生产环境下怎么保证高可用?","keywords":"","body":"图略 高可用 Eureka高可用，至少2台做集群。两个分支内相互配置另一台的ip和端口号。 "},"pages/SpringCloud/1266003505915625504.html":{"url":"pages/SpringCloud/1266003505915625504.html","title":"你们系统遇到过服务发现过慢的问题吗?怎么优化和解决的?","keywords":"","body":"客户端的有效负载缓存应该更新的时间间隔,默认为30 * 1000ms eureka.server.responseCacheUpdateIntervalMs = 30000(30s) -> 3000(3s) 从eureka服务器注册表中获取注册信息的时间间隔(s),默认为30s eureka.client.registryFetchIntervalSeconds = 30000 -> 3000 客户端多长时间发送心跳给eureka服务器,表明它仍然活着,默认为30s eureka.client.leaseRenewalIntervalInSeconds = 30 -> 3 过期实例应该剔除的时间间隔,单位为毫秒,默认为60 * 1000 eureka.server.evictionIntervalTimerInMs = 60000 -> 6000(6s) Eureka服务器在接收到实例的最后一次发出的心跳后,需要等待多久才可以将此实例删除,默认为90s eureka.instance.leaseExpirationDurationInSeconds = 90 -> 9(s) 服务发现的时效性变成秒级,几秒钟可以感知服务的上线和下线 "},"pages/SpringCloud/1266003506066620430.html":{"url":"pages/SpringCloud/1266003506066620430.html","title":"说一下自己公司的服务注册中心怎么技术选型的?生产环境中应该怎么优化?","keywords":"","body":"服务注册,故障和发现的时效性是多长时间?注册中心最大能支撑多少服务实例? 如何部署的，几台机器，每台机器的配置如何，会用比较高配置的机器来做，8核16G，16核32G的高配置机器来搞，基本上可以做到每台机器每秒钟的请求支撑几千绝对没问题。 可用性如何来保证? 有没有做过一些优化，服务注册、故障以及发现的时效性，是否可以优化一下，用eureka的话，可以尝试一下，配合我们讲解的那些参数，优化一下时效性，服务上线、故障到发现是几秒钟的时效性。zk，一旦服务挂掉，zk感知到以及通知其他服务的时效性，服务注册到zk之后通知到其他服务的时效性，leader挂掉之后可用性是否会出现短暂的问题，为了去换取一致性。 "},"pages/SpringCloud/1266003506205032504.html":{"url":"pages/SpringCloud/1266003506205032504.html","title":"你们对网关的技术选型是怎么考虑的?能对比一下各种网关的优劣吗?","keywords":"","body":"网关的核心功能 动态路由：新开发某个服务，动态把请求路径和服务的映射关系热加载到网关里去；服务增减机器，网关自动热感知 灰度发布 授权认证 性能监控：每个API接口的耗时、成功率、QPS 系统日志 数据缓存 限流熔断 Zuul && Spring Cloud Gateway zuul是Netflix的产品，gateway是spring全家桶的亲儿子。zuul 更新维护不积极，所以gateway自己做了网关，就是为了替代zuul zuul 1.0和 2.0差别很大，1.0版本是基于servlet的同步阻塞io，2.0是基于netty通信的异步io，并发能力2.0版本大大提升。但是2.0文档相对不友好。gateway本身是基于netty通信的异步io，并发能力很强。 gateway文档齐全，架构清晰简单。容易上手，团队学习成本低，gateway有很多可以开箱即用的功能，非常方便。 gateway功能性更强，有非常多的predicate实现和filter，直接配置化就可以使用。同时还可以基于Redis记性流量控制。 "},"pages/SpringCloud/1266003506511216704.html":{"url":"pages/SpringCloud/1266003506511216704.html","title":"说说生产环境下,你们是怎么实现网关对服务的动态路由的?","keywords":"","body":"方案一: 数据库 如果映射关系写死，每次路由关系更改，就需要重启网关，影响会非常大，因此需要实现网关动态的更新路由关系。 可以使用第三方组件保存路由关系，然后在网关里面通过定时任务去定时刷新组件中保存的路由信息。 因此就可以基于mqsql去做路由关系的保存，然后通过后台管理系统去操作db，再由网关去定时查询db更新路由表，实现动态效果。Nginx（Kong、Nginx+Lua）：Nginx抗高并发的能力很强，少数几台机器部署一下，就可以抗很高的并发，精通Nginx源码，很难，c语言，很难说从Nginx内核层面去做一些二次开发和源码定制。 方案二: Config配置 将Spring Cloud Zuul的路由信息，配置在 Config Server 的env.yml中，将网关服务注册为Config Client，从Config Server获取路由信息。微服务架构的系统中，我们通常会使用轻量级的消息代理来构建一个共用的消息主题让系统中所有微服务实例都连接上来，由于该主题中产生的消息会被所有实例监听和消费，所以我们称它为消息总线。在总线上的各个实例都可以方便地广播一些需要让其他连接在该主题上的实例都知道的消息，例如配置信息的变更或者其他一些管理操作等。Bus就是Spring Cloud中的消息总线。 其他方案: Apollo, Redis... "},"pages/SpringCloud/1266003506809012225.html":{"url":"pages/SpringCloud/1266003506809012225.html","title":"如果网关需要抗每秒10万的高并发访问,你应该怎么对网关进行生产优化?","keywords":"","body":"方案 Zuul网关部署的是什么配置的机器，部署32核64G，对网关路由转发的请求，每秒抗个小几万请求是不成问题的，几台Zuul网关机器。每秒是1万请求，8核16G的机器部署Zuul网关，5台机器就够了。 "},"pages/SpringCloud/1266003506968395844.html":{"url":"pages/SpringCloud/1266003506968395844.html","title":"你们公司的网关是怎么技术选型的,假设有高并发场景?","keywords":"","body":"测试结果 实际压测经验，gateway包含鉴权、日志等业务操作。2C4G的机器两台。500TPS CPU才30% 左右。一般的系统，妥妥的没压力。如果需要更高并发。直接加机器配置即可。 "},"pages/SpringCloud/1266003507165528135.html":{"url":"pages/SpringCloud/1266003507165528135.html","title":"如果需要部署上万服务实例,现有的服务注册中心能否抗住?如何优化?","keywords":"","body":"服务注册中心结构图 核心思想 注册中心主从架构，分片存储服务注册表，服务按需主动拉取注册表，不用全量拉取/推送，避免反向通知瞬时高并发。 自研注意点 客户端 服务拉取: 不用全量拉取，按需拉取(有疑问，怎么设计按需拉取)。还需要一个用于校验拉取增量数据之后数据是否完整的过程。 心跳发送 服务下线 服务端 服务注册: 服务注册表注意读写高并发控制，保证线程安全，也要降低锁的争用。 健康检查: 单位时间内，如果所注册服务没有续约，则要将其下线。 集群同步: 根据具体业务需求，制定合适的集群架构方案，保证吞吐量。 "},"pages/SpringCloud/1266003507534626867.html":{"url":"pages/SpringCloud/1266003507534626867.html","title":"你们是如何基于网关实现灰度发布的?说说你们的灰度发布方案?","keywords":"","body":"解决思路 通过网关(Zuul, ZuulFilter)的发布开关，把少量流量导入到一两台部署了新版本的服务器上，进行测试，这个就叫灰度发布。 开发流程 准备一个数据库和一个表（也可以用Apollo配置中心、Redis、ZooKeeper，其实都可以），放一个灰度发布启用表，存入具体uri以及是否灰度发布的一些信息，然后搞一张映射表。 启动1个线程每隔多少时间就去刷新灰度发布表的数据写到ConcurrentHashMap里面。 接着搞一个filter继承ZuulFilter，重写里面几个函数，其中shouldFilter根据返回值去判断执不执行run。 因此再should里面遍历map去看这次请求是否有开启灰度发布，如果有就执行run里面的逻辑，就自定义一些分发逻辑，这里用的时通过version去判断和分发。 发布流程 首先通过后台系统更改灰度发布标识，后台线程更新了map后，就会去执行根据version分发的策略，将少部分流量分发到new的服务上，然后监控和对应的后台，如果没问题，就更改为current，全线上线，最后将灰度发布表示改回来。 "},"pages/SpringCloud/1266003507681427533.html":{"url":"pages/SpringCloud/1266003507681427533.html","title":"说说你们一个服务从开发到上线,服务注册 网关路由 服务调用的流程?","keywords":"","body":"调用流程 开发了一个新的服务，线上部署，配合网关动态路由的功能，在网关里配置一下路径和新服务的映射关系，此时请求过来直接就可以走到新的服务里去。对已有服务进行迭代和开发，新版本，灰度发布，新版本部署少数几台机器，通过一个界面，开启这个服务的灰度发布，此时zuul filter启用，按照你的规则，把少量的流量打入到新版本部署的机器上去。观察一下少量流量在新版本的机器上运行是否正常。版本改成current，全量机器部署，关闭灰度发布功能，网关就会把流量均匀分发给那个服务了。 "},"pages/SpringCloud/1266003507773702201.html":{"url":"pages/SpringCloud/1266003507773702201.html","title":"画一下你们系统架构的整体架构图?说说各个服务在生产环境怎么部署的?","keywords":"","body":"核心 服务框架,注册中心,网关 部署 中小型系统，拆分10-20个微服务。大型互联网公司，一般几百个，几千个微服务。 中小型，一般2-3台机器足够，把服务上线，服务发现优化到极致。 服务上线：注册表多级缓存同步至1秒，拉取频率降低至1秒。 服务心跳：1秒报1次。 故障发现：1秒检查一次，2，3秒没有认为没有故障等。 服务注册中心没有压力，服务注册中心部署2台机器，每台4C8G，高可用，每秒轻松几百请求，甚至上千。前提是数据库SQL别写的太烂。 网关机器配置稍微高一些，4C8G，一台扛每秒几百个请求，部署3~4台，保证每台网关机器压力较小，进一步保证可靠性。 "},"pages/SpringCloud/1266003507886948414.html":{"url":"pages/SpringCloud/1266003507886948414.html","title":"你们系统每天有多大的访问量?每个服务高峰QPS多少?压测过服务最大QPS吗?","keywords":"","body":"解决思路 每天服务多少请求量，高峰每秒qps，在代码里稍微加一些metrics代码，对自己运行过程中各种请求量，每秒请求量，成功次数，失败次数，在内存里直接做一些计数。在负责的核心服务里，核心接口，开发一个简单的metric统计机制，AtomicLong，保证原则性，并发数据统计准确。每个接口被调用时，可以对每个接口每分钟做一个metric统计，每个接口每天统计计数。再通过Log4j, logback等日志组件，把次数直接打印到日志文件，统计出高峰期每秒系统被访问的次数，每条每个接口访问量。 响应延时 计算一下每个接口从请求到执行完毕，需要耗费多长时间，算一下每个接口平均的请求延时，TP99，TP95，TP90，TP50，TP99，99%的请求耗费的时间在100ms以内，但是1%的请求可能耗费的时间在100ms以上TP99 = 100ms TP95 = 50ms，95%的请求耗费的时间多在50ms以内，但是5%的请求耗费的时间在50ms以上压测工具，java压测工具，开源的可以用的，模拟出来同时有多少用户发起多少请求，每秒发起1000请求能抗住吗？每秒钟发起2000请求能抗住吗？假设你的系统每秒钟最多抗800请求，如果你的压测工具每秒发起了1000个请求，此时会发现最多只有800个请求同时可以被处理，剩余200个请求需要进行排队被阻塞住了，表示你这个系统每秒钟最多抗800个请求。 "},"pages/SpringCloud/1266003508033749072.html":{"url":"pages/SpringCloud/1266003508033749072.html","title":"如果系统访问量比现在增加10倍,你们考虑过系统的扩容方案吗?","keywords":"","body":"解决方案 网关直接多部署10倍的机器即可，前面的Nginx做会负载均衡，把流量均匀分发给各个网关机器。服务扩容，都很简单的，多加机器，部署启动，自动注册到注册中心去，此时其他服务会自动感知到你的服务多加了一些机器。服务实例变多了10倍，此时几十个服务实例，几百个服务实例，对eureka机器会造成每秒几百请求，没问题，eureka机器，8核16G的配置，单机抗上千请求，很轻松。数据库本来是每秒几百请求，10倍，每秒高峰期是三四千请求，横向扩容很麻烦，此时可以考虑给单个数据库部署的机器提高配置，32核128G高配物理机，每秒钟抗几千请求问题不大。 总结(最基本的操作就是扩容) 网关: 横向加机器。 注册中心: 纵向升配置。 数据库: 纵向升配置。 当然还有很多其他专门针对分布式，高并发的优化和操作，不过加机器都是最简单直接的。 "},"pages/SpringCloud/1266003508155383820.html":{"url":"pages/SpringCloud/1266003508155383820.html","title":"你们生产环境的服务是怎么配置超时和重试参数的?为什么要这样配置?","keywords":"","body":"背景 Spring Cloud生产优化，系统第一次启动的时候，调用请求经常出现timeout。 原因 每个服务第一次被请求的时候，他会去初始化一个Ribbon的组件，初始化这些组件需要耗费一定的时间，所以很容易会导致超时。 解决方案 让每个服务启动的时候就直接初始化Ribbon相关的组件，避免第一次请求的时候初始化。 ribbon: eager-load: enabled: true zuul: ribbon: eager-load: enabled: true feign: hystrix: enabled: false "},"pages/SpringCloud/1266003508289601556.html":{"url":"pages/SpringCloud/1266003508289601556.html","title":"如果出现服务请求重试,会不会出现类似重复下单的问题?","keywords":"","body":"答案 可能会 场景 订单服务 -> 创建订单 -> 库存服务 -> 扣减库存 -> wms服务 -> 通知发货 -> 积分服务 -> 增加积分 原因 订单服务调用库存服务的时候，因为网络抖动，请求超时了，超过了秒钟，此时订单服务会重试，再次调用一下库存服务，发送一模一样的请求过去。比如说，订单服务第一次请求库存服务，库存服务其实是把扣减库存的业务逻辑执行成功了，只不过网络问题，导致响应迟迟没有返回给订单服务，可能在1.2s之后返回了响应给订单服务。订单服务就认为请求超时了，他就再次发送了一个一模一样的请求给库存服务，库存服务可能会再次对库存进行扣减。 "},"pages/SpringCloud/1266003508415430739.html":{"url":"pages/SpringCloud/1266003508415430739.html","title":"对于核心接口的防重幂等性,你们是怎么设计的?怎么防止重复下单问题?","keywords":"","body":"方案 数据库唯一索引 基于Redis实现幂等性防重 原因 核心接口，幂等性都是自己保证，对应Create操作，通过DB唯一索引来保证；对于Update操作，建议在核心接口基于业务逻辑，配合Redis，来保证幂等性。比如库存，定制化的针对接口开发幂等性的机制，比如说一旦库存扣减成功之后，就立马要写一条数据到redis里去，order_id_11356_stock_deduct，写入redis中，如果写入成功，就说明之前这个订单的库存扣减，没人执行过。但是如果此时有一些重试的请求过来了，调用了你的库存扣减接口，他同时也进行了库存的扣减，但是他用同样的一个key，order_id_11356_stock_deduct，写入redis中，此时会发现已经有人写过key，key已经存在了。此时你就应该直接对刚才的库存扣减逻辑做一个反向的回滚逻辑，update product_stock set stock = stock - 100，update product_stock set stock = stock + 100，反向逻辑，回滚自己，避免重复扣减库存。 "},"pages/SpringCloud/1266003508566425662.html":{"url":"pages/SpringCloud/1266003508566425662.html","title":"画一下你们电商系统的核心交易链路图,说说分布式架构下存在什么问题?","keywords":"","body":"问题 分布式事务，分布式锁 原因 分布式系统，事务 -> 分布式事务，锁 -> 分布式锁 电商核心流程 订单服务 -> 创建订单 -> 库存服务 -> 扣减库存 -> 积分服务 -> 增加积分 -> 仓储服务 -> 通知发货 "},"pages/SpringCloud/1266003508725809155.html":{"url":"pages/SpringCloud/1266003508725809155.html","title":"针对电商核心交易链路,你们是怎么设计分布式事务技术方案的?","keywords":"","body":"方案 TCC 订单服务、库存服务、积分服务 -> 绑定为一个TCC事务 撤销刚才创建订单时，回滚刚才扣减库存和增加积分 可靠消息最终一致性 可以去发送一个请求给消息中间件，由中间件保证一定会把消息交给下游的库存服务去扣减库存，仓储服务去通知发货等，如果这个过程中有消息发送失败，则可靠消息中间件应该保证不停的重试投递消息。 原因 一个要求强一致，一个要求最终一致。强一致主要用于核心模块，例如交易/订单等。最终一致一般用于边缘模块例如库存，通过mq去通知，保证最终一致性，也可以业务解耦。 "},"pages/SpringCloud/1266003508860026894.html":{"url":"pages/SpringCloud/1266003508860026894.html","title":"对于TCC事务,最终一致性事务的技术选型,你们是怎么做的?如何调研的?","keywords":"","body":"选型方案 TCC 阿里开源了分布式事务框架，fescar，seata。seata类似TCC事务，经历过阿里生产环境大量考验的框架。支持Dubbo，Spring Cloud。 可靠消息最终一致性 基于ActiveMQ，RabbitMQ, RocketMQ等，自己开发一个可靠消息服务，收到消息之后，尝试投递到MQ，如果投递失败，重试投递。现在大量用RocketMQ，作为MQ中间件，提供了分布式事务支持，已经把可靠消息服务需要实现的功能逻辑已经做好了。 "},"pages/SpringCloud/1266003509036187661.html":{"url":"pages/SpringCloud/1266003509036187661.html","title":"在搭建的电商系统里,落地开发对交易链路的TCC分布式事务方案?","keywords":"","body":"图解 方案 seata (https://github.com/seata/seata-samples.git) 特点 自动回滚数据库事务 原因 把seata所有的示例代码拷贝下来，里面提供的例子就是跟我们说的电商的核心例子是类似的.然后先要下载一个seata-server到本地，在这里下载：https://github.com/seata/seata/releases，然后启动起来，这是分布式事务管理中心，负责维护每一个分布式事务的状态，触发分布式事务的提交和回滚。 "},"pages/SpringCloud/1266003509468201025.html":{"url":"pages/SpringCloud/1266003509468201025.html","title":"你能说说一个TCC分布式事务框架的核心架构原理吗?","keywords":"","body":"Seata架构原理 https://github.com/seata/seata Seata中角色 Transaction Coordinator（TC）:协调器，单独的一个server。维护全局和分支事务的状态，驱动全局事务的提交或回滚。 Transaction Manager(TM)：全局事务的发起者，负责开始/提交/回滚一个全局事务。（对应订单服务） Resource Manager(RM)：管理分支事务（注册分支事务/状态/提交/回滚），并负责与TC通讯。 整个使用seata进行分布式事务管理的生命周期 TM向TC发起全局事务，TC返回XID作为标识。 XID通过调用链传播。 RM将本地的事务注册到TC中表示为XID的全局事务中，成为一个分支事务。 再由TM向TC请求标识为XID的全局事务提交/回滚。 最终，由TC去驱动所有的分支事务提交/回滚。 "},"pages/SpringCloud/1266003509602418771.html":{"url":"pages/SpringCloud/1266003509602418771.html","title":"现有的TCC事务方案的性能瓶颈在哪里?能支撑高并发交易场景吗?如何优化?","keywords":"","body":"瓶颈 使用分布式事务主要是保证核心链路要么全部成功，要么全部失败。当然也会带来一些性能的开销。seata模型里面频繁的网络通信，以及对应事务的状态持久化的IO等等。如果需要支撑高并发，那么TC服务也需要横向扩容。相应的，对于TC背后的DB也需要进行优化。 优化 "},"pages/SpringCloud/1266003509698887696.html":{"url":"pages/SpringCloud/1266003509698887696.html","title":"你了解RocketMQ对分布式事务支持的底层实现原理吗?","keywords":"","body":"图解 原理 核心链路使用seata这种类似于TCC的事务，而像wms这种相当于是分支链路，可以通过MQ进行解耦。但是通过MQ解耦也会带来一些问题，例如消息丢失，消息重复等等问题，因此也需要进行最终一致性的保证。 结合整个订单接口服务，分为两个支付链路，一个是核心链路（订单业务），一个是非核心链路（wms） 整个流程。先向RocketMQ发送half msg，然后调用核心链路。核心链路要是返回失败，就会走失败的逻辑：退款，更改订单状态为取消，再给rocketmq发送callback废弃掉刚才的消息。如果成功，就commit msg让消费者可以消费。如果在等待期间，一直没有callback/commit那么mq就会走回调查询具体的状态。最终消费者接收到消息后，消费完成就回复mq一个ack， 如果消费失败了，mq就会重新投递或者换一个服务投递。使用rocketmq的half msg机制，可以实现这一套固定模式的最终一致性，很完善。 这个将wms的操作放在核心链路前面的这个问题，是为了提升整个订单接口服务的效率，因为需要保证最终一致性，那么必然会有消息生产者对MQ的一些操作，包括重试，ack等等，如果将这些逻辑全部都放在核心链路执行完成后再去一一完成，那么可能会耗费一些时间。而通过rocketmq这个模式，可以通过half msg的支持，来将整个与mq的交互过程拆解掉，从而提升效率。 "},"pages/SpringCloud/1266003509891825709.html":{"url":"pages/SpringCloud/1266003509891825709.html","title":"如果公司没有RocketMQ中间件,那你们如何实现最终一致性事务?","keywords":"","body":"方案 基于数据库自己开发一个可靠消息服务。接受上游Producer发送的haf msg, 存入DB，返回响应。本地可靠消息服务启动定时扫描本地DB的half msg，超过一定时间没有commit/rollback就回调Producer接口，确认本地事务是否成功，获取commit/rollback。如果消息commit就发送消息给下游服务或者发给RabbitMQ/Kafka/ActiveMQ，下游服务消费后，回调可靠消息服务接口进行ack，如果没有收到ack，重发消息给下游服务。 "}}